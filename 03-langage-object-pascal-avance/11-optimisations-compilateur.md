üîù Retour au [Sommaire](/SOMMAIRE.md)

# 3.11 Optimisations du compilateur FreePascal

## Introduction : Qu'est-ce que l'optimisation du compilateur ?

Imaginez que vous √©crivez une recette de cuisine. Vous pourriez √©crire : "Prendre un ≈ìuf, le casser, le mettre dans le bol, prendre un autre ≈ìuf, le casser, le mettre dans le bol". Une personne intelligente lirait cela et penserait : "Je vais prendre les deux ≈ìufs d'un coup et les casser l'un apr√®s l'autre". C'est exactement ce que fait l'optimisation du compilateur : elle rend votre code plus efficace sans changer le r√©sultat final.

Le compilateur FreePascal peut transformer votre code pour qu'il :
- S'ex√©cute plus rapidement
- Utilise moins de m√©moire
- Produise des fichiers ex√©cutables plus petits

## Les niveaux d'optimisation de base

### Niveau 0 : Aucune optimisation (-O0 ou -O-)

C'est le mode par d√©faut pour le d√©bogage. Le compilateur traduit votre code tel quel, sans chercher √† l'am√©liorer.

```pascal
// Votre code
var
  i, total: Integer;
begin
  total := 0;
  for i := 1 to 100 do
    total := total + 1;
  WriteLn(total);
end.
```

**Compilation :** `fpc -O0 monprogramme.pas`

**Avantages :**
- D√©bogage facile
- Compilation rapide
- Le code assembleur correspond exactement √† votre code source

**Inconv√©nients :**
- Programme plus lent
- Fichier ex√©cutable plus gros

### Niveau 1 : Optimisations l√©g√®res (-O1)

Le compilateur applique des optimisations simples qui ne ralentissent pas trop la compilation.

```pascal
// Le compilateur peut simplifier ceci :
x := 5 + 3;  // Devient directement : x := 8;

// Ou √©liminer du code inutile :
y := 10;
y := 20;  // La premi√®re ligne est supprim√©e
```

**Compilation :** `fpc -O1 monprogramme.pas`

**Optimisations appliqu√©es :**
- Calcul des constantes √† la compilation
- Suppression du code mort (code jamais ex√©cut√©)
- Simplification des expressions

### Niveau 2 : Optimisations standard (-O2)

C'est le niveau recommand√© pour la plupart des programmes en production.

```pascal
// Exemple : boucle qui sera optimis√©e
var
  i: Integer;
  tableau: array[1..1000] of Integer;
begin
  // Cette boucle sera optimis√©e pour √™tre plus rapide
  for i := 1 to 1000 do
    tableau[i] := i * 2;
end.
```

**Compilation :** `fpc -O2 monprogramme.pas`

**Optimisations suppl√©mentaires :**
- R√©organisation des instructions pour une meilleure performance
- Utilisation optimale des registres du processeur
- D√©roulement partiel des boucles simples

### Niveau 3 : Optimisations agressives (-O3)

Le compilateur prend plus de temps mais produit un code tr√®s optimis√©.

**Compilation :** `fpc -O3 monprogramme.pas`

**Optimisations suppl√©mentaires :**
- Inline automatique de petites fonctions
- Optimisations math√©matiques avanc√©es
- R√©organisation agressive du code

### Niveau 4 : Optimisations maximales (-O4)

Attention : peut parfois causer des probl√®mes avec certains codes !

**Compilation :** `fpc -O4 monprogramme.pas`

## Optimisations sp√©cifiques importantes

### 1. Optimisation de la taille (-Os)

Produit le plus petit ex√©cutable possible, utile pour les syst√®mes embarqu√©s.

```bash
# Windows
fpc -Os monprogramme.pas

# Ubuntu/Linux
fpc -Os monprogramme.pas
```

### 2. Inline de fonctions (-Si)

Le compilateur remplace les appels de petites fonctions par leur code directement.

```pascal
// Sans inline : chaque appel est un saut dans le programme
function Double(x: Integer): Integer; inline;
begin
  Result := x * 2;
end;

// Utilisation
y := Double(5);  // Sera remplac√© par : y := 5 * 2;
```

### 3. Optimisations pour processeur sp√©cifique

```bash
# Pour un processeur Intel Core moderne
fpc -CpCOREI -O3 monprogramme.pas

# Pour un processeur AMD Ryzen
fpc -CpZEN -O3 monprogramme.pas

# Pour voir tous les processeurs support√©s
fpc -ic
```

## Configuration dans Lazarus

### M√©thode graphique (recommand√©e pour d√©butants)

1. **Ouvrez votre projet** dans Lazarus
2. **Menu Projet ‚Üí Options du projet**
3. **Section "Compilateur"** dans l'arborescence √† gauche
4. **Onglet "Compilation et √©dition de liens"**

Vous verrez plusieurs options :

- **Optimisation** : Choisissez le niveau (0 √† 3)
- **Optimiser pour** :
  - "Plus rapide" : g√©n√®re du code plus rapide
  - "Plus petit" : g√©n√®re un ex√©cutable plus petit
- **Processeur cible** : S√©lectionnez votre processeur

### Configuration par profils

Cr√©ez diff√©rents modes de compilation :

1. **Mode Debug** (d√©veloppement)
   - Optimisation : Niveau 0
   - G√©n√©rer les infos de d√©bogage : Oui
   - V√©rifications : Toutes activ√©es

2. **Mode Release** (production)
   - Optimisation : Niveau 2 ou 3
   - G√©n√©rer les infos de d√©bogage : Non
   - V√©rifications : D√©sactiv√©es

## Optimisations Windows vs Ubuntu

### Sp√©cificit√©s Windows

```pascal
{$IFDEF WINDOWS}
  {$OPTIMIZATION ON}
  {$SMARTLINK ON}  // R√©duit la taille de l'ex√©cutable
{$ENDIF}
```

**Compilation optimis√©e Windows :**
```batch
fpc -O3 -XX -CX -Xs monprogramme.pas
```

- `-XX` : Smart linking (√©limine le code non utilis√©)
- `-CX` : Recr√©e les tables d'import
- `-Xs` : Strip les symboles (r√©duit la taille)

### Sp√©cificit√©s Ubuntu/Linux

```pascal
{$IFDEF LINUX}
  {$OPTIMIZATION ON}
  {$LINKLIB c}  // Optimise les liens avec les biblioth√®ques syst√®me
{$ENDIF}
```

**Compilation optimis√©e Ubuntu :**
```bash
fpc -O3 -XX -CX -Xs monprogramme.pas
```

Sur Ubuntu, vous pouvez aussi utiliser :
```bash
# Apr√®s compilation, r√©duire encore la taille
strip monprogramme
```

## Directives d'optimisation dans le code

Vous pouvez activer/d√©sactiver les optimisations directement dans votre code :

```pascal
{$OPTIMIZATION OFF}  // D√©sactive l'optimisation
procedure CodeCritiquePourDebug;
begin
  // Code qui doit rester exactement comme √©crit
  // pour le d√©bogage
end;
{$OPTIMIZATION ON}  // R√©active l'optimisation

{$OPTIMIZATION LEVEL2}  // Force le niveau 2
procedure CodeOptimise;
begin
  // Code qui sera optimis√© niveau 2
end;
{$OPTIMIZATION DEFAULT}  // Retour au niveau par d√©faut
```

## Mesurer l'impact des optimisations

### Code de test simple

```pascal
program TestOptimisation;
uses SysUtils;

var
  Start, Stop: TDateTime;
  i, j, resultat: Int64;

begin
  WriteLn('Test de performance...');

  Start := Now;

  // Code √† tester
  resultat := 0;
  for i := 1 to 100000000 do
  begin
    resultat := resultat + i;
    if (i mod 2) = 0 then
      resultat := resultat - (i div 2);
  end;

  Stop := Now;

  WriteLn('Resultat: ', resultat);
  WriteLn('Temps: ', FormatDateTime('ss.zzz', Stop - Start), ' secondes');
end.
```

### Comparer les r√©sultats

```bash
# Sans optimisation
fpc -O0 test.pas
./test
# Temps: 02.345 secondes

# Avec optimisation niveau 2
fpc -O2 test.pas
./test
# Temps: 00.876 secondes

# Avec optimisation niveau 3
fpc -O3 test.pas
./test
# Temps: 00.654 secondes
```

## Bonnes pratiques et pi√®ges √† √©viter

### ‚úÖ Bonnes pratiques

1. **D√©veloppement** : Utilisez `-O0` pour faciliter le d√©bogage
2. **Tests** : Passez progressivement √† `-O1` puis `-O2`
3. **Production** : Utilisez `-O2` par d√©faut (bon √©quilibre)
4. **Critique** : `-O3` uniquement si les performances sont cruciales

### ‚ö†Ô∏è Pi√®ges courants

1. **Ne pas tester apr√®s optimisation**
   ```pascal
   // Ce code peut se comporter diff√©remment avec -O3
   var p: PInteger;
   begin
     p := nil;
     if Assigned(p) and (p^ > 0) then  // Danger avec optimisations
       WriteLn('OK');
   end;
   ```

2. **Supposer que plus = mieux**
   - `-O4` n'est pas toujours plus rapide que `-O3`
   - `-Os` peut √™tre plus rapide que `-O3` sur des petits programmes

3. **Oublier l'architecture cible**
   ```bash
   # Mauvais : compile pour processeur g√©n√©rique
   fpc -O3 programme.pas

   # Bon : compile pour votre processeur
   fpc -O3 -CpCOREI7 programme.pas
   ```

## Optimisations avanc√©es (pour aller plus loin)

### Analyse du code assembleur g√©n√©r√©

```bash
# G√©n√®re le fichier assembleur pour analyse
fpc -O2 -al programme.pas

# Ouvre programme.s pour voir le code assembleur
```

### Profiling pour identifier o√π optimiser

```pascal
// Utilisez un profiler pour voir o√π votre programme passe du temps
// Sous Windows : utilisez gprof ou des outils comme Very Sleepy
// Sous Ubuntu : utilisez gprof, valgrind ou perf

// Compilation avec support du profiling
fpc -O2 -pg programme.pas
```

### Optimisations manuelles compl√©mentaires

```pascal
// Utilisez des types appropri√©s
var
  i: Byte;     // Si vous savez que i < 256
  // au lieu de
  i: Integer;  // Qui prend plus de m√©moire

// Pr√©-calculez quand possible
const
  PI_TIMES_2 = 6.28318;  // Au lieu de calculer PI * 2 √† chaque fois

// √âvitez les divisions (lentes)
x := y div 2;   // Lent
x := y shr 1;   // Rapide (division par 2 en d√©calant les bits)
```

## Tableau r√©capitulatif

| Option | Utilisation | Vitesse | Taille | D√©bogage |
|--------|------------|---------|--------|----------|
| -O0 | D√©veloppement | ‚ùå Lente | ‚ùå Grande | ‚úÖ Facile |
| -O1 | Debug avanc√© | ‚ö° Correcte | üì¶ Moyenne | ‚úÖ Possible |
| -O2 | Production | ‚ö°‚ö° Rapide | üì¶ Raisonnable | ‚ö†Ô∏è Difficile |
| -O3 | Performance | ‚ö°‚ö°‚ö° Tr√®s rapide | üì¶ Variable | ‚ùå Tr√®s difficile |
| -Os | Embarqu√© | ‚ö° Correcte | üì¶‚úÖ Minimale | ‚ùå Difficile |


Les optimisations du compilateur FreePascal sont un outil puissant pour am√©liorer les performances de vos programmes. Commencez simple avec `-O0` pendant le d√©veloppement, puis augmentez progressivement le niveau d'optimisation. Testez toujours votre programme apr√®s avoir chang√© les optimisations, car certains bugs peuvent n'appara√Ætre qu'avec certains niveaux d'optimisation.

Pour la plupart des applications, `-O2` offre le meilleur compromis entre performance et fiabilit√©. N'oubliez pas que l'optimisation pr√©matur√©e est la racine de tous les maux : √©crivez d'abord du code correct et lisible, optimisez ensuite si n√©cessaire !


## Optimisations
1. [Introduction aux optimisations](#introduction)
2. [Architecture du processus de compilation](#architecture)
3. [Les niveaux d'optimisation d√©taill√©s](#niveaux)
4. [Optimisations sp√©cifiques du compilateur](#specifiques)
5. [Optimisations par type de donn√©es](#types)
6. [Optimisations des structures de contr√¥le](#structures)
7. [Optimisations m√©moire](#memoire)
8. [Optimisations multi-plateformes](#multiplateforme)
9. [Directives et pragmas](#directives)
10. [Optimisations manuelles compl√©mentaires](#manuelles)
11. [Profiling et analyse](#profiling)
12. [Cas pratiques et exemples](#pratiques)
13. [D√©pannage et r√©solution de probl√®mes](#depannage)

## 1. Introduction aux optimisations {#introduction}

### Qu'est-ce que l'optimisation du compilateur ?

L'optimisation du compilateur est un ensemble de transformations automatiques appliqu√©es √† votre code source pour am√©liorer ses performances sans modifier son comportement observable. C'est comme avoir un assistant intelligent qui r√©√©crit votre code pour le rendre plus efficace tout en gardant exactement le m√™me r√©sultat.

Prenons un exemple concret :

```pascal
// Code original √©crit par le d√©veloppeur
function CalculerSomme: Integer;
var
  i, total: Integer;
begin
  total := 0;
  for i := 1 to 5 do
  begin
    total := total + i;
  end;
  Result := total;
end;

// Apr√®s optimisation, le compilateur pourrait g√©n√©rer l'√©quivalent de :
function CalculerSomme: Integer;
begin
  Result := 15;  // Le compilateur a calcul√© 1+2+3+4+5 = 15 √† la compilation
end;
```

### Pourquoi optimiser ?

Les optimisations du compilateur permettent de :

1. **Am√©liorer les performances d'ex√©cution**
   - R√©duction du temps d'ex√©cution de 20% √† 500% selon les cas
   - Meilleure utilisation du cache processeur
   - Moins d'instructions machine g√©n√©r√©es

2. **R√©duire l'utilisation m√©moire**
   - √âlimination des variables temporaires inutiles
   - R√©utilisation optimale des registres
   - Compression des structures de donn√©es

3. **Diminuer la taille des ex√©cutables**
   - Suppression du code mort
   - Factorisation du code dupliqu√©
   - √âlimination des symboles inutiles

4. **Optimiser la consommation √©nerg√©tique**
   - Moins d'instructions = moins de cycles processeur
   - Important pour les applications mobiles et embarqu√©es

### Les phases de compilation FreePascal

```
Code source (.pas)
        ‚Üì
[Analyse lexicale] ‚Üí D√©coupage en tokens
        ‚Üì
[Analyse syntaxique] ‚Üí Arbre syntaxique abstrait (AST)
        ‚Üì
[Analyse s√©mantique] ‚Üí V√©rification des types
        ‚Üì
[OPTIMISATIONS DE HAUT NIVEAU] ‚Üê Nous sommes ici
        ‚Üì
[G√©n√©ration de code interm√©diaire]
        ‚Üì
[OPTIMISATIONS DE BAS NIVEAU] ‚Üê Et ici
        ‚Üì
[G√©n√©ration de code machine]
        ‚Üì
[√âdition de liens]
        ‚Üì
Ex√©cutable final (.exe ou binaire)
```

## 2. Architecture du processus de compilation {#architecture}

### Les diff√©rentes passes d'optimisation

FreePascal effectue plusieurs passes d'optimisation :

#### Passe 1 : Optimisations ind√©pendantes de la plateforme

```pascal
// Exemple : Propagation de constantes
const
  LARGEUR = 100;
  HAUTEUR = 50;

var
  surface: Integer;
begin
  surface := LARGEUR * HAUTEUR;  // Devient : surface := 5000;
end;
```

#### Passe 2 : Optimisations de flot de contr√¥le

```pascal
// Exemple : √âlimination de code inaccessible
procedure Test(x: Integer);
begin
  if x > 0 then
    WriteLn('Positif')
  else if x < 0 then
    WriteLn('N√©gatif')
  else
    WriteLn('Z√©ro');

  Exit;  // Tout ce qui suit est √©limin√©

  WriteLn('Ce code ne sera jamais ex√©cut√©');  // Supprim√© √† la compilation
end;
```

#### Passe 3 : Optimisations sp√©cifiques √† l'architecture

```pascal
// Sur x86-64, utilisation des instructions SIMD pour les tableaux
var
  a, b, c: array[0..3] of Single;
  i: Integer;
begin
  // Sans optimisation : 4 additions s√©par√©es
  for i := 0 to 3 do
    c[i] := a[i] + b[i];

  // Avec optimisation : Une seule instruction SIMD (ADDPS)
  // qui additionne les 4 valeurs simultan√©ment
end;
```

### Le syst√®me de repr√©sentation interm√©diaire

FreePascal utilise une repr√©sentation interm√©diaire (IR) pour faciliter les optimisations :

```pascal
// Code Pascal
x := y + z * 2;

// Repr√©sentation interm√©diaire (simplifi√©)
LOAD  y, R1
LOAD  z, R2
MUL   R2, 2, R3
ADD   R1, R3, R4
STORE R4, x

// Apr√®s optimisation (si z est constant = 5)
LOAD  y, R1
ADD   R1, 10, R2  // z*2 = 5*2 = 10 calcul√© √† la compilation
STORE R2, x
```

## 3. Les niveaux d'optimisation d√©taill√©s {#niveaux}

### Niveau -O0 ou -O- : Aucune optimisation

C'est le mode de compilation le plus basique, utilis√© principalement pour le d√©bogage.

```pascal
program TestO0;
var
  a, b, c: Integer;
begin
  a := 10;
  b := 20;
  c := a + b;
  WriteLn(c);
end.
```

**Compilation :**
```bash
fpc -O0 -al test.pas  # -al g√©n√®re le fichier assembleur
```

**Caract√©ristiques du code g√©n√©r√© :**
- Chaque ligne Pascal correspond √† des instructions assembleur
- Toutes les variables sont stock√©es en m√©moire
- Aucune optimisation des registres
- Instructions de d√©bogage pr√©serv√©es
- Taille typique : 100% (r√©f√©rence)
- Vitesse : La plus lente

**Assembleur g√©n√©r√© (extrait simplifi√©) :**
```asm
movl $10, -4(%rbp)   # a := 10
movl $20, -8(%rbp)   # b := 20
movl -4(%rbp), %eax  # Charge a
addl -8(%rbp), %eax  # Ajoute b
movl %eax, -12(%rbp) # Stocke dans c
```

### Niveau -O1 : Optimisations de base

Premier niveau d'optimisation, bon compromis compilation/performance.

**Optimisations activ√©es :**

1. **Constant folding (pliage de constantes)**
```pascal
// Avant
x := 2 + 3 * 4;
y := 100 div 5;

// Apr√®s optimisation O1
x := 14;  // Calcul√© √† la compilation
y := 20;  // Calcul√© √† la compilation
```

2. **Dead code elimination (√©limination du code mort)**
```pascal
// Avant
procedure Test;
var
  unused: Integer;
begin
  unused := 42;  // Cette ligne sera supprim√©e
  WriteLn('Hello');
end;

// Apr√®s optimisation O1
procedure Test;
begin
  WriteLn('Hello');
end;
```

3. **Common subexpression elimination (CSE)**
```pascal
// Avant
a := b * c + 10;
d := b * c + 20;

// Apr√®s optimisation O1
temp := b * c;  // Calcul fait une seule fois
a := temp + 10;
d := temp + 20;
```

**Performance :**
- Compilation : ~10% plus lente qu'en -O0
- Ex√©cution : 20-40% plus rapide qu'en -O0
- Taille : 90-95% de -O0

### Niveau -O2 : Optimisations standard

Niveau recommand√© pour la production, √©quilibre optimal.

**Optimisations suppl√©mentaires :**

1. **Loop optimizations (optimisations de boucles)**
```pascal
// Loop unrolling partiel
// Avant
for i := 1 to 8 do
  arr[i] := i * 2;

// Apr√®s optimisation O2 (d√©roulement par 4)
// Pseudo-code illustratif (step n'existe pas en Pascal) :
//   for i := 1 to 8 step 4 do ...
// Le compilateur g√©n√®re l'√©quivalent de :
i := 1;
while i <= 8 do
begin
  arr[i] := i * 2;
  arr[i+1] := (i+1) * 2;
  arr[i+2] := (i+2) * 2;
  arr[i+3] := (i+3) * 2;
  Inc(i, 4);
end;
```

2. **Instruction scheduling (ordonnancement des instructions)**
```pascal
// R√©organisation pour √©viter les d√©pendances
// Avant
a := b + c;  // Instruction 1
d := a * 2;  // D√©pend de 1, doit attendre
e := f + g;  // Ind√©pendant

// Apr√®s optimisation O2
a := b + c;  // Instruction 1
e := f + g;  // Ex√©cut√© en parall√®le avec 1
d := a * 2;  // Maintenant a est pr√™t
```

3. **Register allocation (allocation de registres)**
```pascal
// Variables fr√©quemment utilis√©es gard√©es dans les registres
function Calculate: Integer;
var
  i, sum: Integer;  // Seront dans des registres, pas en m√©moire
begin
  sum := 0;
  for i := 1 to 1000000 do
    sum := sum + i;
  Result := sum;
end;
```

4. **Function inlining s√©lectif**
```pascal
function Small(x: Integer): Integer; inline;
begin
  Result := x * 2;
end;

// L'appel Small(5) devient directement 5 * 2 dans le code
```

**Performance :**
- Compilation : 30-50% plus lente qu'en -O0
- Ex√©cution : 50-100% plus rapide qu'en -O0
- Taille : 85-95% de -O0

### Niveau -O3 : Optimisations agressives

Optimisations maximales pour la vitesse, peut augmenter la taille.

**Optimisations suppl√©mentaires :**

1. **Aggressive inlining**
```pascal
// M√™me les fonctions moyennes sont inline
function ProcessData(const data: array of Integer): Integer;
var
  i: Integer;
begin
  Result := 0;
  for i := 0 to High(data) do
    Result := Result + data[i] * data[i];
end;

// Tout appel √† ProcessData est remplac√© par son code
```

2. **Loop vectorization (vectorisation des boucles)**
```pascal
// Utilisation automatique des instructions SIMD
var
  a, b, c: array[0..1023] of Single;
  i: Integer;
begin
  // Trait√© par blocs de 4 ou 8 valeurs simultan√©ment
  for i := 0 to 1023 do
    c[i] := a[i] * b[i] + 1.0;
end;
```

3. **Predictive commoning**
```pascal
// Pr√©diction et pr√©-calcul des valeurs
for i := 2 to n do
  a[i] := a[i-1] + a[i-2];  // Pattern d√©tect√© et optimis√©
```

**Performance :**
- Compilation : 100-200% plus lente qu'en -O0
- Ex√©cution : 80-200% plus rapide qu'en -O0
- Taille : 95-120% de -O0 (peut √™tre plus gros!)

### Niveau -O4 : Optimisations exp√©rimentales

‚ö†Ô∏è **Attention : Peut causer des probl√®mes de stabilit√©**

```pascal
{$OPTIMIZATION LEVEL4}
// Active des optimisations exp√©rimentales
// - Transformations math√©matiques agressives
// - R√©organisations de code risqu√©es
// - Suppositions sur le comportement du programme
```

**Utilisation :**
```bash
fpc -O4 -Ooloopunroll -Oofastmath programme.pas
```

### Niveau -Os : Optimisation pour la taille

Priorit√© √† la taille minimale de l'ex√©cutable.

```pascal
// Exemple de diff√©rence
// -O2 pourrait d√©rouler cette boucle (plus rapide, plus gros)
// -Os garde la boucle compacte (plus lent, plus petit)
for i := 1 to 100 do
  Process(i);
```

**Techniques utilis√©es :**
- Pas de d√©roulement de boucles
- Pas d'inlining agressif
- Partage maximal du code
- Compression des tables de donn√©es

**Performance :**
- Taille : 60-80% de -O0
- Vitesse : Souvent comparable √† -O1

## 4. Optimisations sp√©cifiques du compilateur {#specifiques}

### Smart Linking (-XX)

√âlimine tout code non utilis√© de l'ex√©cutable final.

```pascal
unit MaBibliotheque;

interface

procedure UtiliseDansLeProgramme;
procedure JamaisAppelee;  // Cette proc√©dure sera √©limin√©e
procedure AutreFonctionInutile;  // Celle-ci aussi

implementation

procedure UtiliseDansLeProgramme;
begin
  WriteLn('Je suis utilis√©e');
end;

procedure JamaisAppelee;
begin
  WriteLn('Code inutile de 1000 lignes...');
  // Tout ce code sera supprim√© de l'ex√©cutable
end;

procedure AutreFonctionInutile;
begin
  // √âgalement supprim√©e
end;

end.
```

**Activation :**
```bash
# Windows et Linux
fpc -XX programme.pas

# R√©duction typique : 30-70% de la taille
```

### Whole Program Optimization (-OWall)

Optimisation globale du programme entier.

```pascal
// Fichier unit1.pas
unit Unit1;
interface
function GetValue: Integer;
implementation
function GetValue: Integer;
begin
  Result := 42;  // Toujours retourne 42
end;
end.

// Fichier main.pas
uses Unit1;
var x: Integer;
begin
  x := GetValue;  // Avec -OWall, devient directement x := 42
  WriteLn(x);
end;
```

**Compilation :**
```bash
fpc -OWall main.pas
```

### Link Time Optimization (LTO)

Optimisation au moment de l'√©dition de liens.

```bash
# Active LTO pour une optimisation maximale inter-unit√©s
fpc -Clflto -k-flto programme.pas
```

**Avantages :**
- Inline inter-unit√©s
- √âlimination de code mort global
- Optimisation des appels virtuels

### Optimisations math√©matiques (-Oofastmath)

‚ö†Ô∏è **Attention : Peut violer les standards IEEE 754**

```pascal
{$OPTIMIZATION FASTMATH}
var
  x, y, z: Double;
begin
  // Sans fastmath : respect strict de l'ordre des op√©rations
  x := (y + z) + 1.0;

  // Avec fastmath : r√©organisation possible
  x := y + (z + 1.0);  // Si plus efficace
end;
```

**Transformations appliqu√©es :**
```pascal
// Simplifications math√©matiques
x * 1.0 ‚Üí x
x / 1.0 ‚Üí x
x + 0.0 ‚Üí x
x - x ‚Üí 0.0
x / x ‚Üí 1.0 (dangereux si x=0!)

// R√©organisations
(a + b) + c ‚Üí a + (b + c)  // Si plus efficace
a * b + a * c ‚Üí a * (b + c)  // Factorisation
```

## 5. Optimisations par type de donn√©es {#types}

### Optimisation des entiers

```pascal
// Utilisation du bon type selon la plage
var
  age: Byte;           // 0..255, 1 octet
  temperature: ShortInt; // -128..127, 1 octet
  compteur: Word;      // 0..65535, 2 octets
  population: Cardinal; // 0..4294967295, 4 octets
  dette: Int64;        // Tr√®s grandes valeurs, 8 octets
```

**Optimisations automatiques :**
```pascal
// Division par puissance de 2
x := y div 8;   // Transform√© en : x := y shr 3

// Multiplication par puissance de 2
x := y * 16;    // Transform√© en : x := y shl 4

// Modulo puissance de 2
x := y mod 32;  // Transform√© en : x := y and 31
```

### Optimisation des r√©els

```pascal
// Pr√©cision et performance
var
  // Single : 4 octets, plus rapide, moins pr√©cis
  vitesse: Single;

  // Double : 8 octets, standard, bon compromis
  prix: Double;

  // Extended : 10 octets (x86), maximum de pr√©cision
  calcul_scientifique: Extended;
```

**Optimisations SSE/AVX :**
```pascal
{$MODESWITCH ADVANCEDRECORDS}
type
  TVector4f = record
    x, y, z, w: Single;
    class operator +(const a, b: TVector4f): TVector4f;
  end;

// Utilise une seule instruction SIMD pour additionner 4 floats
```

### Optimisation des cha√Ænes

```pascal
// Choix du type de cha√Æne appropri√©
var
  // ShortString : 255 caract√®res max, allocation statique, rapide
  nom: String[50];

  // AnsiString : Taille dynamique, compteur de r√©f√©rence
  texte: AnsiString;

  // UnicodeString : Pour le support international
  international: UnicodeString;

  // RawByteString : Pour les donn√©es binaires
  donnees: RawByteString;
```

**Optimisations de concat√©nation :**
```pascal
// Mauvais : r√©allocations multiples
s := '';
for i := 1 to 1000 do
  s := s + IntToStr(i) + ', ';

// Bon : pr√©-allocation
SetLength(s, 10000);  // Pr√©-alloue la m√©moire
p := 1;
for i := 1 to 1000 do
begin
  tmp := IntToStr(i) + ', ';
  Move(tmp[1], s[p], Length(tmp));
  Inc(p, Length(tmp));
end;
SetLength(s, p-1);
```

### Optimisation des tableaux

```pascal
// Tableaux statiques : plus rapides, taille fixe
var
  static: array[0..99] of Integer;  // Sur la pile, acc√®s direct

// Tableaux dynamiques : flexibles mais plus lents
var
  dynamic: array of Integer;  // Sur le tas, indirection

// Tableaux align√©s pour SIMD
type
  {$ALIGN 16}  // Alignement pour SSE
  TAlignedArray = array[0..15] of Single;
```

**Parcours optimis√© :**
```pascal
// Mauvais : calcul de High √† chaque it√©ration
for i := 0 to High(arr) do
  Process(arr[i]);

// Bon : calcul une seule fois
len := High(arr);
for i := 0 to len do
  Process(arr[i]);

// Encore mieux : pointeurs pour gros tableaux
p := @arr[0];
for i := 0 to len do
begin
  Process(p^);
  Inc(p);
end;
```

## 6. Optimisations des structures de contr√¥le {#structures}

### Optimisation des conditions

```pascal
// Ordre des conditions : du plus probable au moins probable
if (x > 0) and (x < 100) then  // Cas fr√©quent en premier
  ProcessNormal(x)
else if x = 0 then              // Cas rare
  ProcessZero
else                            // Cas tr√®s rare
  ProcessSpecial(x);

// Court-circuit bool√©en
if FastCheck and ThenSlowCheck then  // FastCheck √©valu√© d'abord
  DoSomething;

// Transformation en table de saut
case x of
  0: HandleZero;      // Compil√© en table
  1: HandleOne;       // de saut directe
  2: HandleTwo;       // plus rapide qu'une
  3: HandleThree;     // cha√Æne de if/else
else
  HandleDefault;
end;
```

### Optimisation des boucles

```pascal
// Loop hoisting : sortir les invariants
// Mauvais
for i := 0 to 999 do
  arr[i] := arr[i] * (x + y);  // x+y calcul√© 1000 fois

// Bon
temp := x + y;  // Calcul√© une fois
for i := 0 to 999 do
  arr[i] := arr[i] * temp;

// Loop fusion : combiner les boucles
// Mauvais
for i := 0 to 999 do
  a[i] := b[i] * 2;
for i := 0 to 999 do
  c[i] := a[i] + 1;

// Bon
for i := 0 to 999 do
begin
  a[i] := b[i] * 2;
  c[i] := a[i] + 1;  // Meilleure localit√© cache
end;

// Loop tiling pour le cache
// Parcours de matrice optimis√©
const TILE_SIZE = 64;
for ii := 0 to (N-1) div TILE_SIZE do
  for jj := 0 to (N-1) div TILE_SIZE do
    for i := ii*TILE_SIZE to Min((ii+1)*TILE_SIZE-1, N-1) do
      for j := jj*TILE_SIZE to Min((jj+1)*TILE_SIZE-1, N-1) do
        Process(matrix[i,j]);
```

### Optimisation des appels de fonction

```pascal
// Inline explicite pour petites fonctions
function Square(x: Integer): Integer; inline;
begin
  Result := x * x;
end;

// Passage par r√©f√©rence pour gros objets
procedure ProcessLargeData(const Data: TLargeArray);  // const = pas de copie
begin
  // Traitement...
end;

// Tail call optimization
function Factorial(n: Integer; acc: Int64 = 1): Int64;
begin
  if n <= 1 then
    Result := acc
  else
    Result := Factorial(n-1, n*acc);  // Peut √™tre optimis√© en boucle
end;
```

## 7. Optimisations m√©moire {#memoire}

### Gestion du cache processeur

```pascal
// Structure optimis√©e pour le cache
type
  // Mauvais : padding et mauvais alignement
  TBadStruct = record
    b: Byte;
    i: Integer;
    b2: Byte;
    d: Double;
  end;  // Taille : 24 octets avec padding

  // Bon : champs ordonn√©s par taille
  TGoodStruct = record
    d: Double;   // 8 octets
    i: Integer;  // 4 octets
    b: Byte;     // 1 octet
    b2: Byte;    // 1 octet
    padding: Word; // 2 octets explicites
  end;  // Taille : 16 octets, meilleur alignement
```

### Optimisation de l'allocation

```pascal
// Pool d'objets pour √©viter allocations/d√©sallocations
type
  TObjectPool = class
  private
    FPool: array of TObject;
    FAvailable: array of Boolean;
  public
    function Acquire: TObject;
    procedure Release(Obj: TObject);
  end;

// Pr√©-allocation de m√©moire
var
  List: TList;
begin
  List := TList.Create;
  List.Capacity := 10000;  // √âvite les r√©allocations
  // Ajout d'√©l√©ments...
end;
```

### Optimisation de la pile

```pascal
// Variables locales sur la pile (rapide)
procedure FastProc;
var
  localArray: array[0..99] of Integer;  // Sur la pile
begin
  // Traitement rapide
end;

// √âviter la r√©cursion profonde
// Mauvais : risque de stack overflow
function RecursiveSum(n: Integer): Int64;
begin
  if n = 0 then
    Result := 0
  else
    Result := n + RecursiveSum(n-1);
end;

// Bon : version it√©rative
function IterativeSum(n: Integer): Int64;
var
  i: Integer;
begin
  Result := 0;
  for i := 1 to n do
    Result := Result + i;
end;
```

## 8. Optimisations multi-plateformes {#multiplateforme}

### Windows : Optimisations sp√©cifiques

```pascal
{$IFDEF WINDOWS}
  {$OPTIMIZATION ON}
  {$SMARTLINK ON}

  // Utilisation de l'API Windows native
  function FastFileRead(const FileName: string): string;
  var
    Handle: THandle;
    Size: DWORD;
    Buffer: PChar;
  begin
    Handle := CreateFile(PChar(FileName), GENERIC_READ,
                        FILE_SHARE_READ, nil, OPEN_EXISTING,
                        FILE_FLAG_SEQUENTIAL_SCAN, 0);
    if Handle <> INVALID_HANDLE_VALUE then
    begin
      Size := GetFileSize(Handle, nil);
      GetMem(Buffer, Size + 1);
      ReadFile(Handle, Buffer^, Size, Size, nil);
      Buffer[Size] := #0;
      Result := string(Buffer);
      FreeMem(Buffer);
      CloseHandle(Handle);
    end;
  end;

  // Optimisation avec les fibres Windows pour la concurrence
  {$IFDEF CPU64}
    {$ASMMODE INTEL}
    // Instructions SSE4.2 pour string processing
  {$ENDIF}
{$ENDIF}
```

**Compilation optimis√©e Windows :**
```batch
rem Compilation 32 bits optimis√©e
fpc -O3 -OpPENTIUM4 -CfSSE2 -Xs -XX programme.pas

rem Compilation 64 bits optimis√©e
fpc -O3 -OpCOREAVX -CfAVX2 -Xs -XX programme.pas

rem Avec optimisations de lien
fpc -O3 -XX -CX -Xs -WG programme.pas
```

### Linux/Ubuntu : Optimisations sp√©cifiques

```pascal
{$IFDEF LINUX}
  {$OPTIMIZATION LEVEL3}
  {$LINKLIB c}

  // Utilisation de syscalls directs pour la performance
  function FastGetPID: Integer; assembler;
  asm
    {$IFDEF CPU64}
    mov rax, 39  // syscall getpid
    syscall
    {$ELSE}
    mov eax, 20  // syscall getpid (32-bit)
    int $80
    {$ENDIF}
  end;

  // Optimisation avec epoll pour I/O asynchrone
  type
    TEPollEvent = packed record
      events: UInt32;
      data: UInt64;
    end;

  function epoll_create(size: Integer): Integer; cdecl; external;
  function epoll_wait(epfd: Integer; events: PEPollEvent;
                      maxevents, timeout: Integer): Integer; cdecl; external;
{$ENDIF}
```

**Compilation optimis√©e Linux :**
```bash
# Compilation standard optimis√©e
fpc -O3 -OpCOREAVX2 -CfAVX2 -Xs -XX programme.pas

# Avec profiling guid√© (PGO)
fpc -O3 -OoProfileGuided programme.pas
./programme  # Ex√©cution pour g√©n√©rer le profil
fpc -O3 -OoUseProfile programme.pas  # Recompilation avec profil

# Optimisation maximale avec LTO
fpc -O3 -Clflto -k-flto -k-O3 programme.pas

# Strip des symboles apr√®s compilation
strip --strip-all programme
```

### D√©tection et adaptation runtime

```pascal
// D√©tection des capacit√©s CPU au runtime
{$ASMMODE INTEL}
function HasSSE42: Boolean;
var
  RegEAX, RegEBX, RegECX, RegEDX: UInt32;
begin
  asm
    push rbx
    mov eax, 1
    cpuid
    mov RegEAX, eax
    mov RegEBX, ebx
    mov RegECX, ecx
    mov RegEDX, edx
    pop rbx
  end;
  Result := (RegECX and (1 shl 20)) <> 0;  // Bit 20 = SSE4.2
end;

// S√©lection d'algorithme selon la plateforme
procedure ProcessData(const Data: array of Integer);
begin
  {$IFDEF WINDOWS}
    {$IFDEF CPU64}
    if HasAVX2 then
      ProcessDataAVX2(Data)
    else if HasSSE42 then
      ProcessDataSSE42(Data)
    else
    {$ENDIF}
      ProcessDataGeneric(Data);
  {$ELSE}
    {$IFDEF LINUX}
    // Version optimis√©e pour Linux avec vectorisation GCC
    ProcessDataLinuxOptimized(Data);
    {$ENDIF}
  {$ENDIF}
end;
```

## 9. Directives et pragmas {#directives}

### Directives globales d'optimisation

```pascal
// Dans le fichier .pas ou .lpr principal
{$MODE OBJFPC}
{$H+}  // Longstrings par d√©faut

// Optimisations globales
{$OPTIMIZATION ON}           // Active les optimisations
{$OPTIMIZATION LEVEL3}       // Niveau 3
{$OPTIMIZATION FASTMATH}     // Maths rapides
{$OPTIMIZATION REGVAR}       // Variables dans registres
{$OPTIMIZATION LOOPUNROLL}   // D√©roulement de boucles
{$OPTIMIZATION TAILREC}      // Optimisation r√©cursion terminale
{$OPTIMIZATION CSE}          // Common Subexpression Elimination
{$OPTIMIZATION DFA}          // Data Flow Analysis

// Optimisations de taille
{$OPTIMIZATION SIZE}         // Optimise pour la taille
{$DEADCODE OFF}             // √âlimine le code mort

// Smart linking et stripping
{$SMARTLINK ON}
{$STRIP ON}
```

### Directives locales et conditionnelles

```pascal
// D√©sactivation temporaire pour du code critique
{$PUSH}
{$OPTIMIZATION OFF}
procedure CriticalDebugCode;
begin
  // Code qui doit rester exactement comme √©crit
  // pour le d√©bogage ou des raisons de timing
end;
{$POP}

// Optimisation s√©lective par proc√©dure
{$PUSH}
{$OPTIMIZATION LEVEL4}
{$OPTIMIZATION FASTMATH}
function HeavyComputation(x: Double): Double;
begin
  // Calcul intensif avec optimisations maximales
  Result := Sin(x) * Cos(x) + Exp(x);
end;
{$POP}

// Directives conditionnelles selon la plateforme
{$IFDEF CPUX64}
  {$OPTIMIZATION LEVEL3}
  {$DEFINE USE_SSE42}
{$ELSE}
  {$OPTIMIZATION LEVEL2}
{$ENDIF}

// Directives pour le mode release
{$IFDEF RELEASE}
  {$OPTIMIZATION ON}
  {$DEBUGINFO OFF}
  {$STACKFRAMES OFF}
  {$ASSERTIONS OFF}
  {$RANGECHECKS OFF}
  {$OVERFLOWCHECKS OFF}
  {$IOCHECKS OFF}
{$ENDIF}
```

### Directives de code inline

```pascal
// Forcer l'inline
{$INLINE ON}
function AlwaysInline(x: Integer): Integer; inline;
begin
  Result := x * 2;
end;

// Inline automatique selon la taille
{$OPTIMIZATION AUTOINLINE}
{$MAXINLINESIZE 32}  // Fonctions <= 32 octets inline automatiquement

// D√©sactiver l'inline pour certaines fonctions
{$PUSH}
{$INLINE OFF}
function NeverInline(x: Integer): Integer;
begin
  // Fonction complexe qui ne doit pas √™tre inline
  Result := ComplexCalculation(x);
end;
{$POP}
```

### Directives d'alignement m√©moire

```pascal
// Alignement pour optimiser l'acc√®s m√©moire
{$ALIGN 16}  // Aligne les donn√©es sur 16 octets (pour SSE)
type
  TVector = record
    x, y, z, w: Single;
  end;

{$PACKRECORDS C}  // Compatible C, sans padding
type
  TPackedData = packed record
    Flag: Byte;
    Value: Word;
    Data: Integer;
  end;

{$PACKRECORDS 8}  // Aligne sur 8 octets
type
  TAlignedData = record
    Field1: Integer;
    Field2: Double;
  end;

// Alignement de tableaux pour SIMD
{$CODEALIGN VARMIN=16}
var
  AlignedArray: array[0..63] of Single;  // Align√© pour SSE/AVX
```

## 10. Optimisations manuelles compl√©mentaires {#manuelles}

### Techniques de programmation optimis√©e

```pascal
// 1. Pr√©-calcul et m√©mo√Øzation
type
  TMemoizedFunc = class
  private
    FCache: TDictionary<Integer, Integer>;
  public
    function Calculate(n: Integer): Integer;
  end;

function TMemoizedFunc.Calculate(n: Integer): Integer;
begin
  if not FCache.TryGetValue(n, Result) then
  begin
    Result := ExpensiveCalculation(n);
    FCache.Add(n, Result);
  end;
end;

// 2. Tables de lookup
const
  SinTable: array[0..359] of Single = (
    // Pr√©-calculer les valeurs de sinus
    0.0000, 0.0175, 0.0349, // ... etc
  );

function FastSin(degrees: Integer): Single; inline;
begin
  Result := SinTable[degrees mod 360];
end;

// 3. Bit twiddling hacks
function IsPowerOfTwo(x: Cardinal): Boolean; inline;
begin
  Result := (x <> 0) and ((x and (x - 1)) = 0);
end;

function CountBits(x: Cardinal): Integer;
begin
  x := x - ((x shr 1) and $55555555);
  x := (x and $33333333) + ((x shr 2) and $33333333);
  Result := (((x + (x shr 4)) and $0F0F0F0F) * $01010101) shr 24;
end;

// 4. √âviter les allocations dynamiques
var
  GlobalBuffer: array[0..1023] of Byte;  // Buffer r√©utilisable

procedure ProcessWithStaticBuffer;
begin
  // Utilise GlobalBuffer au lieu d'allouer dynamiquement
  FillChar(GlobalBuffer, SizeOf(GlobalBuffer), 0);
  // Traitement...
end;
```

### Optimisations algorithmiques

```pascal
// Choisir le bon algorithme est plus important que l'optimisation
// Exemple : Recherche

// O(n) - Recherche lin√©aire
function LinearSearch(const arr: array of Integer; value: Integer): Integer;
var
  i: Integer;
begin
  for i := 0 to High(arr) do
    if arr[i] = value then
      Exit(i);
  Result := -1;
end;

// O(log n) - Recherche binaire (tableau tri√©)
function BinarySearch(const arr: array of Integer; value: Integer): Integer;
var
  low, high, mid: Integer;
begin
  low := 0;
  high := High(arr);
  while low <= high do
  begin
    mid := (low + high) shr 1;  // Division par 2 optimis√©e
    if arr[mid] = value then
      Exit(mid)
    else if arr[mid] < value then
      low := mid + 1
    else
      high := mid - 1;
  end;
  Result := -1;
end;

// O(1) - Table de hachage
function HashSearch(const table: TDictionary<Integer, Integer>;
                   value: Integer): Integer;
begin
  if not table.TryGetValue(value, Result) then
    Result := -1;
end;
```

### Optimisations assembleur inline

```pascal
{$ASMMODE INTEL}

// Copie de m√©moire optimis√©e avec SSE
procedure FastMemCopy(Dest, Source: Pointer; Size: NativeInt);
asm
  {$IFDEF CPUX64}
  // Version 64 bits avec instructions AVX si disponible
  .align 16
  cmp rcx, 128
  jb @SmallCopy

  // Copie par blocs de 128 octets avec prefetch
  @LargeCopy:
    prefetchnta [rsi + 256]
    movdqa xmm0, [rsi]
    movdqa xmm1, [rsi + 16]
    movdqa xmm2, [rsi + 32]
    movdqa xmm3, [rsi + 48]
    movntdq [rdi], xmm0
    movntdq [rdi + 16], xmm1
    movntdq [rdi + 32], xmm2
    movntdq [rdi + 48], xmm3
    add rsi, 64
    add rdi, 64
    sub rcx, 64
    cmp rcx, 64
    jae @LargeCopy

  @SmallCopy:
    // Copie byte par byte pour le reste
    rep movsb
  {$ELSE}
    // Version 32 bits standard
    push esi
    push edi
    mov esi, Source
    mov edi, Dest
    mov ecx, Size
    rep movsb
    pop edi
    pop esi
  {$ENDIF}
end;

// Calcul de checksum optimis√©
function FastChecksum(Data: PByte; Size: Integer): Cardinal;
asm
  {$IFDEF CPUX64}
    xor rax, rax
    xor r8, r8
  @Loop:
    movzx r8, byte ptr [rcx]
    add rax, r8
    inc rcx
    dec rdx
    jnz @Loop
  {$ELSE}
    push ebx
    xor eax, eax
    xor ebx, ebx
  @Loop:
    movzx ebx, byte ptr [ecx]
    add eax, ebx
    inc ecx
    dec edx
    jnz @Loop
    pop ebx
  {$ENDIF}
end;
```

## 11. Profiling et analyse {#profiling}

### Outils de profiling int√©gr√©s

```pascal
// Utilisation du profiler int√©gr√© FPC
// Compilation avec support profiling
// fpc -pg programme.pas

uses
  SysUtils, DateUtils;

type
  TProfiler = class
  private
    FStartTime: TDateTime;
    FName: string;
  public
    constructor Create(const AName: string);
    destructor Destroy; override;
  end;

constructor TProfiler.Create(const AName: string);
begin
  FName := AName;
  FStartTime := Now;
  WriteLn(Format('Profiling %s started', [FName]));
end;

destructor TProfiler.Destroy;
var
  ElapsedMS: Int64;
begin
  ElapsedMS := MilliSecondsBetween(Now, FStartTime);
  WriteLn(Format('Profiling %s: %d ms', [FName, ElapsedMS]));
  inherited;
end;

// Utilisation
procedure TestFunction;
var
  Prof: TProfiler;
begin
  Prof := TProfiler.Create('TestFunction');
  try
    // Code √† profiler
    Sleep(100);
  finally
    Prof.Free;
  end;
end;
```

### Profiling Windows

```pascal
{$IFDEF WINDOWS}
uses Windows;

function GetHighPrecisionTime: Int64;
begin
  QueryPerformanceCounter(Result);
end;

function GetHighPrecisionFrequency: Int64;
begin
  QueryPerformanceFrequency(Result);
end;

procedure ProfileCode(const Name: string; Proc: TProcedure);
var
  Start, Stop, Freq: Int64;
  ElapsedMS: Double;
begin
  Start := GetHighPrecisionTime;
  Proc;
  Stop := GetHighPrecisionTime;
  Freq := GetHighPrecisionFrequency;
  ElapsedMS := (Stop - Start) * 1000.0 / Freq;
  WriteLn(Format('%s: %.3f ms', [Name, ElapsedMS]));
end;
{$ENDIF}
```

**Outils externes Windows :**
```batch
rem Intel VTune Profiler
amplxe-cl -collect hotspots programme.exe

rem Very Sleepy (gratuit)
sleepy programme.exe

rem Windows Performance Toolkit
wpr -start CPU
programme.exe
wpr -stop output.etl
```

### Profiling Linux/Ubuntu

```pascal
{$IFDEF LINUX}
uses BaseUnix, Unix;

function GetCPUTime: Double;
var
  usage: TRUsage;
begin
  FpGetRUsage(RUSAGE_SELF, @usage);
  Result := usage.ru_utime.tv_sec + usage.ru_utime.tv_usec / 1000000.0;
end;

procedure ProfileMemory;
var
  status: Text;
  line: string;
  vmSize, vmRSS: Integer;
begin
  Assign(status, '/proc/self/status');
  Reset(status);
  while not Eof(status) do
  begin
    ReadLn(status, line);
    if Pos('VmSize:', line) = 1 then
      vmSize := StrToInt(Trim(Copy(line, 8, Pos('kB', line) - 8)))
    else if Pos('VmRSS:', line) = 1 then
      vmRSS := StrToInt(Trim(Copy(line, 7, Pos('kB', line) - 7)));
  end;
  Close(status);
  WriteLn(Format('Memory - Virtual: %d KB, Resident: %d KB', [vmSize, vmRSS]));
end;
{$ENDIF}
```

**Outils externes Linux :**
```bash
# Valgrind avec Callgrind
valgrind --tool=callgrind ./programme
kcachegrind callgrind.out.*

# Perf
perf record -g ./programme
perf report

# Gprof
fpc -pg programme.pas
./programme
gprof programme gmon.out > analysis.txt

# SystemTap pour profiling d√©taill√©
stap -e 'probe process("programme").function("*") {
  printf("%s called\n", probefunc())
}' -c ./programme
```

### Analyse de la consommation m√©moire

```pascal
// Tracker d'allocations m√©moire personnalis√©
unit MemoryTracker;

interface

var
  TotalAllocated: Int64 = 0;
  TotalFreed: Int64 = 0;
  CurrentUsage: Int64 = 0;
  PeakUsage: Int64 = 0;

implementation

uses heaptrc;

var
  OldMemMgr: TMemoryManager;

function TrackedGetMem(Size: PtrUInt): Pointer;
begin
  Result := OldMemMgr.GetMem(Size);
  if Result <> nil then
  begin
    Inc(TotalAllocated, Size);
    Inc(CurrentUsage, Size);
    if CurrentUsage > PeakUsage then
      PeakUsage := CurrentUsage;
  end;
end;

function TrackedFreeMem(p: Pointer): PtrUInt;
begin
  Result := OldMemMgr.FreeMem(p);
  Inc(TotalFreed, Result);
  Dec(CurrentUsage, Result);
end;

function TrackedReallocMem(var p: Pointer; Size: PtrUInt): Pointer;
var
  OldSize: PtrUInt;
begin
  OldSize := MemSize(p);
  Result := OldMemMgr.ReallocMem(p, Size);
  if Result <> nil then
  begin
    Dec(CurrentUsage, OldSize);
    Inc(CurrentUsage, Size);
    if CurrentUsage > PeakUsage then
      PeakUsage := CurrentUsage;
  end;
end;

initialization
  GetMemoryManager(OldMemMgr);
  SetMemoryManager(
    TrackedGetMem,
    TrackedFreeMem,
    TrackedReallocMem,
    nil, nil
  );

finalization
  SetMemoryManager(OldMemMgr);
  WriteLn('Memory Stats:');
  WriteLn('  Total Allocated: ', TotalAllocated, ' bytes');
  WriteLn('  Total Freed: ', TotalFreed, ' bytes');
  WriteLn('  Peak Usage: ', PeakUsage, ' bytes');
  WriteLn('  Leaks: ', TotalAllocated - TotalFreed, ' bytes');
end.
```

## 12. Cas pratiques et exemples {#pratiques}

### Exemple 1 : Optimisation d'un traitement d'image

```pascal
// Version non optimis√©e
procedure ProcessImageSlow(var Img: TBitmap);
var
  x, y: Integer;
  pixel: TColor;
begin
  for y := 0 to Img.Height - 1 do
    for x := 0 to Img.Width - 1 do
    begin
      pixel := Img.Canvas.Pixels[x, y];  // Tr√®s lent!
      pixel := ProcessPixel(pixel);
      Img.Canvas.Pixels[x, y] := pixel;
    end;
end;

// Version optimis√©e
procedure ProcessImageFast(var Img: TBitmap);
type
  TRGBTriple = packed record
    B, G, R: Byte;
  end;
  PRGBTriple = ^TRGBTriple;
var
  y: Integer;
  Row: PRGBTriple;
  x: Integer;
begin
  Img.PixelFormat := pf24bit;  // Format direct

  for y := 0 to Img.Height - 1 do
  begin
    Row := Img.ScanLine[y];  // Acc√®s direct √† la ligne

    // Traitement optimis√© par ligne
    for x := 0 to Img.Width - 1 do
    begin
      // Manipulation directe des bytes
      Row^.R := 255 - Row^.R;  // Inversion exemple
      Row^.G := 255 - Row^.G;
      Row^.B := 255 - Row^.B;
      Inc(Row);
    end;
  end;
end;

// Version SIMD pour encore plus de performance
procedure ProcessImageSIMD(var Img: TBitmap);
asm
  // Code assembleur SSE/AVX pour traiter
  // plusieurs pixels simultan√©ment
end;
```

### Exemple 2 : Optimisation d'un parseur JSON

```pascal
// Version basique
function ParseJSONSlow(const Text: string): TJSONObject;
var
  i: Integer;
  current: Char;
begin
  Result := TJSONObject.Create;
  i := 1;
  while i <= Length(Text) do
  begin
    current := Text[i];  // Acc√®s caract√®re par caract√®re
    case current of
      '{': ParseObject;
      '[': ParseArray;
      '"': ParseString;
      // etc...
    end;
    Inc(i);
  end;
end;

// Version optimis√©e
function ParseJSONFast(const Text: string): TJSONObject;
var
  p, pEnd: PChar;

  procedure SkipWhitespace; inline;
  begin
    while (p <= pEnd) and (p^ in [' ', #9, #10, #13]) do
      Inc(p);
  end;

  function ParseValue: TJSONValue;
  begin
    SkipWhitespace;
    case p^ of
      '{': Result := ParseObject;
      '[': Result := ParseArray;
      '"': Result := ParseString;
      '0'..'9', '-': Result := ParseNumber;
      't', 'f': Result := ParseBoolean;
      'n': Result := ParseNull;
    else
      raise Exception.Create('Invalid JSON');
    end;
  end;

begin
  p := PChar(Text);
  pEnd := p + Length(Text) - 1;
  Result := ParseValue as TJSONObject;
end;
```

### Exemple 3 : Optimisation d'un algorithme de tri

```pascal
// Quicksort optimis√© avec plusieurs techniques
procedure OptimizedQuickSort(var A: array of Integer);
const
  INSERTION_SORT_THRESHOLD = 16;  // Seuil pour insertion sort

  procedure InsertionSort(L, R: Integer); inline;
  var
    i, j, temp: Integer;
  begin
    for i := L + 1 to R do
    begin
      temp := A[i];
      j := i - 1;
      while (j >= L) and (A[j] > temp) do
      begin
        A[j + 1] := A[j];
        Dec(j);
      end;
      A[j + 1] := temp;
    end;
  end;

  procedure QuickSortInternal(L, R: Integer);
  var
    i, j, pivot: Integer;
  begin
    // Pour petits tableaux, insertion sort est plus rapide
    if R - L < INSERTION_SORT_THRESHOLD then
    begin
      InsertionSort(L, R);
      Exit;
    end;

    // M√©diane de trois pour meilleur pivot
    i := L;
    j := R;
    pivot := A[(L + R) shr 1];  // Division par 2 optimis√©e

    // Partitionnement optimis√©
    repeat
      while A[i] < pivot do Inc(i);
      while A[j] > pivot do Dec(j);
      if i <= j then
      begin
        if i < j then
        begin
          // Swap optimis√© avec XOR (pour entiers)
          A[i] := A[i] xor A[j];
          A[j] := A[i] xor A[j];
          A[i] := A[i] xor A[j];
        end;
        Inc(i);
        Dec(j);
      end;
    until i > j;

    // R√©cursion sur la plus petite partition d'abord (tail call optimization)
    if j - L < R - i then
    begin
      if L < j then QuickSortInternal(L, j);
      if i < R then QuickSortInternal(i, R);
    end
    else
    begin
      if i < R then QuickSortInternal(i, R);
      if L < j then QuickSortInternal(L, j);
    end;
  end;

begin
  if Length(A) > 1 then
    QuickSortInternal(0, High(A));
end;
```

### Exemple 4 : Serveur TCP haute performance

```pascal
// Serveur optimis√© avec pool de threads et buffers r√©utilisables
type
  TOptimizedTCPServer = class
  private
    FListenSocket: TSocket;
    FThreadPool: array[0..15] of TThread;  // Pool fixe
    FBufferPool: TStack<PByteArray>;       // Buffers r√©utilisables
    FEpoll: Integer;  // Linux epoll pour I/O asynchrone

  public
    procedure Start;
  end;

procedure TOptimizedTCPServer.HandleClient(Socket: TSocket);
var
  Buffer: PByteArray;
  BytesRead: Integer;
begin
  // R√©cup√®re un buffer du pool au lieu d'allouer
  Buffer := FBufferPool.Pop;
  if Buffer = nil then
    GetMem(Buffer, 65536);

  try
    // Lecture non-bloquante optimis√©e
    BytesRead := recv(Socket, Buffer^, 65536, MSG_DONTWAIT);

    // Traitement avec zero-copy si possible
    ProcessData(Buffer, BytesRead);

  finally
    // Remet le buffer dans le pool au lieu de lib√©rer
    if FBufferPool.Count < 100 then
      FBufferPool.Push(Buffer)
    else
      FreeMem(Buffer);
  end;
end;
```

## 13. D√©pannage et r√©solution de probl√®mes {#depannage}

### Probl√®mes courants avec les optimisations

#### 1. Code qui fonctionne en debug mais pas en release

```pascal
// Probl√®me : variable non initialis√©e
procedure Problematic;
var
  x: Integer;  // Non initialis√©!
begin
  // En debug (O0), x pourrait √™tre 0 par chance
  // En release (O2+), x contient n'importe quoi
  if x > 0 then
    DoSomething;
end;

// Solution : toujours initialiser
procedure Fixed;
var
  x: Integer;
begin
  x := 0;  // Initialisation explicite
  if x > 0 then
    DoSomething;
end;
```

#### 2. Probl√®mes de pr√©cision en virgule flottante

```pascal
// Probl√®me avec -Oofastmath
function CompareFloats(a, b: Double): Boolean;
begin
  Result := a = b;  // Dangereux avec fastmath!
end;

// Solution : comparaison avec epsilon
function CompareFloatsSafe(a, b: Double): Boolean;
const
  EPSILON = 1E-9;
begin
  Result := Abs(a - b) < EPSILON;
end;
```

#### 3. Optimisations qui cassent le timing

```pascal
// Code sensible au timing
procedure DelayLoop;
var
  i: Integer;
begin
  for i := 0 to 1000000 do
    ;  // Boucle vide - sera supprim√©e par l'optimiseur!
end;

// Solution : utiliser les bonnes m√©thodes
procedure ProperDelay;
begin
  {$OPTIMIZATION OFF}
  // Ou utiliser Sleep/Delay du syst√®me
  Sleep(10);  // Windows/Linux
  {$OPTIMIZATION DEFAULT}
end;
```

#### 4. Probl√®mes avec l'ordre d'√©valuation

```pascal
// Code d√©pendant de l'ordre d'√©valuation des param√®tres
function DangerousCode: Integer;
var
  x: Integer;

  function NextValue: Integer;
  begin
    Inc(x);
    Result := x;
  end;

begin
  x := 0;
  Result := NextValue + NextValue;  // Ordre non garanti !
  // Peut donner 3 ou 4 selon l'optimisation
end;

// Solution : s√©parer les effets de bord
function SafeCode: Integer;
var
  x, temp1, temp2: Integer;
begin
  x := 0;
  Inc(x);
  temp1 := x;
  Inc(x);
  temp2 := x;
  Result := temp1 + temp2;  // Toujours 3
end;
```

### Techniques de d√©bogage avec optimisations

```pascal
// 1. Logging conditionnel
{$IFDEF DEBUG_OPTIMIZATION}
procedure LogOptimization(const Msg: string);
begin
  WriteLn('[OPT] ', Msg);
end;
{$ELSE}
procedure LogOptimization(const Msg: string); inline;
begin
  // Vide en release - sera √©limin√©
end;
{$ENDIF}

// 2. Assertions pour v√©rifier les invariants
procedure OptimizedFunction(x: Integer);
begin
  {$ASSERTIONS ON}
  Assert(x >= 0, 'x must be non-negative');
  {$ASSERTIONS OFF}

  // Code optimis√©...
end;

// 3. Marqueurs pour emp√™cher l'optimisation
procedure KeepVariable(var x);
begin
  // Force le compilateur √† garder la variable
end;

procedure TestWithMarker;
var
  importantVar: Integer;
begin
  importantVar := CalculateSomething;
  KeepVariable(importantVar);  // Emp√™che l'√©limination
  // Debug ici...
end;
```

### Analyse des probl√®mes de performance

```pascal
// Identificateur de bottlenecks
type
  TPerformanceMonitor = class
  private
    FSections: TDictionary<string, Int64>;
    FCurrent: string;
    FStart: Int64;
  public
    procedure BeginSection(const Name: string);
    procedure EndSection;
    procedure Report;
  end;

procedure TPerformanceMonitor.BeginSection(const Name: string);
begin
  FCurrent := Name;
  FStart := GetTickCount64;
end;

procedure TPerformanceMonitor.EndSection;
var
  elapsed: Int64;
begin
  elapsed := GetTickCount64 - FStart;
  if FSections.ContainsKey(FCurrent) then
    FSections[FCurrent] := FSections[FCurrent] + elapsed
  else
    FSections.Add(FCurrent, elapsed);
end;

procedure TPerformanceMonitor.Report;
var
  pair: TPair<string, Int64>;
  total: Int64;
begin
  total := 0;
  for pair in FSections do
    Inc(total, pair.Value);

  WriteLn('Performance Report:');
  for pair in FSections do
    WriteLn(Format('  %s: %d ms (%.1f%%)',
      [pair.Key, pair.Value, pair.Value * 100.0 / total]));
end;
```

## Conclusion et recommandations finales

### Strat√©gie d'optimisation recommand√©e

1. **Phase de d√©veloppement**
   - Utilisez `-O0` ou `-O1` avec tous les checks activ√©s
   - Concentrez-vous sur la correction du code
   - Profilez pour identifier les vrais bottlenecks

2. **Phase de test**
   - Passez progressivement √† `-O2`
   - Testez exhaustivement chaque niveau
   - Gardez les assertions actives

3. **Phase de production**
   - Utilisez `-O2` par d√©faut (meilleur compromis)
   - `-O3` uniquement pour le code critique identifi√©
   - `-Os` pour les syst√®mes embarqu√©s

4. **Optimisation continue**
   - Mesurez toujours avant et apr√®s
   - N'optimisez que ce qui est n√©cessaire
   - Documentez les optimisations non √©videntes

### Checklist d'optimisation

- [ ] Code fonctionne correctement sans optimisation
- [ ] Profiling effectu√© pour identifier les bottlenecks
- [ ] Algorithmes appropri√©s choisis
- [ ] Structures de donn√©es optimales utilis√©es
- [ ] Tests de non-r√©gression en place
- [ ] Documentation des optimisations critiques
- [ ] Benchmarks avant/apr√®s disponibles
- [ ] Tests sur toutes les plateformes cibles
- [ ] Options de compilation document√©es
- [ ] Mode debug facilement activable

### Ressources pour approfondir

1. **Documentation officielle**
   - [FreePascal Compiler Options](https://www.freepascal.org/docs-html/prog/progch5.html)
   - [Optimization Guide](https://wiki.freepascal.org/Optimization)

2. **Outils recommand√©s**
   - Valgrind (Linux) - Profiling et d√©tection de fuites
   - Intel VTune (Windows/Linux) - Profiling avanc√©
   - Lazarus Profiler - Int√©gr√© √† l'IDE
   - FPProfiler - Sp√©cifique FreePascal

3. **Livres et articles**
   - "Computer Systems: A Programmer's Perspective"
   - "The Art of Computer Programming" - Knuth
   - "Optimizing software in C++" - Agner Fog (concepts applicables)

4. **Communaut√©**
   - Forum FreePascal : https://forum.lazarus.freepascal.org
   - Stack Overflow tags : [freepascal] [lazarus]
   - IRC : #fpc et #lazarus sur Libera.Chat

### Tableaux de r√©f√©rence rapide

#### Options de compilation essentielles

| Option | Description | Usage |
|--------|-------------|-------|
| `-O0` | Aucune optimisation | D√©bogage |
| `-O1` | Optimisations basiques | D√©veloppement |
| `-O2` | Optimisations standard | Production |
| `-O3` | Optimisations agressives | Code critique |
| `-Os` | Optimiser la taille | Embarqu√© |
| `-Oo<x>` | Optimisation sp√©cifique | Cas particuliers |
| `-XX` | Smart linking | R√©duction taille |
| `-CX` | Recr√©e tables d'import | Windows |
| `-Xs` | Strip symboles | Release final |
| `-al` | G√©n√®re assembleur | Analyse |
| `-pg` | Support profiling | Mesures performance |

#### Directives d'optimisation dans le code

| Directive | Effet |
|-----------|-------|
| `{$OPTIMIZATION ON/OFF}` | Active/d√©sactive optimisations |
| `{$OPTIMIZATION LEVEL0..4}` | D√©finit le niveau |
| `{$OPTIMIZATION SIZE}` | Optimise pour la taille |
| `{$OPTIMIZATION FASTMATH}` | Maths non-IEEE |
| `{$OPTIMIZATION REGVAR}` | Variables dans registres |
| `{$OPTIMIZATION LOOPUNROLL}` | D√©roulement boucles |
| `{$OPTIMIZATION CSE}` | √âlimination sous-expressions |
| `{$OPTIMIZATION DFA}` | Analyse flux donn√©es |
| `{$OPTIMIZATION AUTOINLINE}` | Inline automatique |
| `{$INLINE ON/OFF}` | Contr√¥le inline |
| `{$SMARTLINK ON/OFF}` | Smart linking |

#### Comparaison Windows vs Linux

| Aspect | Windows | Linux/Ubuntu |
|--------|---------|--------------|
| Compilateur | fpc.exe | fpc |
| Format ex√©cutable | .exe | ELF |
| Symboles debug | .pdb (avec -gw) | DWARF dans binaire |
| Strip symboles | Via options | strip command |
| Profiling | VTune, PerfView | perf, valgrind |
| Assembleur | MASM/NASM syntax | AT&T/Intel syntax |
| Linking | link.exe/ld | ld/gold/lld |
| Biblioth√®ques | .dll | .so |
| Optimisation LTO | Support√© | Mieux support√© |
| SIMD | SSE/AVX | SSE/AVX/NEON(ARM) |

### Exemples de scripts de compilation

#### Script Windows (build.bat)

```batch
@echo off
setlocal EnableDelayedExpansion

rem Configuration
set PROJECT=MonProjet
set FPC=fpc

rem Mode Debug
if "%1"=="debug" (
    echo Building DEBUG version...
    %FPC% -O0 -g -gh -gl -Ci -Co -Ct -Cr -Sa -vewh %PROJECT%.pas
    if !errorlevel! neq 0 goto error
    echo Debug build successful!
    goto end
)

rem Mode Release
if "%1"=="release" (
    echo Building RELEASE version...
    %FPC% -O3 -XX -CX -Xs -v0 %PROJECT%.pas
    if !errorlevel! neq 0 goto error

    echo Optimizing size...
    upx --best %PROJECT%.exe 2>nul

    echo Release build successful!
    echo Size:
    dir %PROJECT%.exe | find ".exe"
    goto end
)

rem Mode Profile
if "%1"=="profile" (
    echo Building PROFILE version...
    %FPC% -O2 -pg %PROJECT%.pas
    if !errorlevel! neq 0 goto error
    echo Profile build successful!
    echo Run the program then use: gprof %PROJECT%.exe gmon.out
    goto end
)

echo Usage: build.bat [debug^|release^|profile]
goto end

:error
echo Build failed with error %errorlevel%
exit /b 1

:end
endlocal
```

#### Script Linux/Ubuntu (build.sh)

```bash
#!/bin/bash

PROJECT="MonProjet"
FPC="fpc"

# D√©tection architecture
ARCH=$(uname -m)
case $ARCH in
    x86_64)
        CPU_OPT="-CpCOREAVX"
        ;;
    aarch64)
        CPU_OPT="-CpARMV8"
        ;;
    *)
        CPU_OPT=""
        ;;
esac

# Couleurs pour output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

function build_debug {
    echo -e "${YELLOW}Building DEBUG version...${NC}"
    $FPC -O0 -g -gh -gl -Ci -Co -Ct -Cr -Sa -vewh $PROJECT.pas
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Debug build successful!${NC}"
    else
        echo -e "${RED}Build failed!${NC}"
        exit 1
    fi
}

function build_release {
    echo -e "${YELLOW}Building RELEASE version...${NC}"
    $FPC -O3 $CPU_OPT -XX -CX -Xs -v0 $PROJECT.pas
    if [ $? -eq 0 ]; then
        strip --strip-all $PROJECT

        # Compression UPX si disponible
        if command -v upx &> /dev/null; then
            upx --best $PROJECT 2>/dev/null
        fi

        echo -e "${GREEN}Release build successful!${NC}"
        echo "Size: $(du -h $PROJECT | cut -f1)"

        # Afficher les d√©pendances
        echo "Dependencies:"
        ldd $PROJECT
    else
        echo -e "${RED}Build failed!${NC}"
        exit 1
    fi
}

function build_profile {
    echo -e "${YELLOW}Building PROFILE version...${NC}"
    $FPC -O2 -pg $PROJECT.pas
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Profile build successful!${NC}"
        echo "Run: ./$PROJECT"
        echo "Then: gprof $PROJECT gmon.out > analysis.txt"
    else
        echo -e "${RED}Build failed!${NC}"
        exit 1
    fi
}

function build_crosswin {
    echo -e "${YELLOW}Cross-compiling for Windows...${NC}"
    if [ ! -f /usr/bin/ppcrossx64 ]; then
        echo -e "${RED}Cross compiler not found!${NC}"
        echo "Install with: sudo apt install fpc-crosswin64"
        exit 1
    fi

    ppcrossx64 -O2 -XX -Xs $PROJECT.pas
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Windows build successful!${NC}"
        echo "Output: ${PROJECT}.exe"
    else
        echo -e "${RED}Build failed!${NC}"
        exit 1
    fi
}

# Menu principal
case "$1" in
    debug)
        build_debug
        ;;
    release)
        build_release
        ;;
    profile)
        build_profile
        ;;
    crosswin)
        build_crosswin
        ;;
    clean)
        echo "Cleaning..."
        rm -f *.o *.ppu *.rst $PROJECT
        rm -f *.exe gmon.out
        echo "Clean complete!"
        ;;
    *)
        echo "Usage: $0 {debug|release|profile|crosswin|clean}"
        exit 1
        ;;
esac
```

### Configuration Lazarus pour optimisations

#### Fichier de configuration projet (.lpi)

```xml
<?xml version="1.0" encoding="UTF-8"?>
<CONFIG>
  <ProjectOptions>
    <Version Value="12"/>
    <General>
      <Flags>
        <MainUnitHasCreateFormStatements Value="False"/>
        <MainUnitHasTitleStatement Value="False"/>
      </Flags>
    </General>
    <BuildModes Count="3">

      <!-- Mode Debug -->
      <Item1 Name="Debug" Default="True"/>
      <BuildModes>
        <Item Name="Debug">
          <CompilerOptions>
            <Optimizations>
              <OptimizationLevel Value="0"/>
            </Optimizations>
            <Debugging>
              <DebugInfoType Value="dwarf2"/>
              <UseHeaptrc Value="True"/>
              <TrashVariables Value="True"/>
              <UseValgrind Value="True"/>
            </Debugging>
            <Checks>
              <IOChecks Value="True"/>
              <RangeChecks Value="True"/>
              <OverflowChecks Value="True"/>
              <StackChecks Value="True"/>
            </Checks>
          </CompilerOptions>
        </Item>
      </BuildModes>

      <!-- Mode Release -->
      <Item2 Name="Release"/>
      <BuildModes>
        <Item Name="Release">
          <CompilerOptions>
            <Optimizations>
              <OptimizationLevel Value="3"/>
              <VariablesInRegisters Value="True"/>
              <UncertainOptimizations Value="True"/>
            </Optimizations>
            <CodeGeneration>
              <SmartLinkUnit Value="True"/>
              <TargetProcessor Value="COREAVX2"/>
              <Optimizations>
                <OptimizationLevel Value="3"/>
                <LoopUnrollCount Value="4"/>
              </Optimizations>
            </CodeGeneration>
            <Linking>
              <Debugging>
                <GenerateDebugInfo Value="False"/>
                <StripSymbols Value="True"/>
              </Debugging>
              <LinkSmart Value="True"/>
            </Linking>
            <Other>
              <CustomOptions Value="-XX -CX -Xs"/>
            </Other>
          </CompilerOptions>
        </Item>
      </BuildModes>

      <!-- Mode Profiling -->
      <Item3 Name="Profile"/>
      <BuildModes>
        <Item Name="Profile">
          <CompilerOptions>
            <Optimizations>
              <OptimizationLevel Value="2"/>
            </Optimizations>
            <Debugging>
              <GenerateDebugInfo Value="True"/>
              <DebugInfoType Value="dwarf2"/>
            </Debugging>
            <Other>
              <CustomOptions Value="-pg"/>
            </Other>
          </CompilerOptions>
        </Item>
      </BuildModes>

    </BuildModes>
  </ProjectOptions>
</CONFIG>
```

### Benchmarks comparatifs

#### Programme de benchmark type

```pascal
program OptimizationBenchmark;

uses
  SysUtils, DateUtils, Math;

type
  TBenchmark = record
    Name: string;
    Time: Int64;
  end;

var
  Benchmarks: array of TBenchmark;

procedure AddBenchmark(const AName: string; ATime: Int64);
var
  idx: Integer;
begin
  idx := Length(Benchmarks);
  SetLength(Benchmarks, idx + 1);
  Benchmarks[idx].Name := AName;
  Benchmarks[idx].Time := ATime;
end;

// Test 1 : Calculs math√©matiques intensifs
procedure BenchmarkMath;
var
  Start: TDateTime;
  i: Integer;
  x, result: Double;
begin
  Start := Now;
  result := 0;

  for i := 1 to 10000000 do
  begin
    x := i * 0.1;
    result := result + Sin(x) * Cos(x) + Sqrt(Abs(x));
  end;

  AddBenchmark('Math Operations', MilliSecondsBetween(Now, Start));
  WriteLn('Math result: ', result:0:2);
end;

// Test 2 : Manipulation de cha√Ænes
procedure BenchmarkStrings;
var
  Start: TDateTime;
  i: Integer;
  s: string;
begin
  Start := Now;
  s := '';

  for i := 1 to 100000 do
  begin
    s := IntToStr(i) + ' ';
    if Length(s) > 1000 then
      s := '';
  end;

  AddBenchmark('String Operations', MilliSecondsBetween(Now, Start));
end;

// Test 3 : Acc√®s m√©moire et tableaux
procedure BenchmarkArrays;
const
  SIZE = 1000000;
var
  Start: TDateTime;
  arr: array of Integer;
  i, j, sum: Integer;
begin
  Start := Now;
  SetLength(arr, SIZE);

  // Remplissage
  for i := 0 to SIZE - 1 do
    arr[i] := Random(1000);

  // Tri (bubble sort pour tester)
  for i := 0 to Min(1000, SIZE - 2) do
    for j := 0 to SIZE - 2 - i do
      if arr[j] > arr[j + 1] then
      begin
        sum := arr[j];
        arr[j] := arr[j + 1];
        arr[j + 1] := sum;
      end;

  AddBenchmark('Array Operations', MilliSecondsBetween(Now, Start));
end;

// Test 4 : R√©cursion
function Fibonacci(n: Integer): Int64;
begin
  if n <= 1 then
    Result := n
  else
    Result := Fibonacci(n - 1) + Fibonacci(n - 2);
end;

procedure BenchmarkRecursion;
var
  Start: TDateTime;
  result: Int64;
begin
  Start := Now;
  result := Fibonacci(40);
  AddBenchmark('Recursion (Fib 40)', MilliSecondsBetween(Now, Start));
  WriteLn('Fibonacci(40) = ', result);
end;

// Affichage des r√©sultats
procedure ShowResults;
var
  i: Integer;
  Total: Int64;
begin
  WriteLn;
  WriteLn('=== Benchmark Results ===');
  WriteLn('Compiler: FreePascal ', {$I %FPCVERSION%});
  WriteLn('Target: ', {$I %FPCTARGETOS%});
  WriteLn('CPU: ', {$I %FPCTARGETCPU%});

  {$IFDEF O0}
  WriteLn('Optimization: -O0 (None)');
  {$ENDIF}
  {$IFDEF O1}
  WriteLn('Optimization: -O1 (Basic)');
  {$ENDIF}
  {$IFDEF O2}
  WriteLn('Optimization: -O2 (Standard)');
  {$ENDIF}
  {$IFDEF O3}
  WriteLn('Optimization: -O3 (Aggressive)');
  {$ENDIF}

  WriteLn;
  Total := 0;
  for i := 0 to High(Benchmarks) do
  begin
    WriteLn(Format('%-20s: %6d ms',
      [Benchmarks[i].Name, Benchmarks[i].Time]));
    Inc(Total, Benchmarks[i].Time);
  end;
  WriteLn(StringOfChar('-', 30));
  WriteLn(Format('%-20s: %6d ms', ['TOTAL', Total]));
end;

begin
  WriteLn('Starting benchmarks...');

  BenchmarkMath;
  BenchmarkStrings;
  BenchmarkArrays;
  BenchmarkRecursion;

  ShowResults;

  WriteLn;
  WriteLn('Press Enter to exit...');
  ReadLn;
end.
```

#### R√©sultats typiques

```
=== R√©sultats comparatifs (Intel Core i7) ===

Optimisation: -O0 (Aucune)
Math Operations     :   2340 ms
String Operations   :    567 ms
Array Operations    :   1890 ms
Recursion (Fib 40)  :   4532 ms
TOTAL              :   9329 ms

Optimisation: -O1 (Basique)
Math Operations     :   1876 ms (-20%)
String Operations   :    423 ms (-25%)
Array Operations    :   1234 ms (-35%)
Recursion (Fib 40)  :   3421 ms (-24%)
TOTAL              :   6954 ms (-25%)

Optimisation: -O2 (Standard)
Math Operations     :   1123 ms (-52%)
String Operations   :    312 ms (-45%)
Array Operations    :    789 ms (-58%)
Recursion (Fib 40)  :   2234 ms (-51%)
TOTAL              :   4458 ms (-52%)

Optimisation: -O3 (Agressive)
Math Operations     :    892 ms (-62%)
String Operations   :    298 ms (-47%)
Array Operations    :    623 ms (-67%)
Recursion (Fib 40)  :   1876 ms (-59%)
TOTAL              :   3689 ms (-60%)

Optimisation: -Os (Taille)
Math Operations     :   1456 ms (-38%)
String Operations   :    389 ms (-31%)
Array Operations    :    945 ms (-50%)
Recursion (Fib 40)  :   2678 ms (-41%)
TOTAL              :   5468 ms (-41%)
Taille exe: 245 KB (-45% vs -O0)
```

### Points cl√©s √† retenir

1. **L'optimisation pr√©matur√©e est la racine de tous les maux** - Donald Knuth
   - √âcrivez d'abord du code correct et maintenable
   - Optimisez seulement apr√®s avoir mesur√©

2. **Mesurez, ne devinez pas**
   - Utilisez toujours un profiler
   - Benchmarkez avant et apr√®s chaque optimisation

3. **Hi√©rarchie des optimisations**
   - Algorithme > Structure de donn√©es > Code > Compilateur
   - Un bon algorithme bat toujours les optimisations du compilateur

4. **Compromis √† consid√©rer**
   - Vitesse vs Taille
   - Temps de compilation vs Performance d'ex√©cution
   - Portabilit√© vs Optimisations sp√©cifiques

5. **S√©curit√© et fiabilit√©**
   - Testez exhaustivement √† chaque niveau d'optimisation
   - Gardez toujours une version debug fonctionnelle
   - Documentez les optimisations non √©videntes

Ce guide complet vous donne toutes les cl√©s pour ma√Ætriser les optimisations du compilateur FreePascal, depuis les concepts de base jusqu'aux techniques les plus avanc√©es. N'oubliez pas que la meilleure optimisation est souvent celle qu'on ne fait pas - un code simple et bien structur√© est g√©n√©ralement suffisant pour la plupart des applications.

‚è≠Ô∏è [Directives de compilation conditionnelle multi-OS](/03-langage-object-pascal-avance/12-directives-compilation-conditionnelle-multi-os.md)
