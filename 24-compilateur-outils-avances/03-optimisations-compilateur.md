üîù Retour au [Sommaire](/SOMMAIRE.md)

# 24.3 Optimisations du compilateur

## Introduction

L'**optimisation** est l'art de transformer un programme pour qu'il soit plus rapide, plus compact, ou plus efficace, sans changer son comportement observable. Le compilateur Free Pascal int√®gre de nombreuses optimisations sophistiqu√©es qui peuvent grandement am√©liorer les performances de vos applications.

Dans ce chapitre, nous allons explorer :
- Comment fonctionne l'optimisation
- Les diff√©rents types d'optimisations dans FPC
- Comment contr√¥ler les optimisations
- Comment √©crire du code "optimisable"
- Les pi√®ges et compromis √† conna√Ætre

> üí° **Pour les d√©butants** : Pas de panique si certains concepts semblent complexes. Nous allons les expliquer avec des analogies simples et des exemples concrets !

---

## Qu'est-ce que l'optimisation ?

### Analogie du trajet

Imaginez que vous devez aller du point A au point B :

**Sans optimisation :**
- Vous suivez les instructions au pied de la lettre
- "Allez tout droit, tournez √† gauche, faites demi-tour, tournez √† droite..."
- Vous arrivez, mais le trajet est long

**Avec optimisation :**
- Vous analysez le trajet global
- Vous supprimez le demi-tour inutile
- Vous combinez certains segments
- Vous arrivez plus vite, par le m√™me chemin final

Le compilateur fait la m√™me chose avec votre code !

### Exemple simple

```pascal
// Code original
var
  x, y, z: Integer;
begin
  x := 5;
  y := 10;
  z := x + y;
  WriteLn(z);
end.
```

**Sans optimisation :**
```asm
; Stocker 5 dans x
mov [x], 5
; Stocker 10 dans y
mov [y], 10
; Charger x
mov eax, [x]
; Charger y
mov ebx, [y]
; Additionner
add eax, ebx
; Stocker dans z
mov [z], eax
; Charger z pour l'affichage
mov eax, [z]  
push eax  
call WriteLn
```

**Avec optimisation :**
```asm
; Le compilateur calcule : 5 + 10 = 15
mov eax, 15  
push eax  
call WriteLn
; x, y, z n'existent m√™me plus !
```

Le code optimis√© est **beaucoup plus court et rapide**, mais produit exactement le m√™me r√©sultat !

---

## Niveaux d'optimisation dans FPC

### Options de compilation

FPC propose plusieurs niveaux d'optimisation via l'option `-O` :

| Option | Nom | Description | Utilisation |
|--------|-----|-------------|-------------|
| **-O-** | Aucune optimisation | Code non optimis√©, rapide √† compiler | D√©bogage |
| **-O1** | Optimisations de base | Optimisations simples et s√ªres | D√©veloppement |
| **-O2** | Optimisations standard | Bon compromis vitesse/taille | **Recommand√©** |
| **-O3** | Optimisations agressives | Optimise davantage, peut augmenter la taille | Production |
| **-O4** | Optimisations maximales | Toutes les optimisations possibles | Performances critiques |

### Utilisation en ligne de commande

```bash
# Sans optimisation (pour d√©boguer)
fpc -O- myprogram.pas

# Optimisations standard (recommand√©)
fpc -O2 myprogram.pas

# Optimisations maximales
fpc -O4 myprogram.pas
```

### Configuration dans Lazarus

Dans l'IDE Lazarus :

1. **Project ‚Üí Project Options**
2. **Compiler Options ‚Üí Compilation and Linking**
3. Section **Optimization** :
   - Level: 1, 2, 3, ou 4
   - Cocher les optimisations sp√©cifiques

### Optimisations sp√©cifiques

Vous pouvez activer des optimisations individuelles :

```bash
# Optimiser les registres
fpc -OoREGVAR myprogram.pas

# Optimiser les boucles
fpc -OoLOOPUNROLL myprogram.pas

# Combiner plusieurs optimisations
fpc -O2 -OoREGVAR,LOOPUNROLL myprogram.pas
```

**Liste des optimisations principales :**

- `REGVAR` : Allocation de variables dans les registres
- `STACKFRAME` : Optimisation des frames de pile
- `LOOPUNROLL` : D√©roulage de boucles
- `TAILREC` : Optimisation des appels r√©cursifs terminaux
- `CSE` : √âlimination de sous-expressions communes
- `DFA` : Analyse de flux de donn√©es
- `PEEPHOLE` : Optimisations peephole
- `UNCERTAIN` : Optimisations sp√©culatives (attention !)

---

## Types d'optimisations

### 1. Optimisations locales (Peephole)

Les **optimisations peephole** examinent de petites s√©quences d'instructions et les remplacent par des √©quivalents plus efficaces.

#### √âlimination d'instructions redondantes

**Avant :**
```asm
mov eax, ebx  
mov eax, ebx    ; Redondant !
```

**Apr√®s :**
```asm
mov eax, ebx
```

#### Simplification alg√©brique

**Avant :**
```pascal
x := x + 0;  // Ajouter 0 ne fait rien  
y := y * 1;  // Multiplier par 1 ne fait rien  
z := z * 0;  // Multiplier par 0 donne toujours 0
```

**Apr√®s :**
```pascal
// x := x + 0  ‚Üí compl√®tement supprim√©
// y := y * 1  ‚Üí compl√®tement supprim√©
z := 0;
```

#### Strength reduction

Remplacer des op√©rations co√ªteuses par des √©quivalents moins co√ªteux :

**Avant :**
```pascal
x := y * 2;    // Multiplication  
x := y / 2;    // Division  
x := y * 8;    // Multiplication par puissance de 2
```

**Apr√®s (code assembleur) :**
```asm
; x := y * 2  ‚Üí  shift left 1
shl eax, 1

; x := y / 2  ‚Üí  shift right 1
shr eax, 1

; x := y * 8  ‚Üí  shift left 3
shl eax, 3
```

Les shifts (d√©calages) sont **beaucoup plus rapides** que les multiplications et divisions !

#### Utilisation d'instructions sp√©cialis√©es

**Avant :**
```pascal
x := x + 1;
```

**Apr√®s :**
```asm
; Au lieu de : add eax, 1
inc eax        ; Plus court (peut √™tre plus rapide)
```

### 2. Optimisations au niveau des expressions

#### Pliage de constantes (Constant Folding)

Calculer √† la compilation ce qui peut l'√™tre :

**Avant :**
```pascal
const
  WIDTH = 800;
  HEIGHT = 600;
var
  area: Integer;
begin
  area := WIDTH * HEIGHT;  // Calcul√© √† la compilation !
end.
```

**Apr√®s :**
```pascal
begin
  area := 480000;  // D√©j√† calcul√©
end.
```

#### Propagation de constantes (Constant Propagation)

Propager les valeurs constantes √† travers le code :

**Avant :**
```pascal
var
  x, y, z: Integer;
begin
  x := 5;
  y := x + 3;    // x est connu = 5
  z := y * 2;    // y est connu = 8
  WriteLn(z);    // z est connu = 16
end.
```

**Apr√®s optimisation :**
```pascal
begin
  WriteLn(16);   // Tout calcul√© !
end.
```

#### √âlimination de sous-expressions communes (CSE)

**Avant :**
```pascal
a := b + c;  
d := b + c;      // Recalcule la m√™me chose !  
e := b + c;      // Encore !
```

**Apr√®s :**
```pascal
temp := b + c;   // Calculer une fois  
a := temp;  
d := temp;       // R√©utiliser  
e := temp;
```

**Code assembleur optimis√© :**
```asm
mov eax, [b]  
add eax, [c]     ; Calcul une seule fois  
mov [a], eax  
mov [d], eax     ; Juste copier  
mov [e], eax
```

### 3. Optimisations de flux de contr√¥le

#### √âlimination de code mort (Dead Code Elimination)

Supprimer le code qui ne sera jamais ex√©cut√© :

**Avant :**
```pascal
if False then
  DoSomething;   // Ne sera jamais ex√©cut√©

if True then
  DoA
else
  DoB;           // DoB ne sera jamais appel√©
```

**Apr√®s :**
```pascal
// Premier if compl√®tement supprim√©
DoA;             // Juste DoA, le if a disparu
```

#### Simplification de conditions

**Avant :**
```pascal
if (x > 5) and (x > 5) then  // Condition dupliqu√©e
  DoSomething;

if x or True then             // Toujours vrai
  DoSomething;

if x and False then           // Toujours faux
  DoSomething;
```

**Apr√®s :**
```pascal
if x > 5 then
  DoSomething;

DoSomething;  // Condition toujours vraie

// Code supprim√© (condition toujours fausse)
```

#### Fusion de blocs

**Avant :**
```pascal
if condition then
  goto Label1;

Label1:
  DoSomething;
```

**Apr√®s :**
```pascal
if condition then
  DoSomething;
// Le goto et le label sont √©limin√©s
```

### 4. Optimisations de boucles

#### Invariant code motion

Sortir de la boucle les calculs qui ne changent pas :

**Avant :**
```pascal
for i := 1 to 1000 do  
begin
  limit := GetMaxValue;  // Ne change pas dans la boucle !
  if data[i] > limit then
    Process(data[i]);
end;
```

**Apr√®s :**
```pascal
limit := GetMaxValue;    // Appel√© une seule fois  
for i := 1 to 1000 do  
begin
  if data[i] > limit then
    Process(data[i]);
end;
```

**Impact :** Au lieu d'appeler `GetMaxValue` 1000 fois, on l'appelle 1 fois !

#### Loop unrolling (D√©roulage de boucles)

R√©p√©ter le corps de la boucle plusieurs fois pour r√©duire le surco√ªt :

**Avant :**
```pascal
for i := 0 to 3 do
  sum := sum + data[i];
```

**Apr√®s d√©roulage :**
```pascal
sum := sum + data[0];  
sum := sum + data[1];  
sum := sum + data[2];  
sum := sum + data[3];
// La boucle a disparu !
```

**Avantages :**
- Moins de tests et de sauts
- Meilleur pipeline CPU
- Plus rapide

**Inconv√©nients :**
- Code plus gros
- Ne marche bien que pour petites boucles

#### Loop fusion

Fusionner plusieurs boucles qui parcourent les m√™mes donn√©es :

**Avant :**
```pascal
for i := 1 to 1000 do
  a[i] := b[i] + c[i];

for i := 1 to 1000 do
  d[i] := a[i] * 2;
```

**Apr√®s :**
```pascal
for i := 1 to 1000 do  
begin
  a[i] := b[i] + c[i];
  d[i] := a[i] * 2;      // Dans la m√™me boucle
end;
```

**Avantages :**
- Meilleure utilisation du cache CPU
- Moins de surco√ªt de boucle
- Plus rapide

### 5. Optimisations de proc√©dures

#### Inlining (Incorporation)

Remplacer l'appel d'une fonction par son code directement :

**Avant :**
```pascal
function Square(x: Integer): Integer; inline;  
begin
  Result := x * x;
end;

var
  y: Integer;
begin
  y := Square(5);
end.
```

**Apr√®s inlining :**
```pascal
var
  y: Integer;
begin
  y := 5 * 5;     // Fonction "d√©pli√©e" + constant folding
  // Devient : y := 25;
end.
```

**Avantages :**
- Pas de surco√ªt d'appel de fonction
- Permet d'autres optimisations (ici constant folding)
- Plus rapide

**Inconv√©nients :**
- Code plus gros si fonction appel√©e souvent
- Ne marche que pour petites fonctions

**Utilisation :**
```pascal
// Marquer une fonction inline
function FastCalc(x: Integer): Integer; inline;  
begin
  Result := x * 2 + 1;
end;
```

#### Tail call optimization

Optimiser les appels r√©cursifs terminaux :

**Avant (r√©cursion) :**
```pascal
function Factorial(n: Integer): Integer;  
begin
  if n <= 1 then
    Result := 1
  else
    Result := n * Factorial(n - 1);  // Appel r√©cursif
end;
```

**Probl√®me :** Chaque appel consomme de la pile. Pour Factorial(10000), d√©bordement de pile !

**Solution avec accumulation :**
```pascal
function FactorialTail(n, acc: Integer): Integer;  
begin
  if n <= 1 then
    Result := acc
  else
    Result := FactorialTail(n - 1, n * acc);  // Tail call
end;
```

**Apr√®s optimisation :**
```pascal
function FactorialTail(n, acc: Integer): Integer;  
label
  Start;
begin  
Start:
  if n <= 1 then
    Result := acc
  else
  begin
    acc := n * acc;   // Transform√© en boucle !
    n := n - 1;
    goto Start;
  end;
end;
```

Le compilateur transforme la r√©cursion en boucle : plus de risque de d√©bordement !

#### Dead store elimination

Supprimer les affectations inutiles :

**Avant :**
```pascal
procedure Example;  
var
  x: Integer;
begin
  x := 5;      // Premi√®re affectation
  x := 10;     // √âcrase la premi√®re - la premi√®re est inutile !
  WriteLn(x);
end;
```

**Apr√®s :**
```pascal
procedure Example;  
var
  x: Integer;
begin
  x := 10;     // Premi√®re affectation supprim√©e
  WriteLn(x);
end;
```

### 6. Optimisations de registres

#### Register allocation

Placer les variables les plus utilis√©es dans les registres CPU plut√¥t qu'en m√©moire :

**Sans optimisation :**
```pascal
function Calculate(a, b, c: Integer): Integer;  
begin
  Result := (a + b) * c;
end;
```

**Code g√©n√©r√© non optimis√© :**
```asm
mov eax, [a]     ; Charger depuis m√©moire  
add eax, [b]     ; Charger depuis m√©moire  
mov ebx, [c]     ; Charger depuis m√©moire  
imul eax, ebx  
mov [Result], eax ; Stocker en m√©moire
```

**Code optimis√© (variables en registres) :**
```asm
; a d√©j√† dans eax, b dans ebx, c dans ecx
add eax, ebx     ; Directement dans les registres !  
imul eax, ecx
; Result d√©j√† dans eax (convention d'appel)
```

**Impact :** Acc√®s registre = **50-100x plus rapide** que l'acc√®s m√©moire !

#### Register coalescing

R√©duire les copies entre registres :

**Avant :**
```asm
mov eax, ebx  
mov ecx, eax     ; Copie inutile
```

**Apr√®s :**
```asm
mov ecx, ebx     ; Copie directe
```

### 7. Optimisations m√©moire

#### Array bounds check elimination

Supprimer les v√©rifications de limites quand elles sont prouv√©es inutiles :

**Avant (avec v√©rifications) :**
```pascal
var
  arr: array[1..10] of Integer;
  i: Integer;
begin
  for i := 1 to 10 do
    arr[i] := 0;  // V√©rification : i in [1..10] ?
end;
```

**Apr√®s optimisation :**
```pascal
// Le compilateur sait que i est toujours dans [1..10]
// Les v√©rifications sont supprim√©es
for i := 1 to 10 do
  arr[i] := 0;  // Pas de v√©rification
```

**Impact :** Environ 10-20% plus rapide pour code intensif en tableaux.

**Contr√¥le manuel :**
```pascal
{$R+}  // Range checking ON (mode debug)
{$R-}  // Range checking OFF (mode release)
```

#### String optimizations

Optimisations sp√©cifiques aux cha√Ænes :

**Copy-on-write :**
```pascal
var
  s1, s2: String;
begin
  s1 := 'Hello World';
  s2 := s1;            // Pas de copie ! Juste une r√©f√©rence
  // s2 partage la m√™me m√©moire que s1

  s2 := s2 + '!';      // MAINTENANT il y a copie (modification)
end;
```

**Short string optimization :**
```pascal
var
  s: String[15];  // ShortString - pas d'allocation heap
begin
  s := 'Hello';   // Tr√®s rapide, pas de gestion m√©moire
end;
```

### 8. Optimisations de branchements

#### Branch prediction hints

Aider le CPU √† pr√©dire les branchements :

```pascal
// Indiquer qu'une condition est probable ou improbable
if Unlikely(error <> 0) then
  HandleError;

if Likely(status = OK) then
  Continue;
```

#### Branch elimination via cmov

Utiliser des instructions conditionnelles au lieu de sauts :

**Avant :**
```pascal
if x > y then
  max := x
else
  max := y;
```

**Code na√Øf :**
```asm
cmp eax, ebx  
jle else_branch  
mov ecx, eax  
jmp end_if  
else_branch:  
mov ecx, ebx  
end_if:
```

**Code optimis√© (x86) :**
```asm
cmp eax, ebx  
cmovg ecx, eax   ; Conditional move - pas de saut !  
cmovle ecx, ebx
```

**Avantage :** Pas de saut = meilleur pipeline CPU

---

## Optimisations sp√©cifiques aux plateformes

### Windows vs Linux

Certaines optimisations d√©pendent du syst√®me d'exploitation :

```pascal
{$IFDEF WINDOWS}
  // Utiliser les API Windows optimis√©es
  CopyMemory(@dest, @src, size);
{$ENDIF}

{$IFDEF LINUX}
  // Utiliser memcpy optimis√© de glibc
  Move(src, dest, size);
{$ENDIF}
```

### x86-64 vs ARM

Optimisations sp√©cifiques √† l'architecture :

**x86-64 : REP MOVSB optimis√©**
```pascal
// FPC peut utiliser REP MOVSB (tr√®s rapide sur CPU modernes)
Move(source, dest, large_size);
```

**ARM : Load/Store Multiple**
```pascal
// FPC utilise LDM/STM pour copier plusieurs valeurs
Move(source, dest, 16);  // Optimis√© en une instruction
```

### Vectorisation (SIMD)

Utiliser les instructions vectorielles (SSE, AVX, NEON) :

**Code scalaire :**
```pascal
for i := 0 to 3 do
  result[i] := a[i] + b[i];  // 4 additions s√©quentielles
```

**Code vectoris√© (conceptuel) :**
```pascal
// FPC peut g√©n√©rer du code SSE/AVX
result_vector := a_vector + b_vector;  // 4 additions en parall√®le
```

**Activation :**
```bash
# x86-64 avec SSE2
fpc -CfSSE2 myprogram.pas

# x86-64 avec AVX
fpc -CfAVX myprogram.pas

# ARM avec NEON
fpc -CfNEON myprogram.pas
```

---

## Contr√¥ler les optimisations

### Directives de compilation

#### Au niveau du fichier

```pascal
{$OPTIMIZATION ON}   // ou OFF
{$OPTIMIZATION LEVEL2}
{$OPTIMIZATION REGVAR}
```

#### Au niveau d'une fonction

```pascal
procedure CriticalCode;
{$OPTIMIZATION ON}
begin
  // Code avec optimisations
end;

procedure DebugCode;
{$OPTIMIZATION OFF}
begin
  // Code sans optimisations (facile √† d√©boguer)
end;
```

### Attributs et hints

```pascal
// Forcer l'inlining
function FastCalc(x: Integer): Integer; inline;

// Emp√™cher l'inlining
function ComplexCalc(x: Integer): Integer;  
begin
  // Code complexe
end; {$OPTIMIZATION NOINLINE}

// Indiquer qu'une variable est volatile
var
  hardware_register: LongWord; volatile;
```

### Options de compilation avanc√©es

```bash
# Optimiser pour la taille
fpc -Os myprogram.pas

# Optimiser pour la vitesse
fpc -O3 myprogram.pas

# Optimiser pour un processeur sp√©cifique
fpc -Op3 myprogram.pas     # Pentium 3 et sup√©rieur  
fpc -CpARMV7A myprogram.pas # ARM v7-A

# D√©sactiver des optimisations sp√©cifiques
fpc -O2 -OoNOREGVAR myprogram.pas
```

---

## √âcrire du code optimisable

### Bonnes pratiques

#### 1. Utilisez des types appropri√©s

**Mauvais :**
```pascal
var
  x: Extended;  // 80 bits, lent sur certains CPU
begin
  x := 5.0;
end;
```

**Bon :**
```pascal
var
  x: Double;    // 64 bits, registres SSE
begin
  x := 5.0;
end;
```

#### 2. √âvitez les calculs r√©p√©titifs

**Mauvais :**
```pascal
for i := 0 to GetLength - 1 do  // GetLength appel√© √† chaque it√©ration !
  Process(data[i]);
```

**Bon :**
```pascal
len := GetLength;  // Appel√© une fois  
for i := 0 to len - 1 do
  Process(data[i]);
```

#### 3. Utilisez const pour les param√®tres

**Moins optimis√© :**
```pascal
procedure Process(s: string);  // Copie de la cha√Æne  
begin
  WriteLn(Length(s));
end;
```

**Plus optimis√© :**
```pascal
procedure Process(const s: string);  // Pas de copie !  
begin
  WriteLn(Length(s));
end;
```

#### 4. Pr√©f√©rez les boucles for

**Moins optimis√© :**
```pascal
i := 0;  
while i < 1000 do  
begin
  Process(i);
  Inc(i);
end;
```

**Plus optimis√© :**
```pascal
for i := 0 to 999 do  // Le compilateur optimise mieux les for
  Process(i);
```

#### 5. Localisez les variables

**Moins optimis√© :**
```pascal
var
  Global: Integer;  // Variable globale

procedure Test;  
begin
  Global := Global + 1;  // Acc√®s m√©moire
end;
```

**Plus optimis√© :**
```pascal
procedure Test;  
var
  Local: Integer;   // Variable locale ‚Üí registre
begin
  Local := 0;
  Local := Local + 1;  // Reste dans un registre
end;
```

#### 6. √âvitez les conversions de types inutiles

**Mauvais :**
```pascal
var
  x: Integer;
  y: Double;
begin
  y := x;           // Conversion Int ‚Üí Double
  x := Round(y);    // Conversion Double ‚Üí Int
end;
```

**Bon :**
```pascal
var
  x: Integer;
begin
  x := x + 1;  // Pas de conversion
end;
```

### Pi√®ges √† √©viter

#### 1. Micro-optimisations pr√©matur√©es

**Ne faites pas √ßa :**
```pascal
// Code illisible pour gagner 0.001%
x := (y shl 3) - (y shl 1);  // x := y * 6  (pourquoi ??)
```

**Faites plut√¥t √ßa :**
```pascal
x := y * 6;  // Clair ! Le compilateur optimisera si n√©cessaire
```

**R√®gle d'or :** √âcrivez du code clair d'abord, optimisez ensuite si n√©cessaire.

#### 2. D√©sactiver toutes les v√©rifications

**Dangereux :**
```pascal
{$R-}  // Range checking OFF
{$I-}  // I/O checking OFF
{$Q-}  // Overflow checking OFF
// Programme plus rapide mais bugs cach√©s !
```

**Mieux :**
```pascal
{$IFDEF DEBUG}
  {$R+} {$I+} {$Q+}  // V√©rifications en debug
{$ELSE}
  {$R-} {$I-} {$Q-}  // Optimisations en release
{$ENDIF}
```

#### 3. Optimiser sans mesurer

Toujours **profiler** avant d'optimiser !

```pascal
// Utilisez des timers pour mesurer
var
  start, stop: TDateTime;
begin
  start := Now;

  // Code √† mesurer
  for i := 1 to 1000000 do
    DoSomething;

  stop := Now;
  WriteLn('Temps: ', MilliSecondsBetween(stop, start), ' ms');
end;
```

---

## Profiling et mesure

### Outils de profiling

#### 1. Built-in profiling

FPC peut g√©n√©rer des informations de profiling :

```bash
# Compiler avec profiling
fpc -pg myprogram.pas

# Ex√©cuter le programme
./myprogram

# Analyser les r√©sultats
gprof myprogram gmon.out > profile.txt
```

**Fichier profile.txt :**
```
  %   cumulative   self              self     total
 time   seconds   seconds    calls  ms/call  ms/call  name
 45.2      1.23     1.23   100000     0.01     0.02  SlowFunction
 23.7      1.87     0.64    50000     0.01     0.01  MediumFunction
 15.3      2.29     0.42  1000000     0.00     0.00  FastFunction
```

Vous voyez imm√©diatement o√π le temps est pass√© !

#### 2. Valgrind (Linux)

Profiler d√©taill√© avec informations cache :

```bash
# Profiling avec cachegrind
valgrind --tool=cachegrind ./myprogram

# Analyser
cg_annotate cachegrind.out.<pid>
```

#### 3. Instrumentation manuelle

Ajouter des mesures dans votre code :

```pascal
uses
  SysUtils, DateUtils;

var
  ProfileData: record
    FunctionACalls: Integer;
    FunctionATime: Int64;
    FunctionBCalls: Integer;
    FunctionBTime: Int64;
  end;

procedure StartProfile(var calls: Integer; var time: Int64);  
begin
  Inc(calls);
  time := time - GetTickCount64;
end;

procedure StopProfile(var time: Int64);  
begin
  time := time + GetTickCount64;
end;

procedure FunctionA;  
begin
  StartProfile(ProfileData.FunctionACalls, ProfileData.FunctionATime);

  // Code de la fonction

  StopProfile(ProfileData.FunctionATime);
end;

// √Ä la fin du programme
WriteLn('FunctionA: ', ProfileData.FunctionACalls, ' appels, ',
        ProfileData.FunctionATime, ' ms');
```

### Benchmarking

Comparer plusieurs approches :

```pascal
procedure BenchmarkApproach;  
const
  ITERATIONS = 1000000;
var
  i: Integer;
  start: QWord;
begin
  // Approche 1
  start := GetTickCount64;
  for i := 1 to ITERATIONS do
    Approach1;
  WriteLn('Approche 1: ', GetTickCount64 - start, ' ms');

  // Approche 2
  start := GetTickCount64;
  for i := 1 to ITERATIONS do
    Approach2;
  WriteLn('Approche 2: ', GetTickCount64 - start, ' ms');
end;
```

---

## Cas pratiques d'optimisation

### Cas 1 : Tri de tableau

**Code initial (non optimis√©) :**
```pascal
procedure BubbleSort(var arr: array of Integer);  
var
  i, j, temp: Integer;
begin
  for i := Low(arr) to High(arr) do
    for j := Low(arr) to High(arr) - 1 do
      if arr[j] > arr[j + 1] then
      begin
        temp := arr[j];
        arr[j] := arr[j + 1];
        arr[j + 1] := temp;
      end;
end;
```

**Optimisation 1 : R√©duire les comparaisons**
```pascal
procedure BubbleSortOpt1(var arr: array of Integer);  
var
  i, j, temp: Integer;
  n: Integer;
begin
  n := High(arr);
  for i := Low(arr) to n do
    for j := Low(arr) to n - i do  // R√©duire la port√©e
      if arr[j] > arr[j + 1] then
      begin
        temp := arr[j];
        arr[j] := arr[j + 1];
        arr[j + 1] := temp;
      end;
end;
```

**Optimisation 2 : Sortie anticip√©e**
```pascal
procedure BubbleSortOpt2(var arr: array of Integer);  
var
  i, j, temp: Integer;
  swapped: Boolean;
  n: Integer;
begin
  n := High(arr);
  repeat
    swapped := False;
    for j := Low(arr) to n - 1 do
      if arr[j] > arr[j + 1] then
      begin
        temp := arr[j];
        arr[j] := arr[j + 1];
        arr[j + 1] := temp;
        swapped := True;
      end;
    Dec(n);
  until not swapped;  // Sortir si d√©j√† tri√©
end;
```

**Optimisation 3 : Meilleur algorithme**
```pascal
procedure QuickSort(var arr: array of Integer; left, right: Integer);  
var
  i, j, pivot, temp: Integer;
begin
  if left < right then
  begin
    pivot := arr[(left + right) div 2];
    i := left;
    j := right;

    repeat
      while arr[i] < pivot do Inc(i);
      while arr[j] > pivot do Dec(j);

      if i <= j then
      begin
        temp := arr[i];
        arr[i] := arr[j];
        arr[j] := temp;
        Inc(i);
        Dec(j);
      end;
    until i > j;

    QuickSort(arr, left, j);
    QuickSort(arr, i, right);
  end;
end;
```

**R√©sultats :**
- BubbleSort : O(n¬≤) - 10 secondes pour 10000 √©l√©ments
- BubbleSortOpt1 : O(n¬≤) - 7 secondes (30% plus rapide)
- BubbleSortOpt2 : O(n¬≤) meilleur cas O(n) - 5 secondes si presque tri√©
- QuickSort : O(n log n) - 0.05 secondes ! **200x plus rapide**

### Cas 2 : Recherche dans tableau

**Code initial :**
```pascal
function FindValue(const arr: array of Integer; value: Integer): Integer;  
var
  i: Integer;
begin
  Result := -1;
  for i := Low(arr) to High(arr) do
    if arr[i] = value then
    begin
      Result := i;
      Exit;  // Trouver ‚Üí sortir imm√©diatement
    end;
end;
```

**Optimisation : Tableau tri√© + recherche binaire**
```pascal
function BinarySearch(const arr: array of Integer; value: Integer): Integer;  
var
  left, right, mid: Integer;
begin
  left := Low(arr);
  right := High(arr);
  Result := -1;

  while left <= right do
  begin
    mid := (left + right) div 2;

    if arr[mid] = value then
    begin
      Result := mid;
      Exit;
    end
    else if arr[mid] < value then
      left := mid + 1
    else
      right := mid - 1;
  end;
end;
```

**R√©sultats :**
- Recherche lin√©aire : O(n) - 10000 comparaisons max
- Recherche binaire : O(log n) - 14 comparaisons max ! **700x moins**

### Cas 3 : Concat√©nation de cha√Ænes

**Code initial (TR√àS LENT) :**
```pascal
var
  result: string;
  i: Integer;
begin
  result := '';
  for i := 1 to 10000 do
    result := result + 'item' + IntToStr(i) + ',';
  // Temps : ~5 secondes (chaque += r√©alloue !)
end;
```

**Optimisation 1 : StringBuilder**
```pascal
uses
  Classes;

var
  sb: TStringBuilder;
  i: Integer;
begin
  sb := TStringBuilder.Create;
  try
    for i := 1 to 10000 do
    begin
      sb.Append('item');
      sb.Append(i);
      sb.Append(',');
    end;
    result := sb.ToString;
  finally
    sb.Free;
  end;
  // Temps : ~0.05 secondes ! **100x plus rapide**
end;
```

**Optimisation 2 : TStringList**
```pascal
uses
  Classes;

var
  list: TStringList;
  i: Integer;
begin
  list := TStringList.Create;
  try
    for i := 1 to 10000 do
      list.Add('item' + IntToStr(i));
    result := list.CommaText;
  finally
    list.Free;
  end;
  // Temps : ~0.08 secondes
end;
```

### Cas 4 : Calculs math√©matiques

**Code initial :**
```pascal
function Distance(x1, y1, x2, y2: Double): Double;  
begin
  Result := Sqrt(Sqr(x2 - x1) + Sqr(y2 - y1));
end;

// Appel√© 1 million de fois
for i := 1 to 1000000 do
  d := Distance(points[i].x, points[i].y, target.x, target.y);
```

**Optimisation 1 : Distance carr√©e (√©viter sqrt)**
```pascal
function DistanceSquared(x1, y1, x2, y2: Double): Double; inline;  
begin
  Result := Sqr(x2 - x1) + Sqr(y2 - y1);
end;

// Si on compare juste des distances, pas besoin de sqrt !
for i := 1 to 1000000 do  
begin
  dsq := DistanceSquared(points[i].x, points[i].y, target.x, target.y);
  if dsq < threshold_squared then  // Comparer les carr√©s
    ProcessPoint(i);
end;
// Gain : ~40% plus rapide (sqrt est co√ªteux)
```

**Optimisation 2 : Approximation rapide**
```pascal
function FastDistance(x1, y1, x2, y2: Double): Double; inline;  
var
  dx, dy, min, max: Double;
begin
  dx := Abs(x2 - x1);
  dy := Abs(y2 - y1);

  if dx < dy then
  begin
    min := dx;
    max := dy;
  end
  else
  begin
    min := dy;
    max := dx;
  end;

  // Approximation : max + min/2 (erreur ~8% max)
  Result := max + min * 0.5;
end;
// Gain : ~70% plus rapide, pr√©cision suffisante pour beaucoup de cas
```

---

## Optimisations avanc√©es

### Profile-Guided Optimization (PGO)

Optimiser en fonction de l'utilisation r√©elle :

**√âtape 1 : Compiler avec instrumentation**
```bash
fpc -pg myprogram.pas
```

**√âtape 2 : Ex√©cuter avec donn√©es r√©elles**
```bash
./myprogram < typical_input.txt
# G√©n√®re gmon.out
```

**√âtape 3 : Recompiler avec profil**
```bash
fpc -FWgmon.out -O3 myprogram.pas
# Le compilateur optimise selon l'usage r√©el
```

### Link-Time Optimization (LTO)

Optimiser entre les unit√©s :

```bash
# Activer LTO
fpc -O3 -CX -XX myprogram.pas
```

**Avantages :**
- Inlining entre unit√©s
- √âlimination de code mort global
- Meilleures optimisations globales

**Inconv√©nients :**
- Compilation plus lente
- Fichiers objets plus gros

### Whole Program Optimization

Optimiser le programme entier :

```bash
fpc -O3 -Owdevirtcalls -CX myprogram.pas
```

**Options :**
- `-Owdevirtcalls` : D√©virtualisation d'appels
- `-Owregvars` : Variables globales en registres
- `-CX` : Smart linking

---

## Optimisations sp√©cifiques Windows/Linux

### Windows : FastMM et Memory Manager

**Remplacer le gestionnaire m√©moire par d√©faut :**
```pascal
program MyApp;

{$IFDEF WINDOWS}
uses
  FastMM4;  // Gestionnaire m√©moire optimis√©
{$ENDIF}

begin
  // Votre code
end.
```

**Gain :** Jusqu'√† 30% plus rapide pour code intensif en allocations.

### Linux : jemalloc

**Lier avec jemalloc :**
```bash
# Compiler
fpc myprogram.pas

# Ex√©cuter avec jemalloc
LD_PRELOAD=/usr/lib/libjemalloc.so ./myprogram
```

### Optimisations syst√®me d'exploitation

**Windows : Large pages**
```pascal
{$IFDEF WINDOWS}
uses
  Windows;

// Allouer avec large pages (2MB au lieu de 4KB)
mem := VirtualAlloc(nil, size, MEM_COMMIT or MEM_LARGE_PAGES, PAGE_READWRITE);
{$ENDIF}
```

**Linux : Huge pages**
```bash
# Configurer huge pages
echo 512 > /proc/sys/vm/nr_hugepages

# Compiler avec support
fpc -k-lhugetlbfs myprogram.pas
```

---

## Comprendre les compromis

### Vitesse vs Taille

| Optimisation | Vitesse | Taille | Quand utiliser |
|--------------|---------|--------|----------------|
| `-Os` | + | +++ | Syst√®mes embarqu√©s, bande passante limit√©e |
| `-O2` | ++ | ++ | **Par d√©faut** - bon √©quilibre |
| `-O3` | +++ | + | Serveurs, applications de calcul |
| Loop unrolling | ++++ | - | Boucles critiques courtes |
| Inlining | +++ | -- | Petites fonctions appel√©es souvent |

### Optimisation vs D√©bogage

**Mode Debug :**
```pascal
{$IFDEF DEBUG}
  {$OPTIMIZATION OFF}
  {$ASSERTIONS ON}
  {$RANGECHECKS ON}
  {$OVERFLOWCHECKS ON}
  {$DEBUGINFO ON}
{$ENDIF}
```

**Mode Release :**
```pascal
{$IFDEF RELEASE}
  {$OPTIMIZATION LEVEL3}
  {$ASSERTIONS OFF}
  {$RANGECHECKS OFF}
  {$OVERFLOWCHECKS OFF}
  {$DEBUGINFO OFF}
  {$INLINE ON}
{$ENDIF}
```

### Portable vs Optimis√©

**Code portable (fonctionne partout) :**
```pascal
procedure GenericCopy(src, dst: Pointer; count: Integer);  
var
  i: Integer;
begin
  for i := 0 to count - 1 do
    PByte(dst)[i] := PByte(src)[i];
end;
```

**Code optimis√© (sp√©cifique x86-64) :**
```pascal
procedure OptimizedCopy(src, dst: Pointer; count: Integer);  
begin
  {$IFDEF CPUX86_64}
  asm
    mov rsi, src
    mov rdi, dst
    mov rcx, count
    rep movsb  // Instruction ultra-optimis√©e
  end;
  {$ELSE}
  Move(src^, dst^, count);  // Fallback portable
  {$ENDIF}
end;
```

---

## Mythes et r√©alit√©s de l'optimisation

### Mythe 1 : "L'assembleur est toujours plus rapide"

**FAUX !** Le compilateur moderne optimise souvent mieux :

```pascal
// Code Pascal simple
function Sum(const arr: array of Integer): Integer;  
var
  i: Integer;
begin
  Result := 0;
  for i := Low(arr) to High(arr) do
    Result := Result + arr[i];
end;
```

Le compilateur peut :
- Vectoriser avec SSE/AVX
- D√©rouler la boucle
- Utiliser les meilleurs registres
- S'adapter au CPU cible

√Ä moins d'√™tre expert en assembleur ET de profiler soigneusement, laissez le compilateur optimiser !

### Mythe 2 : "Inline rend toujours plus rapide"

**FAUX !** Inline peut ralentir si :
- La fonction est grosse ‚Üí code bloat ‚Üí cache miss
- La fonction est appel√©e rarement ‚Üí overhead inutile
- La fonction est complexe ‚Üí emp√™che d'autres optimisations

**Bon usage d'inline :**
```pascal
// OUI - petite fonction, appel√©e souvent
function Square(x: Integer): Integer; inline;  
begin
  Result := x * x;
end;

// NON - grosse fonction
function ComplexCalculation(data: TArray<Double>): TResult; inline;  
begin
  // 100 lignes de code...
end;
```

### Mythe 3 : "Les boucles for sont plus lentes que while"

**FAUX !** C'est l'inverse :

```pascal
// Le compilateur optimise tr√®s bien les for
for i := 0 to 999 do
  Process(i);

// Les while sont plus difficiles √† optimiser
i := 0;  
while i < 1000 do  
begin
  Process(i);
  Inc(i);
end;
```

Le `for` permet au compilateur de mieux comprendre l'intention et d'optimiser.

### Mythe 4 : "Goto est plus rapide"

**PEUT √äTRE VRAI, mais...**

```pascal
// Avec goto - difficile √† optimiser
procedure WithGoto;  
label
  Start, End;
begin
  Start:
  if condition then
    goto End;
  // code
  goto Start;
  End:
end;

// Sans goto - le compilateur optimise mieux
procedure WithoutGoto;  
begin
  while not condition do
  begin
    // code
  end;
end;
```

Le code structur√© permet de meilleures optimisations du compilateur.

### Mythe 5 : "Il faut toujours optimiser"

**FAUX !** L'optimisation pr√©matur√©e est la racine du mal.

**R√®gle du 90/10 :**
- 90% du temps d'ex√©cution se passe dans 10% du code
- Optimisez ces 10% seulement !
- Le reste : gardez-le simple et lisible

**Processus correct :**
1. √âcrire du code clair et correct
2. **Profiler** pour identifier les bottlenecks
3. Optimiser **seulement** les parties critiques
4. **Mesurer** l'am√©lioration
5. Si gain insuffisant, recommencer √©tape 2

---

## Checklist d'optimisation

### Avant d'optimiser

‚òëÔ∏è Le code fonctionne correctement

‚òëÔ∏è J'ai des tests unitaires

‚òëÔ∏è J'ai profil√© et identifi√© les bottlenecks

‚òëÔ∏è J'ai mesur√© la performance actuelle

‚òëÔ∏è L'optimisation en vaut vraiment la peine

### Optimisations de base (toujours faire)

‚òëÔ∏è Compiler avec `-O2` minimum

‚òëÔ∏è Utiliser `const` pour param√®tres non modifi√©s

‚òëÔ∏è Utiliser types appropri√©s (Integer, Double, etc.)

‚òëÔ∏è Sortir les invariants des boucles

‚òëÔ∏è Utiliser boucles `for` plut√¥t que `while` quand possible

### Optimisations interm√©diaires

‚òëÔ∏è Marquer fonctions critiques `inline`

‚òëÔ∏è R√©duire les allocations m√©moire

‚òëÔ∏è Utiliser structures de donn√©es appropri√©es

‚òëÔ∏è √âviter conversions de types inutiles

‚òëÔ∏è Pr√©charger les donn√©es (cache-friendly)

### Optimisations avanc√©es

‚òëÔ∏è Profiling d√©taill√© (gprof, valgrind)

‚òëÔ∏è Optimisations algorithmiques

‚òëÔ∏è Vectorisation SIMD si applicable

‚òëÔ∏è Multithreading si parall√©lisable

‚òëÔ∏è Optimisations sp√©cifiques plateforme

### Apr√®s optimisation

‚òëÔ∏è Mesurer l'am√©lioration r√©elle

‚òëÔ∏è V√©rifier que le code fonctionne toujours

‚òëÔ∏è Refaire passer les tests

‚òëÔ∏è Documenter les optimisations non triviales

‚òëÔ∏è Profiler √† nouveau pour prochaines am√©liorations

---

## Outils et ressources

### Outils de profiling

**Linux :**
- `gprof` - Profiling fonction par fonction
- `perf` - Profiling syst√®me complet
- `valgrind` - Cache profiling, leak detection
- `cachegrind` - Analyse cache CPU

**Windows :**
- `AQTime` (Embarcadero) - Profiler complet
- `Intel VTune` - Profiler haute performance
- `Very Sleepy` - Profiler gratuit
- `Windows Performance Toolkit`

**Multi-plateforme :**
- `gperftools` - Google Performance Tools
- Instrumentation manuelle avec timers

### Benchmarking

```pascal
unit BenchmarkUtils;

interface

uses
  SysUtils, DateUtils;

type
  TBenchmark = class
  private
    FStart: QWord;
    FName: string;
  public
    constructor Create(const AName: string);
    destructor Destroy; override;
  end;

implementation

constructor TBenchmark.Create(const AName: string);  
begin
  FName := AName;
  FStart := GetTickCount64;
  WriteLn('Benchmark "', FName, '" started...');
end;

destructor TBenchmark.Destroy;  
var
  elapsed: QWord;
begin
  elapsed := GetTickCount64 - FStart;
  WriteLn('Benchmark "', FName, '" completed in ', elapsed, ' ms');
  inherited;
end;

end.

// Utilisation :
var
  bench: TBenchmark;
begin
  bench := TBenchmark.Create('Mon algorithme');
  try
    // Code √† benchmarker
    for i := 1 to 1000000 do
      DoSomething;
  finally
    bench.Free;  // Affiche automatiquement le temps
  end;
end;
```

### Documentation

üìö **FPC Optimization Guide**
- Wiki FreePascal : https://wiki.freepascal.org/Optimization

üìö **Compiler Options**
- `fpc -h` - Liste compl√®te des options
- Documentation officielle FPC

üìö **Architecture Manuals**
- Intel Optimization Manual
- ARM Cortex Optimization Guide
- Agner Fog's optimization resources (excellent !)

### Livres recommand√©s

üìñ **"Computer Systems: A Programmer's Perspective"**
- Comprendre le hardware pour optimiser
- Cache, pipeline, m√©moire

üìñ **"Code Optimization: Effective Memory Use"**
- Optimisations pratiques
- Nombreux exemples

üìñ **"The Pragmatic Programmer"**
- Philosophie de l'optimisation
- Quand et comment optimiser

---

## Conclusion

### Ce que nous avons appris

‚úÖ **Les types d'optimisations** : locale, expressions, contr√¥le, boucles, proc√©dures, registres, m√©moire

‚úÖ **Contr√¥ler les optimisations** : Options `-O`, directives, attributs

‚úÖ **√âcrire du code optimisable** : Bonnes pratiques, pi√®ges √† √©viter

‚úÖ **Profiler et mesurer** : Outils et techniques

‚úÖ **Cas pratiques** : Optimisations r√©elles sur vrais probl√®mes

‚úÖ **Comprendre les compromis** : Vitesse vs taille, debug vs release, portable vs optimis√©

### Principes fondamentaux √† retenir

üéØ **R√®gle #1 : Profiler avant d'optimiser**
Ne devinez jamais, mesurez !

üéØ **R√®gle #2 : Clart√© d'abord**
Code lisible > code "clever"

üéØ **R√®gle #3 : Algorithme avant micro-optimisation**
O(n log n) vs O(n¬≤) bat n'importe quelle optimisation bas niveau

üéØ **R√®gle #4 : Faire confiance au compilateur**
Il est souvent plus malin que vous

üéØ **R√®gle #5 : Mesurer l'impact**
Si vous ne mesurez pas, vous ne savez pas si √ßa marche

### La philosophie de l'optimisation

> "Premature optimization is the root of all evil" - Donald Knuth

Mais aussi :

> "Mature optimization is the key to success" - Anonyme

**Le bon √©quilibre :**
1. √âcrire du code **correct** et **clair**
2. Le faire fonctionner
3. **Profiler** pour identifier les vrais probl√®mes
4. **Optimiser** ce qui compte vraiment
5. **Mesurer** les r√©sultats
6. R√©p√©ter si n√©cessaire

### Prochaines √©tapes

Pour continuer √† progresser :

1. **Pratiquez** avec de vrais projets
2. **Profilez** r√©guli√®rement vos applications
3. **Exp√©rimentez** avec diff√©rentes optimisations
4. **Lisez** le code source de FPC pour comprendre les optimisations internes
5. **Contribuez** en partageant vos d√©couvertes

### Le mot de la fin

L'optimisation est un **art** autant qu'une **science**. Cela demande :
- De la compr√©hension technique
- De l'exp√©rience pratique
- De l'intuition
- De la mesure rigoureuse
- De la patience

Mais quand vous voyez votre programme passer de 10 secondes √† 0.1 secondes gr√¢ce √† vos optimisations, la satisfaction est immense !

**Bonne optimisation ! üöÄ**

---

*N'oubliez pas : le code le plus rapide est celui qui n'a pas besoin de s'ex√©cuter. R√©fl√©chissez d'abord √† l'algorithme !*

‚è≠Ô∏è [G√©n√©ration de code custom](/24-compilateur-outils-avances/04-generation-code-custom.md)
