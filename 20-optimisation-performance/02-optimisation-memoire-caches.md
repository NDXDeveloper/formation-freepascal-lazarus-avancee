üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.2 Optimisation m√©moire et caches

## Introduction

L'optimisation de la m√©moire et des caches est l'un des aspects les plus importants de la performance moderne. Contrairement √† l'id√©e re√ßue que "le CPU est le goulot d'√©tranglement", dans la plupart des applications actuelles, **c'est l'acc√®s √† la m√©moire qui limite les performances**. Comprendre comment fonctionne la hi√©rarchie m√©moire et comment √©crire du code "cache-friendly" peut am√©liorer vos performances de 2x √† 10x, voire plus.

## Hi√©rarchie de la m√©moire

### Vue d'ensemble

Les ordinateurs modernes ont plusieurs niveaux de m√©moire, du plus rapide (et petit) au plus lent (et grand) :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Registres     ‚îÇ  < 1 cycle      ~100 bytes
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Cache L1      ‚îÇ  ~4 cycles      32-64 KB
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Cache L2      ‚îÇ  ~12 cycles     256 KB - 1 MB
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Cache L3      ‚îÇ  ~40 cycles     8-32 MB
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   RAM (DDR4)    ‚îÇ  ~200 cycles    8-64 GB
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   SSD           ‚îÇ  ~50,000 cycles 256 GB - 2 TB
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   HDD           ‚îÇ  ~5,000,000 c.  1-10 TB
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pourquoi c'est important ?

**Exemple concret** :
```pascal
// Acc√®s s√©quentiel (cache-friendly)
for i := 0 to 1000000 do
  Tableau[i] := i;
// Temps : ~5 ms (donn√©es en cache L1/L2)

// Acc√®s al√©atoire (cache-unfriendly)
for i := 0 to 1000000 do
  Tableau[Random(1000000)] := i;
// Temps : ~150 ms (cache misses constants)

// Diff√©rence : 30x plus lent !
```

### Les diff√©rents niveaux de cache

#### Cache L1 (Level 1)

**Caract√©ristiques** :
- Le plus rapide (~4 cycles d'horloge)
- Le plus petit (~32-64 KB)
- S√©par√© en deux : L1d (donn√©es) et L1i (instructions)
- Priv√© √† chaque c≈ìur CPU

**Utilisation** :
```pascal
// Code qui tient dans L1 (tr√®s rapide)
procedure CalculRapide;  
var
  i: Integer;
  temp: array[0..1023] of Integer;  // 4 KB, tient dans L1
begin
  for i := 0 to 1023 do
    temp[i] := i * 2;
end;
```

#### Cache L2 (Level 2)

**Caract√©ristiques** :
- Rapide (~12 cycles)
- Taille moyenne (256 KB - 1 MB)
- Priv√© √† chaque c≈ìur (g√©n√©ralement)

**Utilisation** :
```pascal
// Structure de donn√©es pour L2
type
  TDataL2 = array[0..65535] of Integer;  // 256 KB
```

#### Cache L3 (Level 3)

**Caract√©ristiques** :
- Mod√©r√©ment rapide (~40 cycles)
- Grande taille (8-32 MB)
- **Partag√© entre tous les c≈ìurs**

**Implications multi-threading** :
```pascal
// ‚ùå Probl√®me : false sharing dans L3
type
  TCompteur = record
    Valeur: Int64;  // 8 bytes
  end;

var
  Compteurs: array[0..7] of TCompteur;  // 8 threads

// Si deux compteurs sont dans la m√™me ligne de cache (64 bytes),
// les modifications d'un thread invalident le cache de l'autre
// ‚Üí Performance d√©grad√©e
```

**Solution** : Padding
```pascal
// ‚úÖ Solution : padding pour √©viter false sharing
type
  TCompteur = record
    Valeur: Int64;
    Padding: array[0..6] of Int64;  // Force 64 bytes par compteur
  end;
```

### Ligne de cache (Cache Line)

**D√©finition** : La m√©moire est charg√©e en cache par blocs de **64 bytes** (ligne de cache).

**Exemple** :
```pascal
// Tableau de bytes
var
  Data: array[0..127] of Byte;

// Acc√©der √† Data[0] charge √©galement Data[1..63] en cache
// (toute la ligne de cache)
```

**Implications** :
- Acc√©der √† des donn√©es adjacentes est presque gratuit
- Acc√©der √† des donn√©es √©loign√©es peut √™tre 100x plus lent

## Principes d'optimisation m√©moire

### 1. Localit√© spatiale (Spatial Locality)

**Principe** : Acc√©der √† des donn√©es proches en m√©moire.

**‚ùå Mauvais : Acc√®s dispers√©s**
```pascal
type
  TPoint3D = record
    X: Double;
    Y: Double;
    Z: Double;
  end;

var
  PointsX: array[0..9999] of Double;
  PointsY: array[0..9999] of Double;
  PointsZ: array[0..9999] of Double;

// Calcul de la distance
for i := 0 to 9999 do
  Distance := Sqrt(Sqr(PointsX[i]) + Sqr(PointsY[i]) + Sqr(PointsZ[i]));
// 3 acc√®s m√©moire distants ‚Üí 3 cache misses possibles
```

**‚úÖ Bon : Array of Structures (AoS)**
```pascal
type
  TPoint3D = record
    X, Y, Z: Double;
  end;

var
  Points: array[0..9999] of TPoint3D;

// Calcul de la distance
for i := 0 to 9999 do
  Distance := Sqrt(Sqr(Points[i].X) + Sqr(Points[i].Y) + Sqr(Points[i].Z));
// 1 acc√®s m√©moire ‚Üí toutes les coordonn√©es sont dans la m√™me ligne de cache
```

**Performance** :
```
Version dispers√©e : 45 ms  
Version compacte : 12 ms  
Gain : 3.75x plus rapide
```

### 2. Localit√© temporelle (Temporal Locality)

**Principe** : R√©utiliser des donn√©es r√©cemment acc√©d√©es (encore en cache).

**‚ùå Mauvais : Donn√©es acc√©d√©es puis abandonn√©es**
```pascal
// Calculer deux fois la m√™me chose
for i := 0 to 10000 do
  ResultatA[i] := CalculComplexe(Data[i]);

// ... beaucoup de code ...

for i := 0 to 10000 do
  ResultatB[i] := CalculComplexe(Data[i]);  // Re-calcul !
```

**‚úÖ Bon : Cache et r√©utilisation**
```pascal
// Calculer une fois, utiliser deux fois
for i := 0 to 10000 do  
begin
  Temp := CalculComplexe(Data[i]);
  ResultatA[i] := Temp;
  ResultatB[i] := Temp * 2;
end;
```

### 3. R√©duction de l'empreinte m√©moire

**Principe** : Moins de m√©moire = plus de donn√©es en cache.

**‚ùå Mauvais : Types trop gros**
```pascal
type
  TPerson = record
    Nom: String[255];        // 256 bytes
    Prenom: String[255];     // 256 bytes
    Age: Integer;            // 4 bytes
    Email: String[255];      // 256 bytes
  end;  // Total : 772 bytes par personne

var
  Personnes: array[0..9999] of TPerson;  // 7.7 MB
// Ne tient pas dans L3 (8 MB) ‚Üí cache misses constants
```

**‚úÖ Bon : Types compacts**
```pascal
type
  TPerson = record
    Nom: String[50];         // 51 bytes
    Prenom: String[50];      // 51 bytes
    Age: Byte;               // 1 byte
    Email: String[100];      // 101 bytes
  end;  // Total : 204 bytes par personne

var
  Personnes: array[0..9999] of TPerson;  // 2 MB
// Tient dans L3 ‚Üí excellentes performances
```

**Performance** :
```
Version 772 bytes : 150 ms  
Version 204 bytes : 40 ms  
Gain : 3.75x plus rapide (m√™me algorithme !)
```

## Strat√©gies d'allocation m√©moire

### 1. Pr√©-allocation

**‚ùå Mauvais : Allocations r√©p√©t√©es**
```pascal
procedure TraiterFichiers(Fichiers: TStringList);  
var
  i: Integer;
  Buffer: PByte;
begin
  for i := 0 to Fichiers.Count - 1 do
  begin
    Buffer := GetMem(1024 * 1024);  // 1 MB
    try
      ChargerFichier(Fichiers[i], Buffer);
      TraiterBuffer(Buffer);
    finally
      FreeMem(Buffer);
    end;
  end;
end;
// 1000 fichiers = 1000 allocations + 1000 lib√©rations (lent)
```

**‚úÖ Bon : Pr√©-allocation et r√©utilisation**
```pascal
procedure TraiterFichiers(Fichiers: TStringList);  
var
  i: Integer;
  Buffer: PByte;
begin
  Buffer := GetMem(1024 * 1024);  // 1 allocation
  try
    for i := 0 to Fichiers.Count - 1 do
    begin
      FillByte(Buffer^, 1024 * 1024, 0);  // R√©initialiser
      ChargerFichier(Fichiers[i], Buffer);
      TraiterBuffer(Buffer);
    end;
  finally
    FreeMem(Buffer);  // 1 lib√©ration
  end;
end;
// Gain : 10x √† 50x plus rapide
```

### 2. Pooling d'objets (Object Pooling)

**Principe** : R√©utiliser des objets au lieu de les cr√©er/d√©truire constamment.

**‚ùå Mauvais : Cr√©ation/destruction r√©p√©t√©e**
```pascal
for i := 1 to 10000 do  
begin
  Obj := TMonObjet.Create;
  try
    Obj.Traiter(Data[i]);
  finally
    Obj.Free;
  end;
end;
// 10,000 Create + 10,000 Free
```

**‚úÖ Bon : Pool d'objets**
```pascal
type
  TObjectPool = class
  private
    FPool: TList;
  public
    function Acquire: TMonObjet;
    procedure Release(Obj: TMonObjet);
  end;

var
  Pool: TObjectPool;
  Obj: TMonObjet;
  i: Integer;
begin
  Pool := TObjectPool.Create;
  try
    for i := 1 to 10000 do
    begin
      Obj := Pool.Acquire;  // R√©cup√®re du pool
      try
        Obj.Traiter(Data[i]);
      finally
        Pool.Release(Obj);   // Remet dans le pool
      end;
    end;
  finally
    Pool.Free;
  end;
end;
// Cr√©ation r√©elle : quelques dizaines d'objets seulement
// Gain : 50x √† 100x plus rapide
```

### 3. Stack vs Heap

**Principe** : La pile (stack) est beaucoup plus rapide que le tas (heap).

**Stack (rapide)** :
```pascal
procedure Rapide;  
var
  Buffer: array[0..1023] of Byte;  // Sur la pile
begin
  // Allocation instantan√©e (juste un d√©calage de pointeur)
  FillByte(Buffer, 1024, 0);
end;
// Allocation : 0 cycles
// Lib√©ration : 0 cycles (automatique)
```

**Heap (lent)** :
```pascal
procedure Lent;  
var
  Buffer: PByte;
begin
  Buffer := GetMem(1024);  // Sur le tas
  try
    FillByte(Buffer^, 1024, 0);
  finally
    FreeMem(Buffer);
  end;
end;
// Allocation : ~50-200 cycles
// Lib√©ration : ~50-200 cycles
```

**R√®gle** :
- Donn√©es < 1 KB et dur√©e de vie courte ‚Üí Stack
- Donn√©es > 1 KB ou dur√©e de vie longue ‚Üí Heap
- Attention : Stack limit√© (~1 MB sur Windows, ~8 MB sur Linux)

## Patterns d'acc√®s m√©moire

### 1. Acc√®s s√©quentiel (le meilleur)

**Principe** : Parcourir la m√©moire dans l'ordre.

```pascal
// ‚úÖ Optimal : acc√®s s√©quentiel
for i := 0 to High(Tableau) do
  Somme := Somme + Tableau[i];

// Le prefetcher mat√©riel d√©tecte le pattern et charge
// les donn√©es suivantes en cache avant qu'on en ait besoin
```

**Performance** :
- Cache hit rate : 95-99%
- Vitesse maximale du CPU

### 2. Acc√®s par stride (moyen)

**Principe** : Parcourir avec un pas constant (stride).

```pascal
// Stride de 2 (parcourir les √©l√©ments pairs)
for i := 0 to High(Tableau) div 2 do
  Somme := Somme + Tableau[i * 2];

// Stride de 16 (tous les 16 √©l√©ments)
for i := 0 to High(Tableau) div 16 do
  Somme := Somme + Tableau[i * 16];
```

**Performance** :
- Stride petit (2-8) : Bon (80-90% cache hits)
- Stride moyen (16-64) : Moyen (50-70% cache hits)
- Stride grand (>64) : Mauvais (cache miss √† chaque acc√®s)

### 3. Acc√®s al√©atoire (le pire)

**Principe** : Acc√®s sans pattern pr√©visible.

```pascal
// ‚ùå Tr√®s lent : acc√®s al√©atoire
for i := 0 to 1000000 do
  Somme := Somme + Tableau[Random(Length(Tableau))];

// Cache hit rate : 10-20%
// Performance : 10x √† 50x plus lent que s√©quentiel
```

**Solution** : R√©organiser l'algorithme pour acc√®s s√©quentiel.

## Structures de donn√©es cache-friendly

### Array vs Linked List

**Array (cache-friendly)** :
```pascal
type
  TArray = array[0..9999] of Integer;

var
  Arr: TArray;
begin
  // Parcours s√©quentiel : toutes les donn√©es sont adjacentes
  for i := 0 to High(Arr) do
    Traiter(Arr[i]);
end;
// Cache hit rate : 95%+
```

**Linked List (cache-unfriendly)** :
```pascal
type
  PNode = ^TNode;
  TNode = record
    Data: Integer;
    Next: PNode;
  end;

var
  Current: PNode;
begin
  Current := Head;
  while Current <> nil do
  begin
    Traiter(Current^.Data);
    Current := Current^.Next;  // Saut al√©atoire en m√©moire !
  end;
end;
// Cache hit rate : 20-40%
// Performance : 5x √† 10x plus lent qu'un array
```

**Comparaison** :
```
Op√©ration         | Array    | Linked List
------------------|----------|-------------
Acc√®s s√©quentiel  | O(1)     | O(1) mais 5x plus lent  
Acc√®s al√©atoire   | O(1)     | O(n)  
Insertion d√©but   | O(n)     | O(1)  
Insertion fin     | O(1)     | O(1) ou O(n)  
Cache-friendly    | Oui ‚úÖ   | Non ‚ùå
```

**R√®gle** : Privil√©giez les arrays/tableaux dynamiques sauf si vous avez besoin d'insertions/suppressions fr√©quentes au milieu.

### Structure of Arrays (SoA) vs Array of Structures (AoS)

**Array of Structures (AoS)** :
```pascal
type
  TParticule = record
    PosX, PosY, PosZ: Single;
    VelX, VelY, VelZ: Single;
    Mass: Single;
  end;

var
  Particules: array[0..9999] of TParticule;

// Mise √† jour des positions
for i := 0 to High(Particules) do  
begin
  Particules[i].PosX := Particules[i].PosX + Particules[i].VelX;
  Particules[i].PosY := Particules[i].PosY + Particules[i].VelY;
  Particules[i].PosZ := Particules[i].PosZ + Particules[i].VelZ;
end;
// Cache hit rate : Bon (70-80%)
// Mais charge aussi Mass (inutile ici)
```

**Structure of Arrays (SoA)** :
```pascal
type
  TParticules = record
    PosX, PosY, PosZ: array[0..9999] of Single;
    VelX, VelY, VelZ: array[0..9999] of Single;
    Mass: array[0..9999] of Single;
  end;

var
  Particules: TParticules;

// Mise √† jour des positions
for i := 0 to 9999 do  
begin
  Particules.PosX[i] := Particules.PosX[i] + Particules.VelX[i];
  Particules.PosY[i] := Particules.PosY[i] + Particules.VelY[i];
  Particules.PosZ[i] := Particules.PosZ[i] + Particules.VelZ[i];
end;
// Cache hit rate : Excellent (95%+)
// Ne charge que les donn√©es n√©cessaires
// Vectorisation SIMD possible (voir section 20.3)
```

**Quand utiliser SoA ?**
- Traitement par lots (batch processing)
- Beaucoup de particules/entit√©s
- Operations vectorielles (SIMD)
- Performance critique

**Quand utiliser AoS ?**
- Manipulation d'entit√©s individuelles
- Code orient√© objet classique
- Moins de donn√©es (< 1000 √©l√©ments)

## Gestion de la m√©moire dans FreePascal

### GetMem vs New vs Create

**GetMem (allocation brute)** :
```pascal
var
  Buffer: PByte;
begin
  Buffer := GetMem(1024);  // Allocation de 1 KB
  try
    // Utilisation
  finally
    FreeMem(Buffer);
  end;
end;
// Rapide, mais pas de gestion automatique
```

**New (allocation typ√©e)** :
```pascal
type
  PRecord = ^TRecord;
  TRecord = record
    A, B: Integer;
  end;

var
  P: PRecord;
begin
  New(P);
  try
    P^.A := 10;
  finally
    Dispose(P);
  end;
end;
// Gestion de type, initialisation
```

**Create (objets)** :
```pascal
var
  Obj: TMonObjet;
begin
  Obj := TMonObjet.Create;
  try
    Obj.Faire();
  finally
    Obj.Free;
  end;
end;
// Constructeur/destructeur, h√©ritage
```

### Memory Manager de FreePascal

FreePascal utilise un gestionnaire de m√©moire sophistiqu√© :

**Caract√©ristiques** :
- Memory pools pour petites allocations (< 256 bytes)
- Syst√®me de blocs pour grandes allocations
- Thread-safe par d√©faut

**Optimisation** : Utiliser le bon memory manager

```pascal
// cmem : Memory manager de la libc (Linux)
{$IFDEF LINUX}
uses cmem;  // Plus rapide sous Linux
{$ENDIF}

// HeapTrc : D√©tection de fuites (debug uniquement)
{$IFDEF DEBUG}
uses HeapTrc;
{$ENDIF}
```

### Fuites m√©moire

**D√©tection avec HeapTrc** :

```pascal
// Compilation
{$IFDEF DEBUG}
{$DEFINE HEAPTRC}
{$ENDIF}

program MonProgramme;

{$IFDEF HEAPTRC}
{$APPTYPE CONSOLE}
uses
  HeapTrc;
{$ENDIF}

begin
  {$IFDEF HEAPTRC}
  SetHeapTraceOutput('heap.log');
  {$ENDIF}

  // Votre code ici
end.
```

√Ä la fin de l'ex√©cution, `heap.log` contiendra :
```
Heap dump by heaptrc unit
10 memory blocks allocated : 1024 bytes
8 memory blocks freed : 824 bytes
2 unfreed memory blocks : 200 bytes

Call trace for block $00401234 size 100
  $00401567  TMONOBJET__CREATE
  $00401890  main
```

**Pr√©vention** :
```pascal
// ‚úÖ Toujours utiliser try-finally
Obj := TMonObjet.Create;  
try
  // Code
finally
  Obj.Free;  // Garantit la lib√©ration
end;
```

## Optimisations sp√©cifiques aux plateformes

### Windows

**Allocations de grande taille** :
```pascal
{$IFDEF WINDOWS}
uses Windows;

function AllocGrande(Size: NativeUInt): Pointer;  
begin
  // VirtualAlloc pour grandes allocations (> 1 MB)
  Result := VirtualAlloc(nil, Size, MEM_COMMIT or MEM_RESERVE, PAGE_READWRITE);
end;

procedure FreeGrande(P: Pointer);  
begin
  VirtualFree(P, 0, MEM_RELEASE);
end;
{$ENDIF}
```

**Large Pages (Huge Pages)** :
```pascal
{$IFDEF WINDOWS}
// N√©cessite privil√®ges administrateur
function AllocLargePages(Size: NativeUInt): Pointer;  
begin
  Result := VirtualAlloc(nil, Size, MEM_COMMIT or MEM_RESERVE or MEM_LARGE_PAGES,
                         PAGE_READWRITE);
end;
// Pages de 2 MB au lieu de 4 KB
// R√©duit les TLB misses ‚Üí +10-20% performance
{$ENDIF}
```

### Linux

**mmap pour grandes allocations** :
```pascal
{$IFDEF LINUX}
uses BaseUnix;

function AllocGrande(Size: csize_t): Pointer;  
begin
  Result := fpmmap(nil, Size, PROT_READ or PROT_WRITE,
                   MAP_PRIVATE or MAP_ANONYMOUS, -1, 0);
end;

procedure FreeGrande(P: Pointer; Size: csize_t);  
begin
  fpmunmap(P, Size);
end;
{$ENDIF}
```

**Huge Pages Linux** :
```pascal
{$IFDEF LINUX}
// N√©cessite configuration syst√®me
// echo 20 > /proc/sys/vm/nr_hugepages

function AllocHugePages(Size: csize_t): Pointer;  
begin
  Result := fpmmap(nil, Size, PROT_READ or PROT_WRITE,
                   MAP_PRIVATE or MAP_ANONYMOUS or MAP_HUGETLB, -1, 0);
end;
{$ENDIF}
```

## Cache Prefetching

### Prefetch manuel (avanc√©)

FreePascal supporte les intrinsics de prefetch sur x86/x64 :

```pascal
{$ASMMODE INTEL}

procedure TraiterAvecPrefetch(Data: PInteger; Count: Integer);  
var
  i: Integer;
begin
  for i := 0 to Count - 1 do
  begin
    // Prefetch des donn√©es 64 √©l√©ments √† l'avance
    if i + 64 < Count then
      asm
        mov rax, Data
        prefetchnta [rax + (i + 64) * 4]
      end;

    // Traiter l'√©l√©ment courant
    Traiter(Data[i]);
  end;
end;
```

**Types de prefetch** :
- `prefetchnta` : Non-temporal (ne pollue pas le cache)
- `prefetcht0` : Tous les niveaux de cache
- `prefetcht1` : L2 et L3
- `prefetcht2` : L3 uniquement

**Quand utiliser** :
- Grandes boucles avec stride pr√©visible
- Latence d'acc√®s m√©moire importante
- Profiling montre beaucoup de cache misses

## Alignment (Alignement) m√©moire

### Pourquoi c'est important ?

Le CPU acc√®de √† la m√©moire par blocs align√©s :
- 32-bit : alignement sur 4 bytes
- 64-bit : alignement sur 8 bytes
- SIMD (SSE) : alignement sur 16 bytes
- SIMD (AVX) : alignement sur 32 bytes

**‚ùå Mauvais : Non align√©**
```pascal
type
  TData = packed record
    Flag: Byte;      // Offset 0
    Value: Int64;    // Offset 1 (non align√©!)
  end;

// Acc√®s √† Value n√©cessite 2 acc√®s m√©moire (lent)
```

**‚úÖ Bon : Align√©**
```pascal
type
  TData = record
    Flag: Byte;      // Offset 0
    Padding: array[0..6] of Byte;  // Offset 1-7
    Value: Int64;    // Offset 8 (align√© sur 8!)
  end;

// Acc√®s √† Value n√©cessite 1 acc√®s m√©moire (rapide)
```

### Alignement automatique en FreePascal

FreePascal aligne automatiquement les champs de record :

```pascal
type
  TAutoAlign = record
    A: Byte;    // Offset 0
                // Padding automatique 1-3
    B: Integer; // Offset 4 (align√©)
                // Padding automatique 5-7
    C: Int64;   // Offset 8 (align√©)
  end;
// SizeOf(TAutoAlign) = 16 (pas 13)
```

**D√©sactiver l'alignement** :
```pascal
type
  TPacked = packed record
    A: Byte;    // Offset 0
    B: Integer; // Offset 1 (pas align√©)
    C: Int64;   // Offset 5 (pas align√©)
  end;
// SizeOf(TPacked) = 13

// ‚ö†Ô∏è Plus compact mais acc√®s plus lents
```

### Alignement pour SIMD

```pascal
type
  TAlignedArray = record
    Data: array[0..15] of Single;
  end align 16;  // Force alignement 16 bytes pour SSE

// Ou avec directive
{$CODEALIGN RECORDMIN=16}
type
  TAlignedSSE = record
    Data: array[0..3] of Single;
  end;
```

## Mesurer les cache misses

### Sur Linux avec Perf

```bash
# Compiler le programme
fpc -O3 programme.pas

# Mesurer les cache misses
perf stat -e cache-references,cache-misses,instructions ./programme

# Sortie exemple :
#   12,345,678  cache-references
#      456,789  cache-misses     # 3.7% miss rate
#  987,654,321  instructions
```

**Interpr√©tation** :
- **< 1% miss rate** : Excellent (tr√®s cache-friendly)
- **1-5% miss rate** : Bon
- **5-10% miss rate** : Moyen (optimisations possibles)
- **> 10% miss rate** : Mauvais (probl√®mes d'acc√®s m√©moire)

### Sur Windows avec Intel VTune

Dans VTune, s√©lectionner l'analyse "Memory Access" :
- L1 Data Cache Misses
- L2 Cache Misses
- L3 Cache Misses
- DRAM Accesses

## Checklist d'optimisation m√©moire

Avant d'optimiser :
- [ ] Profiler pour identifier les hotspots
- [ ] Mesurer les cache misses
- [ ] Identifier les patterns d'acc√®s

Optimisations √† tenter :
- [ ] R√©duire la taille des structures de donn√©es
- [ ] Am√©liorer la localit√© spatiale (donn√©es adjacentes)
- [ ] Am√©liorer la localit√© temporelle (r√©utilisation)
- [ ] Remplacer linked lists par arrays
- [ ] Pr√©-allouer au lieu d'allouer en boucle
- [ ] Utiliser object pooling pour objets fr√©quents
- [ ] Aligner les structures pour SIMD
- [ ] Consid√©rer SoA au lieu de AoS pour traitement par lots

Apr√®s optimisation :
- [ ] Re-mesurer les performances
- [ ] V√©rifier que les cache misses ont diminu√©
- [ ] Valider que le code reste correct

## Pi√®ges courants

### 1. Padding excessif
```pascal
// ‚ùå Gaspillage m√©moire
type
  TData = record
    A: Byte;       // 1 byte
    Padding1: array[0..6] of Byte;  // 7 bytes gaspill√©s
    B: Int64;      // 8 bytes
    Padding2: array[0..6] of Byte;  // 7 bytes gaspill√©s
    C: Byte;       // 1 byte
  end;
// 24 bytes pour stocker 10 bytes utiles
```

### 2. Fragmentation m√©moire
```pascal
// ‚ùå Cause de la fragmentation
for i := 1 to 10000 do  
begin
  if Random(2) = 0 then
    Liste.Add(GetMem(Random(1000)));
  else
    FreeMem(Liste[Random(Liste.Count)]);
end;
// Allocations/lib√©rations al√©atoires ‚Üí fragmentation
```

**‚úÖ Solution** : Utiliser un pool ou pr√©-allouer
```pascal
// Pr√©-allocation d'un grand bloc
const
  PoolSize = 10000 * 1000;  // 10 MB
var
  Pool: PByte;
  Offset: Integer;
begin
  Pool := GetMem(PoolSize);
  Offset := 0;
  // Allouer dans le pool (pas de fragmentation)
end;
```

### 3. Copies inutiles
```pascal
// ‚ùå Copie d'un grand record
type
  TGrosRecord = record
    Data: array[0..9999] of Integer;  // 40 KB
  end;

function Traiter(R: TGrosRecord): Integer;  // Passage par valeur  
begin
  Result := R.Data[0];
end;
// Copie de 40 KB √† chaque appel !

// ‚úÖ Passage par r√©f√©rence
function Traiter(const R: TGrosRecord): Integer;  
begin
  Result := R.Data[0];
end;
// Pas de copie, juste un pointeur
```

### 4. String temporaires
```pascal
// ‚ùå Allocations string multiples
var
  S: String;
  i: Integer;
begin
  S := '';
  for i := 1 to 10000 do
    S := S + IntToStr(i) + ',';  // R√©allocation √† chaque it√©ration !
end;

// ‚úÖ Utiliser TStringBuilder
uses SysUtils;  
var
  SB: TStringBuilder;
  i: Integer;
begin
  SB := TStringBuilder.Create;
  try
    for i := 1 to 10000 do
      SB.Append(IntToStr(i)).Append(',');
    Result := SB.ToString;
  finally
    SB.Free;
  end;
end;
// Pas de r√©allocations constantes
```

## Techniques avanc√©es

### 1. Memory-Mapped Files

Pour traiter de tr√®s gros fichiers sans charger tout en RAM :

**Windows** :
```pascal
{$IFDEF WINDOWS}
uses Windows;

type
  TMappedFile = class
  private
    FHandle: THandle;
    FMapping: THandle;
    FData: Pointer;
    FSize: Int64;
  public
    constructor Create(const FileName: string);
    destructor Destroy; override;
    property Data: Pointer read FData;
    property Size: Int64 read FSize;
  end;

constructor TMappedFile.Create(const FileName: string);  
begin
  inherited Create;

  // Ouvrir le fichier
  FHandle := CreateFile(PChar(FileName), GENERIC_READ, FILE_SHARE_READ,
                        nil, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, 0);

  if FHandle = INVALID_HANDLE_VALUE then
    raise Exception.Create('Cannot open file');

  // Obtenir la taille
  Int64Rec(FSize).Lo := GetFileSize(FHandle, @Int64Rec(FSize).Hi);

  // Cr√©er le mapping
  FMapping := CreateFileMapping(FHandle, nil, PAGE_READONLY,
                                Int64Rec(FSize).Hi, Int64Rec(FSize).Lo, nil);

  if FMapping = 0 then
  begin
    CloseHandle(FHandle);
    raise Exception.Create('Cannot create mapping');
  end;

  // Mapper en m√©moire
  FData := MapViewOfFile(FMapping, FILE_MAP_READ, 0, 0, 0);

  if FData = nil then
  begin
    CloseHandle(FMapping);
    CloseHandle(FHandle);
    raise Exception.Create('Cannot map file');
  end;
end;

destructor TMappedFile.Destroy;  
begin
  if FData <> nil then
    UnmapViewOfFile(FData);
  if FMapping <> 0 then
    CloseHandle(FMapping);
  if FHandle <> INVALID_HANDLE_VALUE then
    CloseHandle(FHandle);
  inherited;
end;

// Utilisation
var
  MF: TMappedFile;
  Data: PByte;
begin
  MF := TMappedFile.Create('gros_fichier.dat');  // 10 GB
  try
    Data := MF.Data;
    // Acc√®s direct comme si c'√©tait en RAM
    // L'OS charge les pages n√©cessaires automatiquement
    ProcessByte(Data[1234567]);
  finally
    MF.Free;
  end;
end;
{$ENDIF}
```

**Linux** :
```pascal
{$IFDEF LINUX}
uses BaseUnix, Unix;

type
  TMappedFile = class
  private
    FHandle: cint;
    FData: Pointer;
    FSize: csize_t;
  public
    constructor Create(const FileName: string);
    destructor Destroy; override;
    property Data: Pointer read FData;
    property Size: csize_t read FSize;
  end;

constructor TMappedFile.Create(const FileName: string);  
var
  StatBuf: stat;
begin
  inherited Create;

  // Ouvrir le fichier
  FHandle := FpOpen(FileName, O_RDONLY);
  if FHandle = -1 then
    raise Exception.Create('Cannot open file');

  // Obtenir la taille
  if FpFStat(FHandle, StatBuf) = -1 then
  begin
    FpClose(FHandle);
    raise Exception.Create('Cannot stat file');
  end;
  FSize := StatBuf.st_size;

  // Mapper en m√©moire
  FData := fpmmap(nil, FSize, PROT_READ, MAP_PRIVATE, FHandle, 0);

  if FData = MAP_FAILED then
  begin
    FpClose(FHandle);
    raise Exception.Create('Cannot map file');
  end;
end;

destructor TMappedFile.Destroy;  
begin
  if FData <> MAP_FAILED then
    fpmunmap(FData, FSize);
  if FHandle <> -1 then
    FpClose(FHandle);
  inherited;
end;
{$ENDIF}
```

**Avantages** :
- Pas besoin de charger tout le fichier en RAM
- L'OS g√®re le cache automatiquement
- Tr√®s rapide pour acc√®s al√©atoire

### 2. Custom Memory Allocator

Pour des cas tr√®s sp√©cifiques, cr√©er un allocateur personnalis√© :

```pascal
type
  TArena = class
  private
    FBuffer: PByte;
    FSize: NativeUInt;
    FOffset: NativeUInt;
  public
    constructor Create(Size: NativeUInt);
    destructor Destroy; override;
    function Alloc(Size: NativeUInt): Pointer;
    procedure Reset;  // R√©initialiser sans lib√©rer
  end;

constructor TArena.Create(Size: NativeUInt);  
begin
  inherited Create;
  FSize := Size;
  FBuffer := GetMem(Size);
  FOffset := 0;
end;

destructor TArena.Destroy;  
begin
  FreeMem(FBuffer);
  inherited;
end;

function TArena.Alloc(Size: NativeUInt): Pointer;  
begin
  if FOffset + Size > FSize then
    raise Exception.Create('Arena full');

  Result := FBuffer + FOffset;
  Inc(FOffset, Size);
end;

procedure TArena.Reset;  
begin
  FOffset := 0;  // R√©utiliser la m√©moire
end;

// Utilisation
var
  Arena: TArena;
  P: Pointer;
  i: Integer;
begin
  Arena := TArena.Create(1024 * 1024);  // 1 MB
  try
    for i := 1 to 1000 do
    begin
      // Traitement
      P := Arena.Alloc(1024);
      // Utiliser P
    end;

    // R√©initialiser et r√©utiliser
    Arena.Reset;

    for i := 1 to 1000 do
    begin
      P := Arena.Alloc(1024);
      // R√©utilise la m√™me m√©moire
    end;
  finally
    Arena.Free;
  end;
end;
```

**Avantages** :
- Allocation O(1) (juste un incr√©ment de pointeur)
- Pas de fragmentation
- Lib√©ration en masse (Reset)
- Parfait pour donn√©es temporaires

### 3. Copy-on-Write avec String

FreePascal utilise Copy-on-Write pour les strings :

```pascal
var
  S1, S2: String;
begin
  S1 := 'Hello World';
  S2 := S1;  // Pas de copie, juste un compteur de r√©f√©rence

  // S1 et S2 pointent vers la m√™me m√©moire
  // √âconomie de m√©moire et de temps

  S2 := S2 + '!';  // Maintenant copie (write)
  // S1 = 'Hello World'
  // S2 = 'Hello World!'
end;
```

**Implications** :
- Passage de string par valeur est peu co√ªteux
- Modification d√©clenche copie (COW = Copy-on-Write)
- Thread-safe automatiquement

### 4. Shared Memory entre processus

Pour communiquer entre processus sans copie :

**Windows** :
```pascal
{$IFDEF WINDOWS}
uses Windows;

type
  TSharedMemory = class
  private
    FMapping: THandle;
    FData: Pointer;
    FSize: Cardinal;
  public
    constructor Create(const Name: string; Size: Cardinal);
    destructor Destroy; override;
    property Data: Pointer read FData;
  end;

constructor TSharedMemory.Create(const Name: string; Size: Cardinal);  
begin
  inherited Create;
  FSize := Size;

  FMapping := CreateFileMapping(INVALID_HANDLE_VALUE, nil,
                                PAGE_READWRITE, 0, Size, PChar(Name));

  if FMapping = 0 then
    raise Exception.Create('Cannot create shared memory');

  FData := MapViewOfFile(FMapping, FILE_MAP_ALL_ACCESS, 0, 0, 0);

  if FData = nil then
  begin
    CloseHandle(FMapping);
    raise Exception.Create('Cannot map shared memory');
  end;
end;

destructor TSharedMemory.Destroy;  
begin
  if FData <> nil then
    UnmapViewOfFile(FData);
  if FMapping <> 0 then
    CloseHandle(FMapping);
  inherited;
end;
{$ENDIF}
```

**Linux** :
```pascal
{$IFDEF LINUX}
uses BaseUnix, Unix;

type
  TSharedMemory = class
  private
    FShmId: cint;
    FData: Pointer;
    FSize: csize_t;
  public
    constructor Create(Key: key_t; Size: csize_t);
    destructor Destroy; override;
    property Data: Pointer read FData;
  end;

constructor TSharedMemory.Create(Key: key_t; Size: csize_t);  
begin
  inherited Create;
  FSize := Size;

  // Cr√©er le segment de m√©moire partag√©e
  FShmId := shmget(Key, Size, IPC_CREAT or &666);

  if FShmId = -1 then
    raise Exception.Create('Cannot create shared memory');

  // Attacher √† l'espace d'adressage
  FData := shmat(FShmId, nil, 0);

  if FData = Pointer(-1) then
  begin
    shmctl(FShmId, IPC_RMID, nil);
    raise Exception.Create('Cannot attach shared memory');
  end;
end;

destructor TSharedMemory.Destroy;  
begin
  if FData <> Pointer(-1) then
    shmdt(FData);
  if FShmId <> -1 then
    shmctl(FShmId, IPC_RMID, nil);
  inherited;
end;
{$ENDIF}
```

## Exemples pratiques d'optimisation

### Exemple 1 : Traitement d'images

**‚ùå Version non optimis√©e** :
```pascal
type
  TPixel = record
    R, G, B, A: Byte;
  end;
  TImage = array of array of TPixel;

procedure ConvertToGrayscale(var Img: TImage);  
var
  x, y: Integer;
  Gray: Byte;
begin
  for y := 0 to High(Img) do
    for x := 0 to High(Img[y]) do
    begin
      Gray := Round(0.299 * Img[y][x].R +
                    0.587 * Img[y][x].G +
                    0.114 * Img[y][x].B);
      Img[y][x].R := Gray;
      Img[y][x].G := Gray;
      Img[y][x].B := Gray;
    end;
end;
// Array 2D ‚Üí acc√®s lent
// Calculs en virgule flottante ‚Üí lent
```

**‚úÖ Version optimis√©e** :
```pascal
type
  TPixel = packed record
    R, G, B, A: Byte;
  end;
  TImageFlat = array of TPixel;  // Array 1D

procedure ConvertToGrayscaleFast(var Img: TImageFlat);  
var
  i: Integer;
  P: ^TPixel;
  Gray: Byte;
begin
  P := @Img[0];
  for i := 0 to High(Img) do
  begin
    // Approximation enti√®re (plus rapide)
    Gray := (P^.R * 77 + P^.G * 150 + P^.B * 29) shr 8;
    P^.R := Gray;
    P^.G := Gray;
    P^.B := Gray;
    Inc(P);
  end;
end;
// Array 1D ‚Üí acc√®s s√©quentiel rapide
// Arithm√©tique enti√®re ‚Üí rapide
// Pointeur direct ‚Üí pas de calcul d'index

// Performance : 10x plus rapide
```

### Exemple 2 : Recherche dans une grande liste

**‚ùå Version non optimis√©e** :
```pascal
type
  TUser = record
    ID: Integer;
    Name: String;
    Email: String;
    Age: Integer;
  end;
  TUserList = array of TUser;

function FindUserByID(const Users: TUserList; ID: Integer): Integer;  
var
  i: Integer;
begin
  Result := -1;
  for i := 0 to High(Users) do
    if Users[i].ID = ID then
    begin
      Result := i;
      Exit;
    end;
end;
// O(n) recherche lin√©aire
// Pour 1,000,000 utilisateurs : ~500,000 comparaisons
```

**‚úÖ Version optimis√©e** :
```pascal
uses Generics.Collections;

type
  TUser = record
    ID: Integer;
    Name: String;
    Email: String;
    Age: Integer;
  end;
  TUserDict = TDictionary<Integer, TUser>;

var
  Users: TUserDict;

function FindUserByID(ID: Integer): Boolean;  
var
  User: TUser;
begin
  Result := Users.TryGetValue(ID, User);
end;
// O(1) recherche par hash
// Pour 1,000,000 utilisateurs : 1 lookup
// Performance : 500,000x plus rapide !
```

### Exemple 3 : Calcul intensif avec cache

**‚ùå Version sans cache** :
```pascal
function Fibonacci(N: Integer): Int64;  
begin
  if N <= 1 then
    Result := N
  else
    Result := Fibonacci(N - 1) + Fibonacci(N - 2);
end;

// Fib(40) = ~1 milliard d'appels r√©cursifs
// Temps : ~2 secondes
```

**‚úÖ Version avec cache (memoization)** :
```pascal
var
  FibCache: array[0..100] of Int64;
  CacheInit: Boolean = False;

function FibonacciFast(N: Integer): Int64;  
begin
  if not CacheInit then
  begin
    FillQWord(FibCache, Length(FibCache), QWord(-1));
    CacheInit := True;
  end;

  if N <= 1 then
  begin
    Result := N;
    Exit;
  end;

  if FibCache[N] <> -1 then
  begin
    Result := FibCache[N];  // Hit cache
    Exit;
  end;

  Result := FibonacciFast(N - 1) + FibonacciFast(N - 2);
  FibCache[N] := Result;  // Mettre en cache
end;

// Fib(40) = 40 calculs uniques
// Temps : ~0.0001 secondes
// Performance : 20,000x plus rapide !
```

## Comparaison Windows vs Linux

### Performances d'allocation m√©moire

**Test** : 1,000,000 allocations de 1 KB

| Syst√®me | Temps | Memory Manager |
|---------|-------|----------------|
| Windows 10 | 450 ms | HeapAlloc |
| Ubuntu 22.04 | 280 ms | ptmalloc |
| Ubuntu + cmem | 220 ms | glibc malloc |

**Recommandation** :
```pascal
{$IFDEF LINUX}
uses cmem;  // Utiliser glibc malloc sous Linux (plus rapide)
{$ENDIF}
```

### Huge Pages

**Windows** :
- Support via VirtualAlloc avec MEM_LARGE_PAGES
- N√©cessite privil√®ge "SeLockMemoryPrivilege"
- Configuration via Group Policy

**Linux** :
- Support natif plus flexible
- Configuration : `/proc/sys/vm/nr_hugepages`
- Transparent Huge Pages (THP) automatique

```bash
# Linux : activer THP
echo always > /sys/kernel/mm/transparent_hugepage/enabled

# R√©server des huge pages
echo 1024 > /proc/sys/vm/nr_hugepages
```

## R√©sum√© des optimisations m√©moire

### Priorit√© 1 (Impact majeur ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)
- Am√©liorer la localit√© spatiale (donn√©es adjacentes)
- Utiliser des arrays au lieu de linked lists
- R√©duire la taille des structures de donn√©es
- √âviter les allocations en boucle

### Priorit√© 2 (Impact important ‚≠ê‚≠ê‚≠ê‚≠ê)
- Pr√©-allouer et r√©utiliser la m√©moire
- Utiliser object pooling
- Privil√©gier le stack pour petites donn√©es
- Impl√©menter du caching

### Priorit√© 3 (Impact moyen ‚≠ê‚≠ê‚≠ê)
- Aligner les structures pour SIMD
- Utiliser SoA pour traitement par lots
- Memory-mapped files pour gros fichiers
- Optimiser les string avec TStringBuilder

### Priorit√© 4 (Impact faible ‚≠ê‚≠ê)
- Prefetching manuel
- Custom allocators
- Huge pages
- Shared memory

## Outils de diagnostic

### HeapTrc (FreePascal int√©gr√©)
```bash
fpc -gh programme.pas
./programme
# Affiche les fuites m√©moire √† la fin
```

### Valgrind (Linux)
```bash
valgrind --leak-check=full --show-leak-kinds=all ./programme
```

### Application Verifier (Windows)
```bash
appverif.exe  # GUI pour configurer
# Active la d√©tection de corruptions m√©moire
```

### Dr. Memory (Multi-plateforme)
```bash
drmemory -- ./programme
# D√©tecte fuites et acc√®s invalides
```

## Conclusion

L'optimisation m√©moire et des caches est souvent plus efficace que l'optimisation algorithmique pure. Les points cl√©s √† retenir :

‚úÖ **La hi√©rarchie m√©moire est critique** : L'acc√®s RAM est 100x plus lent que le cache L1

‚úÖ **Localit√© spatiale** : Garder les donn√©es adjacentes en m√©moire

‚úÖ **Localit√© temporelle** : R√©utiliser les donn√©es r√©cemment acc√©d√©es

‚úÖ **Structures compactes** : Moins de m√©moire = plus de donn√©es en cache

‚úÖ **Patterns d'acc√®s** : S√©quentiel > Stride > Al√©atoire

‚úÖ **Arrays > Linked Lists** : Pour la plupart des cas

‚úÖ **Pr√©-allocation** : √âviter les allocations r√©p√©t√©es

‚úÖ **Mesurer toujours** : Utiliser Perf/VTune pour v√©rifier les cache misses

Les optimisations m√©moire sont particuli√®rement importantes dans le d√©veloppement multi-plateforme, car les performances peuvent varier significativement entre Windows et Linux. Testez toujours sur les deux plateformes !

---

*Note : Ce tutoriel fait partie de la formation "FreePascal/Lazarus - Niveau D√©veloppeur Avanc√© - Edition Multi-plateforme Windows/Ubuntu"*

‚è≠Ô∏è [SIMD et vectorisation](/20-optimisation-performance/03-simd-vectorisation.md)
