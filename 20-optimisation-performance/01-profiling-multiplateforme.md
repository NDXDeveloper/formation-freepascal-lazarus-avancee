üîù Retour au [Sommaire](/SOMMAIRE.md)

# 20.1 Profiling Multi-plateforme

## Introduction

Le **profiling** (ou profilage en fran√ßais) est l'une des comp√©tences les plus importantes d'un d√©veloppeur avanc√©. Il s'agit de l'art de mesurer et d'analyser les performances d'un programme pour identifier o√π et comment l'optimiser. Dans le contexte du d√©veloppement multi-plateforme avec FreePascal/Lazarus, ma√Ætriser les outils de profiling sur Windows et Linux est essentiel pour cr√©er des applications performantes sur les deux syst√®mes.

## Qu'est-ce que le profiling ?

### D√©finition simple

Le profiling consiste √† **observer un programme pendant son ex√©cution** pour collecter des informations sur :

- **Le temps** : Combien de temps chaque fonction prend-elle ?
- **La m√©moire** : Combien de m√©moire est utilis√©e et o√π ?
- **Les appels** : Quelles fonctions appellent quelles autres fonctions ?
- **Les ressources** : Comment le CPU, le cache, et les autres ressources sont-ils utilis√©s ?

### Pourquoi profiler ?

L'optimisation pr√©matur√©e est souvent cit√©e comme "la racine de tous les maux" en programmation. Le profiling vous permet d'optimiser **au bon endroit** :

‚ùå **Sans profiling** :
```
"Je pense que cette boucle est lente, je vais l'optimiser..."
‚Üí 2 heures de travail
‚Üí Gain : 0.1% de performance
```

‚úÖ **Avec profiling** :
```
"Le profiler montre que 80% du temps est dans la fonction X"
‚Üí 30 minutes de travail sur X
‚Üí Gain : 60% de performance globale
```

### La r√®gle des 80/20 (Principe de Pareto)

En g√©n√©ral, **80% du temps d'ex√©cution** d'un programme est pass√© dans **20% du code**. Le profiling permet d'identifier pr√©cis√©ment ces 20% critiques, appel√©s **hotspots** (points chauds).

## Types de profiling

Il existe plusieurs approches pour profiler un programme, chacune avec ses avantages et inconv√©nients.

### 1. Profiling par √©chantillonnage (Sampling)

**Principe** : Le profiler interrompt r√©guli√®rement le programme (par exemple toutes les 10ms) et enregistre quelle fonction est en cours d'ex√©cution.

**Avantages** :
- Tr√®s faible overhead (< 5% de ralentissement)
- Adapt√© aux programmes en production
- Donne une vue statistique r√©aliste

**Inconv√©nients** :
- Moins pr√©cis pour les fonctions tr√®s rapides
- Peut manquer des √©v√©nements rares

**Outils** :
- Windows : Intel VTune, Very Sleepy
- Linux : Perf
- Multi-plateforme : Profilers int√©gr√©s dans certains IDEs

**Exemple de r√©sultat** :
```
Fonction                    √âchantillons    % Total
--------------------------------------------------
TForm1.CalculComplexe       4,523          45.2%  
System.Move                 1,645          16.4%  
TDatabase.Query             987            9.8%
```

### 2. Profiling par instrumentation

**Principe** : Le profiler ins√®re du code de mesure dans le programme (soit √† la compilation, soit √† l'ex√©cution) pour enregistrer chaque entr√©e et sortie de fonction.

**Avantages** :
- Tr√®s pr√©cis, capture tous les appels
- Compte exact des appels et du timing
- Id√©al pour analyser le flot d'ex√©cution

**Inconv√©nients** :
- Overhead √©lev√© (10x √† 50x plus lent)
- Modifie l√©g√®rement le comportement du programme
- G√©n√®re beaucoup de donn√©es

**Outils** :
- Linux : Valgrind (Callgrind)
- Windows : Certains profilers commerciaux

**Exemple de r√©sultat** :
```
Fonction                    Appels     Temps Self    Temps Total
-----------------------------------------------------------------
TForm1.CalculComplexe       1          2.450s        3.200s
  ‚îî‚îÄ TMath.Sqrt             1,000,000  0.650s        0.650s
  ‚îî‚îÄ TMath.Sin              1,000,000  0.750s        0.750s
```

### 3. Profiling manuel (chronom√©trage)

**Principe** : Le d√©veloppeur ins√®re manuellement du code pour mesurer le temps dans des sections sp√©cifiques.

**Avantages** :
- Contr√¥le total sur ce qui est mesur√©
- Aucun outil externe n√©cessaire
- Peut √™tre laiss√© en production

**Inconv√©nients** :
- Fastidieux et source d'erreurs
- Ne donne qu'une vue partielle
- Difficile √† maintenir

**Exemple en FreePascal** :
```pascal
uses SysUtils, DateUtils;

var
  StartTime, EndTime: TDateTime;
  ElapsedMs: Int64;
begin
  StartTime := Now;

  // Code √† profiler
  CalculComplexe();

  EndTime := Now;
  ElapsedMs := MilliSecondsBetween(EndTime, StartTime);
  WriteLn('Temps √©coul√© : ', ElapsedMs, ' ms');
end;
```

### 4. Profiling m√©moire

**Principe** : Analyse de l'utilisation de la m√©moire (allocation, lib√©ration, fuites).

**Avantages** :
- D√©tecte les fuites m√©moire
- Identifie les allocations excessives
- Am√©liore la stabilit√©

**Inconv√©nients** :
- Overhead souvent √©lev√©
- N√©cessite des outils sp√©cialis√©s

**Outils** :
- Linux : Valgrind (Memcheck, Massif)
- Windows : Dr. Memory, Application Verifier
- Multi-plateforme : Heaptrc (int√©gr√© √† FreePascal)

## Concepts fondamentaux du profiling

### Hotspot (Point chaud)

Un **hotspot** est une fonction ou une portion de code qui consomme une part significative du temps d'ex√©cution total.

**Crit√®res** :
- **> 20%** du temps total ‚Üí Hotspot critique (√† optimiser en priorit√©)
- **10-20%** ‚Üí Hotspot important (optimisation recommand√©e)
- **5-10%** ‚Üí Hotspot mineur (optimisation optionnelle)
- **< 5%** ‚Üí N√©gligeable (ne pas perdre de temps dessus)

**Exemple** :
```
Si votre programme prend 10 secondes, et qu'une fonction prend 6 secondes,  
c'est un hotspot de 60% ‚Üí TR√àS haute priorit√© d'optimisation
```

### Call Graph (Graphe d'appels)

Le **call graph** montre les relations entre les fonctions : qui appelle qui, et combien de fois.

**Exemple visuel** :
```
Main (100% du temps)
‚îú‚îÄ InitApplication (2%)
‚îú‚îÄ ProcessData (90%)
‚îÇ  ‚îú‚îÄ LoadFile (10%)
‚îÇ  ‚îú‚îÄ ParseData (30%)
‚îÇ  ‚îÇ  ‚îî‚îÄ ValidateField (25%)
‚îÇ  ‚îî‚îÄ SaveResults (50%)
‚îî‚îÄ CleanUp (8%)
```

**Utilit√©** :
- Comprendre le contexte d'un hotspot
- Identifier les cha√Ænes d'appels co√ªteuses
- D√©tecter les fonctions appel√©es trop souvent

### Self Time vs Total Time

Deux m√©triques fondamentales pour chaque fonction :

**Self Time (Temps propre)** :
- Temps pass√© **dans la fonction elle-m√™me**
- N'inclut PAS le temps des sous-fonctions appel√©es
- Utile pour savoir si la fonction fait trop de calculs

**Total Time (Temps inclusif)** :
- Temps total incluant **les sous-fonctions**
- Temps de l'entr√©e √† la sortie de la fonction
- Utile pour identifier les chemins critiques

**Exemple** :
```pascal
procedure Externe;       // Total: 10s, Self: 1s  
begin
  // 1s de travail propre
  Interne();            // 9s
end;

procedure Interne;       // Total: 9s, Self: 9s  
begin
  // 9s de travail propre
end;
```

Dans cet exemple :
- `Interne` est le vrai hotspot (9s de self time)
- `Externe` semble co√ªteuse en total time, mais elle-m√™me est rapide

### IPC (Instructions Per Cycle)

**IPC** mesure l'efficacit√© du code au niveau du processeur :

- **IPC √©lev√© (> 2.0)** : Code bien optimis√©, utilise bien le pipeline CPU
- **IPC moyen (1.0-2.0)** : Code standard
- **IPC faible (< 1.0)** : Code inefficace, beaucoup d'attentes (cache miss, branch misprediction)

Cette m√©trique est avanc√©e et n√©cessite des profilers mat√©riels (Intel VTune, Perf avec compteurs PMU).

### Cache Miss

Le **cache miss** se produit quand le CPU doit aller chercher des donn√©es en RAM au lieu du cache (beaucoup plus lent).

**Impact** :
- Cache L1 hit : ~1 cycle
- Cache L2 hit : ~10 cycles
- Cache L3 hit : ~40 cycles
- RAM : ~200 cycles

Un taux de cache miss √©lev√© (> 10%) indique souvent des probl√®mes de **localit√© des donn√©es**.

## Workflow de profiling

Un profiling efficace suit g√©n√©ralement ces √©tapes :

### 1. Mesurer d'abord (Baseline)

Avant toute optimisation, √©tablissez une **baseline** (r√©f√©rence) :

```bash
# Exemple : temps d'ex√©cution initial
$ time ./monprogramme
real    0m5.234s  
user    0m5.123s  
sys     0m0.089s
```

Notez cette valeur. C'est votre point de d√©part.

### 2. Profiler

Utilisez un profiler pour identifier les hotspots :

```bash
# Linux avec Perf
$ perf record -g ./monprogramme
$ perf report
```

### 3. Analyser

Identifiez les fonctions qui consomment le plus de temps :

```
45% ‚Üí TDataProcessor.ParseCSV
20% ‚Üí System.AnsiStrings.Copy
15% ‚Üí TDatabase.ExecuteQuery
```

**Question √† se poser** :
- Pourquoi cette fonction est-elle si co√ªteuse ?
- Est-elle appel√©e trop souvent ?
- Fait-elle des op√©rations inutiles ?
- Peut-on la remplacer par quelque chose de plus efficace ?

### 4. Optimiser

Concentrez-vous sur le hotspot #1 uniquement :

**Mauvaise approche** :
```
J'optimise 10 fonctions qui repr√©sentent chacune 2% du temps
‚Üí Gain potentiel maximal : 20%
‚Üí Beaucoup de travail pour peu de gain
```

**Bonne approche** :
```
J'optimise LA fonction qui repr√©sente 45% du temps
‚Üí Gain potentiel : jusqu'√† 45%
‚Üí Un seul focus, maximum d'impact
```

### 5. Re-mesurer

Apr√®s optimisation, re-profiler pour v√©rifier le gain :

```bash
$ time ./monprogramme_optimise
real    0m2.987s    # Avant : 5.234s ‚Üí Gain de 43% ‚úì
```

**Important** : Si le gain est n√©gligeable ou inexistant, annulez l'optimisation et cherchez ailleurs.

### 6. It√©rer

R√©p√©tez le processus jusqu'√† atteindre vos objectifs de performance :

```
Cycle 1: 5.2s ‚Üí 3.0s (optimisation parsing CSV)  
Cycle 2: 3.0s ‚Üí 2.1s (optimisation requ√™tes DB)  
Cycle 3: 2.1s ‚Üí 1.8s (cache des r√©sultats)
‚Üí Performance finale : 1.8s (65% plus rapide)
```

## Diff√©rences multi-plateformes

### Outils par plateforme

| Plateforme | Profiler CPU | Profiler M√©moire | Interface |
|------------|--------------|------------------|-----------|
| **Windows** | Intel VTune, Very Sleepy | Dr. Memory | GUI |
| **Linux** | Perf, Valgrind | Valgrind (Memcheck) | CLI + GUI |
| **macOS** | Instruments | Instruments | GUI |
| **Multi-plateforme** | Manuel (chrono) | HeapTrc (FPC) | Code |

### Diff√©rences de performance

**Attention** : Les performances peuvent varier significativement entre Windows et Linux pour le m√™me code :

**Facteurs de variation** :
- **Compilateur** : Optimisations diff√©rentes selon l'OS
- **Biblioth√®ques** : GTK vs Win32 pour les interfaces
- **Syst√®me de fichiers** : NTFS vs ext4 ont des performances diff√©rentes
- **Gestion m√©moire** : Allocateurs m√©moire diff√©rents
- **Scheduler** : Ordonnancement des threads diff√©rent

**Exemple r√©el** :
```
Programme de traitement de fichiers :
- Windows : 5.2 secondes
- Linux : 3.8 secondes (27% plus rapide)

Raison : Les E/S fichiers sont plus rapides sur ext4 que NTFS
```

**Bonne pratique** : Profiler sur **les deux plateformes** si votre application doit √™tre performante partout.

## Pr√©parer son code pour le profiling

### 1. Compiler avec les symboles de d√©bogage

Pour que les profilers puissent afficher les noms de fonctions et les num√©ros de lignes :

**Dans Lazarus** :
1. `Project` ‚Üí `Project Options`
2. `Compiler Options` ‚Üí `Debugging`
3. Cochez `Generate debug info for GDB (-g)`
4. D√©cochez `Strip symbols from executable (-Xs)`

**En ligne de commande** :
```bash
fpc -g -gl monprogramme.pas
```

**Important** : Les symboles de d√©bogage n'affectent **pas** les performances mesur√©es, seulement la taille de l'ex√©cutable.

### 2. Compiler avec ou sans optimisations ?

Deux approches selon l'objectif :

**Mode Debug (sans optimisations)** :
```bash
fpc -g monprogramme.pas
```
- Avantages : Code plus lisible dans le profiler, correspondance exacte avec le source
- Inconv√©nients : Ne refl√®te pas les performances r√©elles en production

**Mode Release (avec optimisations)** :
```bash
fpc -O3 -g monprogramme.pas
```
- Avantages : Performances r√©alistes, c'est ce qui sera d√©ploy√©
- Inconv√©nients : Certaines fonctions peuvent √™tre inline, le code peut √™tre r√©organis√©

**Recommandation** :
- Profiler d'abord en **Release** pour avoir des mesures r√©alistes
- Si besoin de plus de d√©tails, re-profiler en Debug certaines sections

### 3. Utiliser des builds s√©par√©s

Cr√©ez des configurations de build dans Lazarus :

```
Debug Build:
  - Optimisations : D√©sactiv√©es
  - Symboles : Oui
  - Assertions : Activ√©es
  - Usage : D√©veloppement quotidien

Release Build:
  - Optimisations : Niveau 3 (-O3)
  - Symboles : Oui (pour profiling)
  - Assertions : D√©sactiv√©es
  - Usage : Tests de performance

Production Build:
  - Optimisations : Niveau 3 (-O3)
  - Symboles : Non (-Xs)
  - Assertions : D√©sactiv√©es
  - Usage : D√©ploiement final
```

### 4. √âviter le code qui fausse les mesures

Certains patterns de code peuvent donner des r√©sultats trompeurs :

**‚ùå Mauvais** : Chronom√®tre non repr√©sentatif
```pascal
// Code qui s'ex√©cute en 0.001s
// Le profiler peut le manquer en mode sampling
procedure TresCourte;  
begin
  X := X + 1;
end;
```

**‚úì Bon** : Code repr√©sentatif
```pascal
// Pour profiler du code tr√®s court, l'ex√©cuter en boucle
procedure TestPerformance;  
var i: Integer;  
begin
  for i := 1 to 1000000 do
    TresCourte();  // Maintenant mesurable
end;
```

## M√©triques importantes √† surveiller

### Temps d'ex√©cution

**Wall Clock Time (Temps r√©el)** :
- Temps total du d√©but √† la fin du programme
- Inclut TOUT : calculs, I/O, attentes, pauses
- C'est ce que l'utilisateur per√ßoit

**CPU Time (Temps CPU)** :
- Temps pendant lequel le CPU ex√©cute r√©ellement du code
- N'inclut PAS les attentes I/O
- Utile pour identifier le code co√ªteux en calculs

**Exemple** :
```
Programme qui lit un fichier de 1GB :
- Wall Clock Time : 30s
- CPU Time : 2s
‚Üí Le programme passe 28s √† attendre les I/O disque
‚Üí Optimiser le code ne servira √† rien, il faut optimiser les I/O
```

### Utilisation m√©moire

**Heap Usage** :
- M√©moire allou√©e dynamiquement (GetMem, New, objets)
- Surveiller les fuites et allocations excessives

**Stack Usage** :
- M√©moire pour les variables locales et appels de fonctions
- Rarement un probl√®me sauf r√©cursion profonde

### Nombre d'appels

Le nombre de fois qu'une fonction est appel√©e :

```
Fonction A : 5% du temps, appel√©e 1 fois
‚Üí Optimisation difficile, gain limit√©

Fonction B : 5% du temps, appel√©e 1,000,000 fois
‚Üí Optimiser B et/ou r√©duire le nombre d'appels
```

## Pi√®ges courants du profiling

### 1. Optimisation pr√©matur√©e

```
"L'optimisation pr√©matur√©e est la racine de tous les maux"
- Donald Knuth
```

**Ne jamais optimiser avant d'avoir profil√©.** Votre intuition sur ce qui est lent est souvent fausse.

### 2. Micro-optimisations inutiles

Optimiser des d√©tails qui repr√©sentent < 1% du temps total :

```pascal
// ‚ùå Perdre du temps sur √ßa
if (x = 0) then  // vs  if x = 0 then
```

**Impact r√©el** : 0.00001% de gain. Ne vaut pas la peine.

### 3. Effet observateur

Le simple fait de profiler peut changer le comportement du programme :

- Valgrind ralentit de 10x-50x ‚Üí Chauffe moins ‚Üí Moins de throttling CPU
- Profiling peut changer l'ordonnancement des threads
- Mesures chronom√©tr√©es peuvent introduire des biais

**Solution** : Faire plusieurs mesures et comparer les moyennes.

### 4. Comparer des ex√©cutions diff√©rentes

```
Test 1 : Programme seul ‚Üí 5.2s  
Test 2 : Programme + Chrome + 10 tabs ‚Üí 8.7s
```

**Conclusion erron√©e** : "Mon programme est devenu plus lent"  
**R√©alit√©** : La charge syst√®me √©tait diff√©rente  

**Solution** : Toujours profiler dans les **m√™mes conditions** (m√™me charge syst√®me, m√™me temp√©rature CPU, etc.)

### 5. Ignorer les variations

Un programme peut prendre 5.0s, puis 5.3s, puis 4.9s selon l'ex√©cution (cache, scheduler, etc.).

**Solution** :
```bash
# Lancer 10 fois et prendre la moyenne
for i in {1..10}; do time ./monprogramme; done
```

## Outils compl√©mentaires

En plus des profilers d√©di√©s, plusieurs outils sont utiles :

### Commande `time`

**Linux/macOS** :
```bash
time ./monprogramme
```

**Windows PowerShell** :
```powershell
Measure-Command { .\monprogramme.exe }
```

### HeapTrc (FreePascal int√©gr√©)

FreePascal inclut un traceur de heap pour d√©tecter les fuites m√©moire :

**Compilation** :
```bash
fpc -gh monprogramme.pas
```

**Ex√©cution** :
```bash
./monprogramme
```

√Ä la fin de l'ex√©cution, un rapport de fuites est affich√© :

```
Heap dump by heaptrc unit
123 memory blocks allocated : 45678 bytes
120 memory blocks freed     : 45234 bytes
3 unfreed memory blocks : 444 bytes

Call trace for block $00123456 size 148
  $00401234  TMONOBJET__CREATE
  $00401567  main
```

### Benchmarking avec FPCUnit

Pour des micro-benchmarks reproductibles :

```pascal
uses fpcunit, testutils, SysUtils, DateUtils;

procedure TTestPerformance.TestOptimisation;  
var
  StartTime: TDateTime;
  i: Integer;
const
  Iterations = 1000000;
begin
  StartTime := Now;
  for i := 1 to Iterations do
    FonctionAOptimiser();

  WriteLn('Temps pour ', Iterations, ' it√©rations: ',
          MilliSecondsBetween(Now, StartTime), ' ms');
end;
```

## Quand profiler ?

### Pendant le d√©veloppement

- **Rarement** : Focalisez sur la correction et la fonctionnalit√© d'abord
- **Sur demande** : Quand une fonctionnalit√© semble anormalement lente
- **Fin de sprint** : Check rapide avant de livrer

### Avant le d√©ploiement

- **Tests de charge** : Profiler sous conditions r√©alistes (1000 utilisateurs, gros fichiers, etc.)
- **Comparaison baseline** : Est-ce plus rapide/lent que la version pr√©c√©dente ?
- **Profiling multi-plateforme** : V√©rifier les performances sur Windows ET Linux

### En production (avec pr√©caution)

- **Monitoring l√©ger** : Temps de r√©ponse, throughput
- **Profiling sampling** : Acceptable en production (overhead faible)
- **Jamais d'instrumentation** : Trop lent pour la production

## Objectifs de performance r√©alistes

D√©finissez des objectifs mesurables avant d'optimiser :

**Mauvais objectif** : "Rendre le programme plus rapide"  
**Bon objectif** : "R√©duire le temps de chargement de 10s √† 2s"  

**Exemples d'objectifs** :
- Temps de r√©ponse < 100ms pour une requ√™te
- Capacit√© de traiter 10,000 transactions/seconde
- Utilisation m√©moire < 500 MB
- Temps de d√©marrage < 2 secondes

**Loi d'Amdahl** : Si une portion du code repr√©sente 50% du temps et que vous la rendez infiniment rapide, le gain maximal est de 50%.

```
Exemple :  
Programme : 10s total
- Partie A : 8s (80%)
- Partie B : 2s (20%)

Si on rend A infiniment rapide (0s) :  
Nouveau temps = 0s + 2s = 2s  
Gain maximal = 80% (m√™me si A est infiniment optimis√©)
```

## Prochaines √©tapes

Maintenant que vous comprenez les concepts fondamentaux du profiling multi-plateforme, les sections suivantes d√©tailleront les outils sp√©cifiques pour chaque syst√®me :

‚û°Ô∏è **Section 20.1.1 : Intel VTune (Windows)**
- Installation et configuration
- Utilisation pour identifier les hotspots
- Analyse des compteurs mat√©riels
- Optimisations sp√©cifiques Windows

‚û°Ô∏è **Section 20.1.2 : Perf et Valgrind (Linux)**
- Profiling avec Perf
- D√©tection de fuites m√©moire avec Valgrind
- Callgrind pour analyse d√©taill√©e
- Optimisations sp√©cifiques Linux

## R√©sum√© des points cl√©s

‚úÖ **Profiler avant d'optimiser** : Ne jamais optimiser sans mesures  
‚úÖ **R√®gle 80/20** : 80% du temps est dans 20% du code  
‚úÖ **Focus sur les hotspots** : Optimiser ce qui compte vraiment  
‚úÖ **Mesurer, optimiser, valider** : Workflow it√©ratif  
‚úÖ **Multi-plateforme** : Profiler sur Windows ET Linux  
‚úÖ **Outils appropri√©s** : Sampling pour prod, instrumentation pour debug  
‚úÖ **Symboles de d√©bogage** : Essentiels pour des r√©sultats lisibles  
‚úÖ **Objectifs mesurables** : D√©finir ce qu'on veut atteindre

Le profiling est une comp√©tence qui s'acquiert avec la pratique. Plus vous profilez, plus vous d√©velopperez une intuition sur ce qui peut causer des probl√®mes de performance, mais **toujours validez avec des mesures r√©elles**.

---

*Note : Ce tutoriel fait partie de la formation "FreePascal/Lazarus - Niveau D√©veloppeur Avanc√© - Edition Multi-plateforme Windows/Ubuntu"*

‚è≠Ô∏è [Intel VTune (Windows)](/20-optimisation-performance/01.1-intel-vtune-windows.md)
