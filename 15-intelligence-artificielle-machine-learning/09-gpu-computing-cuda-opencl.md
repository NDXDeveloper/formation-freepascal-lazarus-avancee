üîù Retour au [Sommaire](/SOMMAIRE.md)

# 15.9 GPU computing avec CUDA/OpenCL

## Introduction au Calcul GPU

Le **GPU (Graphics Processing Unit)** est un processeur sp√©cialis√© con√ßu √† l'origine pour les graphiques 3D, mais qui s'est r√©v√©l√© extr√™mement puissant pour les calculs parall√®les en g√©n√©ral.

### CPU vs GPU : La diff√©rence

**CPU (Processeur Central)**
- Quelques c≈ìurs puissants (4-16 typiquement)
- Excellent pour les t√¢ches s√©quentielles
- Bonne gestion des branchements complexes
- Latence faible

**GPU (Processeur Graphique)**
- Des milliers de c≈ìurs simples (1000-10000+)
- Excellent pour les calculs parall√®les massifs
- Optimis√© pour les op√©rations r√©p√©titives
- D√©bit tr√®s √©lev√©

### Analogie simple

Imaginez que vous devez peindre 1000 chaises :

**Approche CPU** : Un peintre tr√®s qualifi√© qui peint les chaises une par une, tr√®s vite et avec une grande pr√©cision.

**Approche GPU** : 1000 peintres moins qualifi√©s qui peignent toutes les chaises en m√™me temps. Chacun travaille plus lentement, mais ensemble ils finissent beaucoup plus vite !

### Quand utiliser le GPU ?

‚úÖ **Parfait pour :**
- Traitement d'images (filtres, convolutions)
- Deep Learning (r√©seaux de neurones)
- Calculs math√©matiques vectoriels
- Simulations scientifiques
- Cryptographie (minage, hashing)
- Analyse de donn√©es massives

‚ùå **Moins adapt√© pour :**
- Algorithmes s√©quentiels
- Beaucoup de branchements conditionnels
- Petites quantit√©s de donn√©es
- Acc√®s m√©moire tr√®s al√©atoires

### Acc√©l√©ration typique

Pour des calculs parall√©lisables :
- **10-50x** plus rapide pour des op√©rations simples
- **100-1000x** pour le deep learning
- **Parfois jusqu'√† 10000x** pour certains algorithmes sp√©cifiques

---

## CUDA vs OpenCL

Il existe deux principales technologies pour le calcul GPU :

### CUDA (Compute Unified Device Architecture)

**D√©velopp√© par** : NVIDIA  
**Fonctionne sur** : Cartes NVIDIA uniquement  
**Langage** : C-like avec extensions  

**Avantages :**
- ‚úÖ Tr√®s optimis√© pour les GPU NVIDIA
- ‚úÖ Excellent outillage (profiler, debugger)
- ‚úÖ Grande communaut√©
- ‚úÖ Biblioth√®ques puissantes (cuBLAS, cuDNN)

**Inconv√©nients :**
- ‚ùå Propri√©taire (NVIDIA only)
- ‚ùå Pas portable vers AMD ou Intel

### OpenCL (Open Computing Language)

**D√©velopp√© par** : Khronos Group (standard ouvert)  
**Fonctionne sur** : NVIDIA, AMD, Intel, ARM, CPU  
**Langage** : C99-like  

**Avantages :**
- ‚úÖ Standard ouvert
- ‚úÖ Multi-plateforme et multi-vendor
- ‚úÖ Peut aussi utiliser le CPU
- ‚úÖ Portable

**Inconv√©nients :**
- ‚ùå Parfois moins optimis√© que CUDA
- ‚ùå API plus verbose
- ‚ùå Support variable selon les vendors

### Comparaison

| Crit√®re | CUDA | OpenCL |
|---------|------|--------|
| **Performance** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Portabilit√©** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Facilit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Outils** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Communaut√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

**Recommandation :**
- Si vous avez une carte NVIDIA et que la portabilit√© n'est pas critique ‚Üí **CUDA**
- Si vous voulez supporter plusieurs vendeurs ou architectures ‚Üí **OpenCL**

---

## Installation et Configuration

### Installation CUDA (NVIDIA)

**Windows :**

1. **V√©rifier votre GPU**
```batch
nvidia-smi
```

2. **T√©l√©charger CUDA Toolkit**
- Site : https://developer.nvidia.com/cuda-downloads
- Choisir Windows, x86_64, version de Windows
- T√©l√©charger l'installeur (‚âà3 GB)

3. **Installer**
- Ex√©cuter l'installeur
- Choisir "Express Installation"
- Attendre la fin (peut prendre 15-30 min)

4. **V√©rifier l'installation**
```batch
nvcc --version
```

**Linux/Ubuntu :**

```bash
# V√©rifier le GPU
lspci | grep -i nvidia

# Ajouter le d√©p√¥t NVIDIA
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update

# Installer CUDA
sudo apt-get install cuda

# Configurer PATH
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# V√©rifier
nvcc --version
nvidia-smi
```

### Installation OpenCL

**Windows :**

OpenCL est g√©n√©ralement inclus avec les drivers GPU. T√©l√©charger :
- NVIDIA : Drivers r√©cents incluent OpenCL
- AMD : AMD APP SDK
- Intel : Intel SDK for OpenCL

**Linux/Ubuntu :**

```bash
# Pour NVIDIA
sudo apt install nvidia-opencl-dev

# Pour AMD
sudo apt install mesa-opencl-icd

# Pour Intel
sudo apt install intel-opencl-icd

# Outils de d√©veloppement
sudo apt install opencl-headers ocl-icd-opencl-dev

# V√©rifier
clinfo
```

### V√©rification de l'installation

```pascal
program CheckGPU;

{$mode objfpc}{$H+}

uses
  SysUtils, dynlibs;

var
  cudaLib: TLibHandle;
  openclLib: TLibHandle;

begin
  WriteLn('=== V√©rification GPU ===');
  WriteLn;

  // V√©rifier CUDA
  {$IFDEF WINDOWS}
  cudaLib := LoadLibrary('cudart64_12.dll');
  {$ELSE}
  cudaLib := LoadLibrary('libcudart.so');
  {$ENDIF}

  if cudaLib <> 0 then
  begin
    WriteLn('‚úì CUDA d√©tect√©');
    FreeLibrary(cudaLib);
  end
  else
    WriteLn('‚úó CUDA non d√©tect√©');

  // V√©rifier OpenCL
  {$IFDEF WINDOWS}
  openclLib := LoadLibrary('OpenCL.dll');
  {$ELSE}
  openclLib := LoadLibrary('libOpenCL.so');
  {$ENDIF}

  if openclLib <> 0 then
  begin
    WriteLn('‚úì OpenCL d√©tect√©');
    FreeLibrary(openclLib);
  end
  else
    WriteLn('‚úó OpenCL non d√©tect√©');

  {$IFDEF WINDOWS}
  ReadLn;
  {$ENDIF}
end.
```

---

## Premiers Pas avec OpenCL

### Architecture OpenCL

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Application HOST         ‚îÇ
‚îÇ     (FreePascal/Lazarus)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ OpenCL API
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        OpenCL Runtime           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   GPU    ‚îÇ      ‚îÇ   CPU    ‚îÇ
‚îÇ Device   ‚îÇ      ‚îÇ Device   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Concepts cl√©s

**Platform** : Un vendor (NVIDIA, AMD, Intel)  
**Device** : Un GPU ou CPU disponible  
**Context** : Environnement d'ex√©cution  
**Command Queue** : File d'instructions pour le device  
**Kernel** : Fonction qui s'ex√©cute sur le GPU  
**Buffer** : M√©moire sur le GPU  

### Bindings OpenCL pour FreePascal

```pascal
unit OpenCL;

{$mode objfpc}{$H+}

interface

uses
  Classes, SysUtils, dynlibs;

const
  {$IFDEF WINDOWS}
  OpenCL_LIB = 'OpenCL.dll';
  {$ENDIF}
  {$IFDEF LINUX}
  OpenCL_LIB = 'libOpenCL.so';
  {$ENDIF}
  {$IFDEF DARWIN}
  OpenCL_LIB = 'OpenCL';
  {$ENDIF}

type
  // Types de base
  cl_int = Int32;
  cl_uint = UInt32;
  cl_ulong = UInt64;
  size_t = NativeUInt;

  // Types opaques (pointeurs)
  cl_platform_id = Pointer;
  cl_device_id = Pointer;
  cl_context = Pointer;
  cl_command_queue = Pointer;
  cl_mem = Pointer;
  cl_program = Pointer;
  cl_kernel = Pointer;
  cl_event = Pointer;

  // Types tableau
  Pcl_platform_id = ^cl_platform_id;
  Pcl_device_id = ^cl_device_id;

  // Codes d'erreur
  cl_error_code = cl_int;

const
  // Codes de succ√®s/erreur
  CL_SUCCESS = 0;
  CL_DEVICE_NOT_FOUND = -1;
  CL_DEVICE_NOT_AVAILABLE = -2;
  CL_COMPILER_NOT_AVAILABLE = -3;
  CL_OUT_OF_HOST_MEMORY = -6;

  // Types de device
  CL_DEVICE_TYPE_DEFAULT = 1 shl 0;
  CL_DEVICE_TYPE_CPU = 1 shl 1;
  CL_DEVICE_TYPE_GPU = 1 shl 2;
  CL_DEVICE_TYPE_ACCELERATOR = 1 shl 3;
  CL_DEVICE_TYPE_ALL = $FFFFFFFF;

  // Flags de m√©moire
  CL_MEM_READ_WRITE = 1 shl 0;
  CL_MEM_WRITE_ONLY = 1 shl 1;
  CL_MEM_READ_ONLY = 1 shl 2;
  CL_MEM_COPY_HOST_PTR = 1 shl 5;

  // Informations device
  CL_DEVICE_NAME = $102B;
  CL_DEVICE_VENDOR = $102C;
  CL_DEVICE_VERSION = $102F;
  CL_DEVICE_MAX_COMPUTE_UNITS = $1002;
  CL_DEVICE_MAX_WORK_GROUP_SIZE = $1004;
  CL_DEVICE_GLOBAL_MEM_SIZE = $101F;

var
  // Fonctions OpenCL charg√©es dynamiquement
  clGetPlatformIDs: function(num_entries: cl_uint; platforms: Pcl_platform_id;
                             num_platforms: Pcl_uint): cl_int; cdecl;
  clGetDeviceIDs: function(platform: cl_platform_id; device_type: cl_uint;
                           num_entries: cl_uint; devices: Pcl_device_id;
                           num_devices: Pcl_uint): cl_int; cdecl;
  clGetDeviceInfo: function(device: cl_device_id; param_name: cl_uint;
                            param_value_size: size_t; param_value: Pointer;
                            param_value_size_ret: Psize_t): cl_int; cdecl;
  clCreateContext: function(properties: Pcl_uint; num_devices: cl_uint;
                            devices: Pcl_device_id; pfn_notify: Pointer;
                            user_data: Pointer; errcode_ret: Pcl_int): cl_context; cdecl;
  clCreateCommandQueue: function(context: cl_context; device: cl_device_id;
                                 properties: cl_uint; errcode_ret: Pcl_int): cl_command_queue; cdecl;
  clCreateBuffer: function(context: cl_context; flags: cl_uint; size: size_t;
                           host_ptr: Pointer; errcode_ret: Pcl_int): cl_mem; cdecl;
  clCreateProgramWithSource: function(context: cl_context; count: cl_uint;
                                      strings: PPChar; lengths: Psize_t;
                                      errcode_ret: Pcl_int): cl_program; cdecl;
  clBuildProgram: function(prog: cl_program; num_devices: cl_uint;
                           device_list: Pcl_device_id; options: PChar;
                           pfn_notify: Pointer; user_data: Pointer): cl_int; cdecl;
  clCreateKernel: function(prog: cl_program; kernel_name: PChar;
                           errcode_ret: Pcl_int): cl_kernel; cdecl;
  clSetKernelArg: function(kernel: cl_kernel; arg_index: cl_uint;
                           arg_size: size_t; arg_value: Pointer): cl_int; cdecl;
  clEnqueueWriteBuffer: function(command_queue: cl_command_queue; buffer: cl_mem;
                                 blocking_write: cl_uint; offset: size_t;
                                 size: size_t; ptr: Pointer; num_events: cl_uint;
                                 event_wait_list: Pointer; event: Pointer): cl_int; cdecl;
  clEnqueueReadBuffer: function(command_queue: cl_command_queue; buffer: cl_mem;
                                blocking_read: cl_uint; offset: size_t;
                                size: size_t; ptr: Pointer; num_events: cl_uint;
                                event_wait_list: Pointer; event: Pointer): cl_int; cdecl;
  clEnqueueNDRangeKernel: function(command_queue: cl_command_queue; kernel: cl_kernel;
                                   work_dim: cl_uint; global_work_offset: Psize_t;
                                   global_work_size: Psize_t; local_work_size: Psize_t;
                                   num_events: cl_uint; event_wait_list: Pointer;
                                   event: Pointer): cl_int; cdecl;
  clFinish: function(command_queue: cl_command_queue): cl_int; cdecl;
  clReleaseMemObject: function(memobj: cl_mem): cl_int; cdecl;
  clReleaseKernel: function(kernel: cl_kernel): cl_int; cdecl;
  clReleaseProgram: function(prog: cl_program): cl_int; cdecl;
  clReleaseCommandQueue: function(command_queue: cl_command_queue): cl_int; cdecl;
  clReleaseContext: function(context: cl_context): cl_int; cdecl;

function LoadOpenCL: Boolean;
procedure UnloadOpenCL;
function GetErrorString(AError: cl_int): string;

implementation

var
  OpenCLHandle: TLibHandle = 0;

function LoadOpenCL: Boolean;
begin
  Result := False;

  if OpenCLHandle <> 0 then
  begin
    Result := True;
    Exit;
  end;

  OpenCLHandle := LoadLibrary(OpenCL_LIB);
  if OpenCLHandle = 0 then
  begin
    WriteLn('Erreur: Impossible de charger ', OpenCL_LIB);
    Exit;
  end;

  // Charger les fonctions
  Pointer(clGetPlatformIDs) := GetProcAddress(OpenCLHandle, 'clGetPlatformIDs');
  Pointer(clGetDeviceIDs) := GetProcAddress(OpenCLHandle, 'clGetDeviceIDs');
  Pointer(clGetDeviceInfo) := GetProcAddress(OpenCLHandle, 'clGetDeviceInfo');
  Pointer(clCreateContext) := GetProcAddress(OpenCLHandle, 'clCreateContext');
  Pointer(clCreateCommandQueue) := GetProcAddress(OpenCLHandle, 'clCreateCommandQueue');
  Pointer(clCreateBuffer) := GetProcAddress(OpenCLHandle, 'clCreateBuffer');
  Pointer(clCreateProgramWithSource) := GetProcAddress(OpenCLHandle, 'clCreateProgramWithSource');
  Pointer(clBuildProgram) := GetProcAddress(OpenCLHandle, 'clBuildProgram');
  Pointer(clCreateKernel) := GetProcAddress(OpenCLHandle, 'clCreateKernel');
  Pointer(clSetKernelArg) := GetProcAddress(OpenCLHandle, 'clSetKernelArg');
  Pointer(clEnqueueWriteBuffer) := GetProcAddress(OpenCLHandle, 'clEnqueueWriteBuffer');
  Pointer(clEnqueueReadBuffer) := GetProcAddress(OpenCLHandle, 'clEnqueueReadBuffer');
  Pointer(clEnqueueNDRangeKernel) := GetProcAddress(OpenCLHandle, 'clEnqueueNDRangeKernel');
  Pointer(clFinish) := GetProcAddress(OpenCLHandle, 'clFinish');
  Pointer(clReleaseMemObject) := GetProcAddress(OpenCLHandle, 'clReleaseMemObject');
  Pointer(clReleaseKernel) := GetProcAddress(OpenCLHandle, 'clReleaseKernel');
  Pointer(clReleaseProgram) := GetProcAddress(OpenCLHandle, 'clReleaseProgram');
  Pointer(clReleaseCommandQueue) := GetProcAddress(OpenCLHandle, 'clReleaseCommandQueue');
  Pointer(clReleaseContext) := GetProcAddress(OpenCLHandle, 'clReleaseContext');

  Result := Assigned(clGetPlatformIDs);
end;

procedure UnloadOpenCL;
begin
  if OpenCLHandle <> 0 then
  begin
    FreeLibrary(OpenCLHandle);
    OpenCLHandle := 0;
  end;
end;

function GetErrorString(AError: cl_int): string;
begin
  case AError of
    CL_SUCCESS: Result := 'Success';
    CL_DEVICE_NOT_FOUND: Result := 'Device not found';
    CL_DEVICE_NOT_AVAILABLE: Result := 'Device not available';
    CL_COMPILER_NOT_AVAILABLE: Result := 'Compiler not available';
    CL_OUT_OF_HOST_MEMORY: Result := 'Out of host memory';
  else
    Result := Format('Unknown error: %d', [AError]);
  end;
end;

initialization

finalization
  UnloadOpenCL;

end.
```

---

## Premier Programme : Addition de Vecteurs

### Le kernel OpenCL

Un kernel est une fonction qui s'ex√©cute sur le GPU. Voici un kernel simple qui additionne deux vecteurs :

```c
// kernel_add.cl
__kernel void vector_add(__global const float* A,
                         __global const float* B,
                         __global float* C,
                         const unsigned int N)
{
    int i = get_global_id(0);

    if (i < N) {
        C[i] = A[i] + B[i];
    }
}
```

**Explications :**
- `__kernel` : marque la fonction comme un kernel
- `__global` : m√©moire globale accessible par tous les threads
- `get_global_id(0)` : obtient l'index du thread courant
- Chaque thread calcule un √©l√©ment du r√©sultat

### Programme FreePascal complet

```pascal
program VectorAddGPU;

{$mode objfpc}{$H+}

uses
  SysUtils, OpenCL;

const
  VECTOR_SIZE = 1024;

  // Code du kernel
  KERNEL_SOURCE =
    '__kernel void vector_add(__global const float* A,' + LineEnding +
    '                         __global const float* B,' + LineEnding +
    '                         __global float* C,' + LineEnding +
    '                         const unsigned int N)' + LineEnding +
    '{' + LineEnding +
    '    int i = get_global_id(0);' + LineEnding +
    '    if (i < N) {' + LineEnding +
    '        C[i] = A[i] + B[i];' + LineEnding +
    '    }' + LineEnding +
    '}';

var
  // Donn√©es CPU
  A, B, C: array[0..VECTOR_SIZE-1] of Single;

  // OpenCL
  platform: cl_platform_id;
  device: cl_device_id;
  context: cl_context;
  queue: cl_command_queue;
  bufferA, bufferB, bufferC: cl_mem;
  prog: cl_program;
  kernel: cl_kernel;

  // Variables
  err: cl_int;
  i: Integer;
  numPlatforms, numDevices: cl_uint;
  globalSize: size_t;
  kernelSource: PChar;
  startTime, endTime: QWord;
  gpuTime, cpuTime: Double;

begin
  WriteLn('=== Addition de vecteurs sur GPU ===');
  WriteLn;

  if not LoadOpenCL then
  begin
    WriteLn('√âchec du chargement d''OpenCL');
    Exit;
  end;

  // Initialiser les donn√©es
  WriteLn('Initialisation des donn√©es...');
  for i := 0 to VECTOR_SIZE - 1 do
  begin
    A[i] := i;
    B[i] := i * 2;
  end;

  try
    // 1. Obtenir une plateforme OpenCL
    err := clGetPlatformIDs(1, @platform, @numPlatforms);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur clGetPlatformIDs: ', GetErrorString(err));
      Exit;
    end;
    WriteLn('‚úì Plateforme trouv√©e');

    // 2. Obtenir un device GPU
    err := clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 1, @device, @numDevices);
    if err <> CL_SUCCESS then
    begin
      WriteLn('GPU non trouv√©, essai avec CPU...');
      err := clGetDeviceIDs(platform, CL_DEVICE_TYPE_CPU, 1, @device, @numDevices);
      if err <> CL_SUCCESS then
      begin
        WriteLn('Aucun device trouv√©');
        Exit;
      end;
    end;
    WriteLn('‚úì Device trouv√©');

    // 3. Cr√©er un contexte
    context := clCreateContext(nil, 1, @device, nil, nil, @err);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur clCreateContext: ', GetErrorString(err));
      Exit;
    end;
    WriteLn('‚úì Contexte cr√©√©');

    // 4. Cr√©er une command queue
    queue := clCreateCommandQueue(context, device, 0, @err);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur clCreateCommandQueue: ', GetErrorString(err));
      clReleaseContext(context);
      Exit;
    end;
    WriteLn('‚úì Command queue cr√©√©e');

    // 5. Cr√©er les buffers sur le GPU
    bufferA := clCreateBuffer(context, CL_MEM_READ_ONLY or CL_MEM_COPY_HOST_PTR,
                               VECTOR_SIZE * SizeOf(Single), @A[0], @err);
    bufferB := clCreateBuffer(context, CL_MEM_READ_ONLY or CL_MEM_COPY_HOST_PTR,
                               VECTOR_SIZE * SizeOf(Single), @B[0], @err);
    bufferC := clCreateBuffer(context, CL_MEM_WRITE_ONLY,
                               VECTOR_SIZE * SizeOf(Single), nil, @err);
    WriteLn('‚úì Buffers GPU cr√©√©s');

    // 6. Cr√©er et compiler le programme
    kernelSource := PChar(KERNEL_SOURCE);
    prog := clCreateProgramWithSource(context, 1, @kernelSource, nil, @err);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur clCreateProgramWithSource: ', GetErrorString(err));
      Exit;
    end;

    err := clBuildProgram(prog, 1, @device, nil, nil, nil);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur de compilation du kernel: ', GetErrorString(err));
      Exit;
    end;
    WriteLn('‚úì Kernel compil√©');

    // 7. Cr√©er le kernel
    kernel := clCreateKernel(prog, 'vector_add', @err);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur clCreateKernel: ', GetErrorString(err));
      Exit;
    end;

    // 8. D√©finir les arguments du kernel
    clSetKernelArg(kernel, 0, SizeOf(cl_mem), @bufferA);
    clSetKernelArg(kernel, 1, SizeOf(cl_mem), @bufferB);
    clSetKernelArg(kernel, 2, SizeOf(cl_mem), @bufferC);
    clSetKernelArg(kernel, 3, SizeOf(cl_uint), @VECTOR_SIZE);
    WriteLn('‚úì Arguments du kernel d√©finis');

    // 9. Ex√©cuter le kernel
    WriteLn;
    WriteLn('Ex√©cution sur GPU...');
    startTime := GetTickCount64;

    globalSize := VECTOR_SIZE;
    err := clEnqueueNDRangeKernel(queue, kernel, 1, nil, @globalSize, nil, 0, nil, nil);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur clEnqueueNDRangeKernel: ', GetErrorString(err));
      Exit;
    end;

    clFinish(queue);
    endTime := GetTickCount64;
    gpuTime := (endTime - startTime);

    WriteLn('‚úì Kernel ex√©cut√© en ', gpuTime:0:2, ' ms');

    // 10. Lire le r√©sultat
    err := clEnqueueReadBuffer(queue, bufferC, 1, 0, VECTOR_SIZE * SizeOf(Single),
                                @C[0], 0, nil, nil);
    if err <> CL_SUCCESS then
    begin
      WriteLn('Erreur clEnqueueReadBuffer: ', GetErrorString(err));
      Exit;
    end;

    // V√©rifier les r√©sultats
    WriteLn;
    WriteLn('V√©rification des r√©sultats...');
    WriteLn('Quelques valeurs:');
    for i := 0 to 9 do
      WriteLn(Format('  A[%d] + B[%d] = %.0f + %.0f = %.0f',
        [i, i, A[i], B[i], C[i]]));

    // Comparaison avec le CPU
    WriteLn;
    WriteLn('Comparaison CPU vs GPU:');

    startTime := GetTickCount64;
    for i := 0 to VECTOR_SIZE - 1 do
      C[i] := A[i] + B[i];
    endTime := GetTickCount64;
    cpuTime := (endTime - startTime);

    WriteLn('  Temps CPU: ', cpuTime:0:2, ' ms');
    WriteLn('  Temps GPU: ', gpuTime:0:2, ' ms');

    if cpuTime > 0 then
      WriteLn('  Acc√©l√©ration: ', (cpuTime / gpuTime):0:2, 'x');

    // Lib√©rer les ressources
    clReleaseMemObject(bufferA);
    clReleaseMemObject(bufferB);
    clReleaseMemObject(bufferC);
    clReleaseKernel(kernel);
    clReleaseProgram(prog);
    clReleaseCommandQueue(queue);
    clReleaseContext(context);

    WriteLn;
    WriteLn('‚úì Ressources lib√©r√©es');

  finally
    UnloadOpenCL;
  end;

  {$IFDEF WINDOWS}
  WriteLn;
  WriteLn('Appuyez sur Entr√©e pour quitter...');
  ReadLn;
  {$ENDIF}
end.
```

**Sortie attendue :**
```
=== Addition de vecteurs sur GPU ===

Initialisation des donn√©es...
‚úì Plateforme trouv√©e
‚úì Device trouv√©
‚úì Contexte cr√©√©
‚úì Command queue cr√©√©e
‚úì Buffers GPU cr√©√©s
‚úì Kernel compil√©
‚úì Arguments du kernel d√©finis

Ex√©cution sur GPU...
‚úì Kernel ex√©cut√© en 2.35 ms

V√©rification des r√©sultats...
Quelques valeurs:
  A[0] + B[0] = 0 + 0 = 0
  A[1] + B[1] = 1 + 2 = 3
  A[2] + B[2] = 2 + 4 = 6
  A[3] + B[3] = 3 + 6 = 9
  A[4] + B[4] = 4 + 8 = 12
  A[5] + B[5] = 5 + 10 = 15
  A[6] + B[6] = 6 + 12 = 18
  A[7] + B[7] = 7 + 14 = 21
  A[8] + B[8] = 8 + 16 = 24
  A[9] + B[9] = 9 + 18 = 27

Comparaison CPU vs GPU:
  Temps CPU: 0.02 ms
  Temps GPU: 2.35 ms
  Acc√©l√©ration: 0.01x

‚úì Ressources lib√©r√©es
```

**Note importante :** Pour de petites donn√©es (1024 √©l√©ments), le CPU est plus rapide car le transfert de donn√©es CPU‚ÜîGPU prend plus de temps que le calcul lui-m√™me. Le GPU devient int√©ressant avec des donn√©es plus volumineuses (millions d'√©l√©ments).

---

## Wrapper Orient√© Objet

Pour simplifier l'utilisation d'OpenCL, cr√©ons un wrapper orient√© objet :

```pascal
unit GPUCompute;

{$mode objfpc}{$H+}

interface

uses
  Classes, SysUtils, OpenCL;

type
  TGPUDevice = class
  private
    FPlatform: cl_platform_id;
    FDevice: cl_device_id;
    FContext: cl_context;
    FQueue: cl_command_queue;
    FDeviceName: string;
    FDeviceVendor: string;
    FMaxComputeUnits: Integer;
    FGlobalMemSize: Int64;
    FInitialized: Boolean;

    procedure LoadDeviceInfo;
  public
    constructor Create;
    destructor Destroy; override;

    function Initialize(APreferGPU: Boolean = True): Boolean;
    function CreateBuffer(ASize: size_t; AFlags: cl_uint): cl_mem;
    function WriteBuffer(ABuffer: cl_mem; AData: Pointer; ASize: size_t): Boolean;
    function ReadBuffer(ABuffer: cl_mem; AData: Pointer; ASize: size_t): Boolean;
    procedure ReleaseBuffer(ABuffer: cl_mem);
    procedure Finish;

    property DeviceName: string read FDeviceName;
    property DeviceVendor: string read FDeviceVendor;
    property MaxComputeUnits: Integer read FMaxComputeUnits;
    property GlobalMemSize: Int64 read FGlobalMemSize;
    property Initialized: Boolean read FInitialized;
    property Context: cl_context read FContext;
    property Queue: cl_command_queue read FQueue;
    property Device: cl_device_id read FDevice;
  end;

  TGPUKernel = class
  private
    FDevice: TGPUDevice;
    FProgram: cl_program;
    FKernel: cl_kernel;
    FKernelName: string;
    FCompiled: Boolean;
  public
    constructor Create(ADevice: TGPUDevice);
    destructor Destroy; override;

    function CompileFromSource(const ASource, AKernelName: string): Boolean;
    function CompileFromFile(const AFileName, AKernelName: string): Boolean;
    function SetArg(AIndex: Integer; ASize: size_t; AValue: Pointer): Boolean;
    function Execute(AGlobalSize: size_t; ALocalSize: size_t = 0): Boolean;

    property Compiled: Boolean read FCompiled;
    property KernelName: string read FKernelName;
  end;

implementation

{ TGPUDevice }

constructor TGPUDevice.Create;
begin
  FInitialized := False;

  if not LoadOpenCL then
    raise Exception.Create('OpenCL non disponible');
end;

destructor TGPUDevice.Destroy;
begin
  if FInitialized then
  begin
    if Assigned(FQueue) then
      clReleaseCommandQueue(FQueue);
    if Assigned(FContext) then
      clReleaseContext(FContext);
  end;

  inherited;
end;

function TGPUDevice.Initialize(APreferGPU: Boolean): Boolean;
var
  err: cl_int;
  numPlatforms: cl_uint;
  deviceType: cl_uint;
begin
  Result := False;

  // Obtenir une plateforme
  err := clGetPlatformIDs(1, @FPlatform, @numPlatforms);
  if err <> CL_SUCCESS then
    Exit;

  // Choisir le type de device
  if APreferGPU then
    deviceType := CL_DEVICE_TYPE_GPU
  else
    deviceType := CL_DEVICE_TYPE_CPU;

  // Obtenir le device
  err := clGetDeviceIDs(FPlatform, deviceType, 1, @FDevice, nil);
  if err <> CL_SUCCESS then
  begin
    // Fallback sur CPU si GPU non disponible
    if deviceType = CL_DEVICE_TYPE_GPU then
    begin
      WriteLn('GPU non disponible, utilisation du CPU');
      err := clGetDeviceIDs(FPlatform, CL_DEVICE_TYPE_CPU, 1, @FDevice, nil);
    end;

    if err <> CL_SUCCESS then
      Exit;
  end;

  // Cr√©er le contexte
  FContext := clCreateContext(nil, 1, @FDevice, nil, nil, @err);
  if err <> CL_SUCCESS then
    Exit;

  // Cr√©er la command queue
  FQueue := clCreateCommandQueue(FContext, FDevice, 0, @err);
  if err <> CL_SUCCESS then
  begin
    clReleaseContext(FContext);
    Exit;
  end;

  // Charger les informations du device
  LoadDeviceInfo;

  FInitialized := True;
  Result := True;
end;

procedure TGPUDevice.LoadDeviceInfo;
var
  buffer: array[0..255] of Char;
  retSize: size_t;
  value: cl_uint;
  memSize: cl_ulong;
begin
  // Nom du device
  if clGetDeviceInfo(FDevice, CL_DEVICE_NAME, 256, @buffer[0], @retSize) = CL_SUCCESS then
    FDeviceName := string(PChar(@buffer[0]));

  // Vendeur
  if clGetDeviceInfo(FDevice, CL_DEVICE_VENDOR, 256, @buffer[0], @retSize) = CL_SUCCESS then
    FDeviceVendor := string(PChar(@buffer[0]));

  // Nombre d'unit√©s de calcul
  if clGetDeviceInfo(FDevice, CL_DEVICE_MAX_COMPUTE_UNITS, SizeOf(cl_uint), @value, nil) = CL_SUCCESS then
    FMaxComputeUnits := value;

  // M√©moire globale
  if clGetDeviceInfo(FDevice, CL_DEVICE_GLOBAL_MEM_SIZE, SizeOf(cl_ulong), @memSize, nil) = CL_SUCCESS then
    FGlobalMemSize := memSize;
end;

function TGPUDevice.CreateBuffer(ASize: size_t; AFlags: cl_uint): cl_mem;
var
  err: cl_int;
begin
  Result := clCreateBuffer(FContext, AFlags, ASize, nil, @err);
  if err <> CL_SUCCESS then
    Result := nil;
end;

function TGPUDevice.WriteBuffer(ABuffer: cl_mem; AData: Pointer; ASize: size_t): Boolean;
var
  err: cl_int;
begin
  err := clEnqueueWriteBuffer(FQueue, ABuffer, 1, 0, ASize, AData, 0, nil, nil);
  Result := err = CL_SUCCESS;
end;

function TGPUDevice.ReadBuffer(ABuffer: cl_mem; AData: Pointer; ASize: size_t): Boolean;
var
  err: cl_int;
begin
  err := clEnqueueReadBuffer(FQueue, ABuffer, 1, 0, ASize, AData, 0, nil, nil);
  Result := err = CL_SUCCESS;
end;

procedure TGPUDevice.ReleaseBuffer(ABuffer: cl_mem);
begin
  if Assigned(ABuffer) then
    clReleaseMemObject(ABuffer);
end;

procedure TGPUDevice.Finish;
begin
  clFinish(FQueue);
end;

{ TGPUKernel }

constructor TGPUKernel.Create(ADevice: TGPUDevice);
begin
  FDevice := ADevice;
  FCompiled := False;
end;

destructor TGPUKernel.Destroy;
begin
  if FCompiled then
  begin
    if Assigned(FKernel) then
      clReleaseKernel(FKernel);
    if Assigned(FProgram) then
      clReleaseProgram(FProgram);
  end;

  inherited;
end;

function TGPUKernel.CompileFromSource(const ASource, AKernelName: string): Boolean;
var
  err: cl_int;
  source: PChar;
begin
  Result := False;
  FKernelName := AKernelName;

  // Cr√©er le programme
  source := PChar(ASource);
  FProgram := clCreateProgramWithSource(FDevice.Context, 1, @source, nil, @err);
  if err <> CL_SUCCESS then
  begin
    WriteLn('Erreur cr√©ation du programme: ', GetErrorString(err));
    Exit;
  end;

  // Compiler
  err := clBuildProgram(FProgram, 1, @FDevice.Device, nil, nil, nil);
  if err <> CL_SUCCESS then
  begin
    WriteLn('Erreur compilation: ', GetErrorString(err));
    clReleaseProgram(FProgram);
    Exit;
  end;

  // Cr√©er le kernel
  FKernel := clCreateKernel(FProgram, PChar(AKernelName), @err);
  if err <> CL_SUCCESS then
  begin
    WriteLn('Erreur cr√©ation du kernel: ', GetErrorString(err));
    clReleaseProgram(FProgram);
    Exit;
  end;

  FCompiled := True;
  Result := True;
end;

function TGPUKernel.CompileFromFile(const AFileName, AKernelName: string): Boolean;
var
  source: TStringList;
begin
  source := TStringList.Create;
  try
    source.LoadFromFile(AFileName);
    Result := CompileFromSource(source.Text, AKernelName);
  finally
    source.Free;
  end;
end;

function TGPUKernel.SetArg(AIndex: Integer; ASize: size_t; AValue: Pointer): Boolean;
var
  err: cl_int;
begin
  err := clSetKernelArg(FKernel, AIndex, ASize, AValue);
  Result := err = CL_SUCCESS;
end;

function TGPUKernel.Execute(AGlobalSize: size_t; ALocalSize: size_t): Boolean;
var
  err: cl_int;
  localSize: Psize_t;
begin
  if ALocalSize > 0 then
    localSize := @ALocalSize
  else
    localSize := nil;

  err := clEnqueueNDRangeKernel(FDevice.Queue, FKernel, 1, nil,
                                @AGlobalSize, localSize, 0, nil, nil);
  Result := err = CL_SUCCESS;
end;

end.
```

### Utilisation du wrapper

```pascal
program SimpleGPUCompute;

{$mode objfpc}{$H+}

uses
  SysUtils, GPUCompute;

const
  DATA_SIZE = 1024;

  KERNEL_SOURCE =
    '__kernel void square(__global float* input,' + LineEnding +
    '                     __global float* output)' + LineEnding +
    '{' + LineEnding +
    '    int i = get_global_id(0);' + LineEnding +
    '    output[i] = input[i] * input[i];' + LineEnding +
    '}';

var
  device: TGPUDevice;
  kernel: TGPUKernel;
  input, output: array[0..DATA_SIZE-1] of Single;
  bufferInput, bufferOutput: cl_mem;
  i: Integer;

begin
  WriteLn('=== Calcul GPU simplifi√© ===');
  WriteLn;

  // Cr√©er le device GPU
  device := TGPUDevice.Create;
  try
    if not device.Initialize(True) then
    begin
      WriteLn('Impossible d''initialiser le GPU');
      Exit;
    end;

    WriteLn('Device: ', device.DeviceName);
    WriteLn('Vendor: ', device.DeviceVendor);
    WriteLn('Compute Units: ', device.MaxComputeUnits);
    WriteLn('Global Memory: ', device.GlobalMemSize div (1024*1024), ' MB');
    WriteLn;

    // Pr√©parer les donn√©es
    for i := 0 to DATA_SIZE - 1 do
      input[i] := i;

    // Cr√©er les buffers
    bufferInput := device.CreateBuffer(DATA_SIZE * SizeOf(Single),
                                       CL_MEM_READ_ONLY);
    bufferOutput := device.CreateBuffer(DATA_SIZE * SizeOf(Single),
                                        CL_MEM_WRITE_ONLY);

    // √âcrire les donn√©es d'entr√©e
    device.WriteBuffer(bufferInput, @input[0], DATA_SIZE * SizeOf(Single));

    // Compiler le kernel
    kernel := TGPUKernel.Create(device);
    try
      if not kernel.CompileFromSource(KERNEL_SOURCE, 'square') then
      begin
        WriteLn('Erreur de compilation du kernel');
        Exit;
      end;

      WriteLn('‚úì Kernel compil√©');

      // D√©finir les arguments
      kernel.SetArg(0, SizeOf(cl_mem), @bufferInput);
      kernel.SetArg(1, SizeOf(cl_mem), @bufferOutput);

      // Ex√©cuter
      WriteLn('Ex√©cution du kernel...');
      if kernel.Execute(DATA_SIZE) then
      begin
        device.Finish;
        WriteLn('‚úì Kernel ex√©cut√©');

        // Lire les r√©sultats
        device.ReadBuffer(bufferOutput, @output[0], DATA_SIZE * SizeOf(Single));

        // Afficher quelques r√©sultats
        WriteLn;
        WriteLn('R√©sultats:');
        for i := 0 to 9 do
          WriteLn(Format('  %.0f¬≤ = %.0f', [input[i], output[i]]));
      end
      else
        WriteLn('‚úó Erreur d''ex√©cution');

    finally
      kernel.Free;
    end;

    // Lib√©rer les buffers
    device.ReleaseBuffer(bufferInput);
    device.ReleaseBuffer(bufferOutput);

  finally
    device.Free;
  end;

  {$IFDEF WINDOWS}
  WriteLn;
  WriteLn('Appuyez sur Entr√©e...');
  ReadLn;
  {$ENDIF}
end.
```

---

## Exemples Pratiques

### 1. Traitement d'Image : Filtre de Flou

```pascal
// Kernel pour un flou gaussien
const
  BLUR_KERNEL =
    '__kernel void gaussian_blur(__global const uchar4* input,' + LineEnding +
    '                            __global uchar4* output,' + LineEnding +
    '                            const int width,' + LineEnding +
    '                            const int height)' + LineEnding +
    '{' + LineEnding +
    '    int x = get_global_id(0);' + LineEnding +
    '    int y = get_global_id(1);' + LineEnding +
    '    ' + LineEnding +
    '    if (x >= width || y >= height) return;' + LineEnding +
    '    ' + LineEnding +
    '    // Noyau 3x3' + LineEnding +
    '    float kernel[9] = {1, 2, 1, 2, 4, 2, 1, 2, 1};' + LineEnding +
    '    float sum = 16.0f;' + LineEnding +
    '    ' + LineEnding +
    '    float4 result = (float4)(0, 0, 0, 0);' + LineEnding +
    '    ' + LineEnding +
    '    for (int dy = -1; dy <= 1; dy++) {' + LineEnding +
    '        for (int dx = -1; dx <= 1; dx++) {' + LineEnding +
    '            int nx = clamp(x + dx, 0, width - 1);' + LineEnding +
    '            int ny = clamp(y + dy, 0, height - 1);' + LineEnding +
    '            int idx = ny * width + nx;' + LineEnding +
    '            ' + LineEnding +
    '            uchar4 pixel = input[idx];' + LineEnding +
    '            float weight = kernel[(dy+1)*3 + (dx+1)];' + LineEnding +
    '            ' + LineEnding +
    '            result += convert_float4(pixel) * weight;' + LineEnding +
    '        }' + LineEnding +
    '    }' + LineEnding +
    '    ' + LineEnding +
    '    result /= sum;' + LineEnding +
    '    output[y * width + x] = convert_uchar4(result);' + LineEnding +
    '}';

program ImageBlurGPU;

{$mode objfpc}{$H+}

uses
  SysUtils, Graphics, GPUCompute;

procedure ApplyBlur(ABitmap: TBitmap);
var
  device: TGPUDevice;
  kernel: TGPUKernel;
  width, height, i: Integer;
  inputData, outputData: array of LongWord;
  bufferInput, bufferOutput: cl_mem;
  globalSize: array[0..1] of size_t;
begin
  width := ABitmap.Width;
  height := ABitmap.Height;

  SetLength(inputData, width * height);
  SetLength(outputData, width * height);

  // Copier les pixels
  for i := 0 to width * height - 1 do
    inputData[i] := PLongWord(ABitmap.ScanLine[i div width])[i mod width];

  device := TGPUDevice.Create;
  try
    if not device.Initialize then
    begin
      WriteLn('GPU non disponible');
      Exit;
    end;

    // Cr√©er les buffers
    bufferInput := device.CreateBuffer(width * height * 4, CL_MEM_READ_ONLY);
    bufferOutput := device.CreateBuffer(width * height * 4, CL_MEM_WRITE_ONLY);

    device.WriteBuffer(bufferInput, @inputData[0], width * height * 4);

    // Compiler et ex√©cuter
    kernel := TGPUKernel.Create(device);
    try
      if kernel.CompileFromSource(BLUR_KERNEL, 'gaussian_blur') then
      begin
        kernel.SetArg(0, SizeOf(cl_mem), @bufferInput);
        kernel.SetArg(1, SizeOf(cl_mem), @bufferOutput);
        kernel.SetArg(2, SizeOf(Integer), @width);
        kernel.SetArg(3, SizeOf(Integer), @height);

        globalSize[0] := width;
        globalSize[1] := height;

        // Note: Pour 2D, utilisez clEnqueueNDRangeKernel directement
        // ou modifiez TGPUKernel pour supporter 2D

        device.Finish;
        device.ReadBuffer(bufferOutput, @outputData[0], width * height * 4);

        // Copier les r√©sultats
        for i := 0 to width * height - 1 do
          PLongWord(ABitmap.ScanLine[i div width])[i mod width] := outputData[i];
      end;
    finally
      kernel.Free;
    end;

    device.ReleaseBuffer(bufferInput);
    device.ReleaseBuffer(bufferOutput);

  finally
    device.Free;
  end;
end;

end.
```

### 2. Multiplication de Matrices

```pascal
const
  MATRIX_MUL_KERNEL =
    '__kernel void matmul(__global const float* A,' + LineEnding +
    '                     __global const float* B,' + LineEnding +
    '                     __global float* C,' + LineEnding +
    '                     const int M,' + LineEnding +
    '                     const int N,' + LineEnding +
    '                     const int K)' + LineEnding +
    '{' + LineEnding +
    '    int row = get_global_id(0);' + LineEnding +
    '    int col = get_global_id(1);' + LineEnding +
    '    ' + LineEnding +
    '    if (row >= M || col >= N) return;' + LineEnding +
    '    ' + LineEnding +
    '    float sum = 0.0f;' + LineEnding +
    '    for (int k = 0; k < K; k++) {' + LineEnding +
    '        sum += A[row * K + k] * B[k * N + col];' + LineEnding +
    '    }' + LineEnding +
    '    ' + LineEnding +
    '    C[row * N + col] = sum;' + LineEnding +
    '}';

type
  TMatrix = array of array of Single;

function MatrixMultiplyGPU(const A, B: TMatrix): TMatrix;
var
  device: TGPUDevice;
  kernel: TGPUKernel;
  M, N, K: Integer;
  flatA, flatB, flatC: array of Single;
  bufA, bufB, bufC: cl_mem;
  i, j: Integer;
begin
  M := Length(A);      // Lignes de A
  K := Length(A[0]);   // Colonnes de A = Lignes de B
  N := Length(B[0]);   // Colonnes de B

  // Aplatir les matrices
  SetLength(flatA, M * K);
  SetLength(flatB, K * N);
  SetLength(flatC, M * N);

  for i := 0 to M - 1 do
    for j := 0 to K - 1 do
      flatA[i * K + j] := A[i, j];

  for i := 0 to K - 1 do
    for j := 0 to N - 1 do
      flatB[i * N + j] := B[i, j];

  device := TGPUDevice.Create;
  try
    device.Initialize;

    // Cr√©er les buffers
    bufA := device.CreateBuffer(M * K * SizeOf(Single), CL_MEM_READ_ONLY);
    bufB := device.CreateBuffer(K * N * SizeOf(Single), CL_MEM_READ_ONLY);
    bufC := device.CreateBuffer(M * N * SizeOf(Single), CL_MEM_WRITE_ONLY);

    device.WriteBuffer(bufA, @flatA[0], M * K * SizeOf(Single));
    device.WriteBuffer(bufB, @flatB[0], K * N * SizeOf(Single));

    kernel := TGPUKernel.Create(device);
    try
      if kernel.CompileFromSource(MATRIX_MUL_KERNEL, 'matmul') then
      begin
        kernel.SetArg(0, SizeOf(cl_mem), @bufA);
        kernel.SetArg(1, SizeOf(cl_mem), @bufB);
        kernel.SetArg(2, SizeOf(cl_mem), @bufC);
        kernel.SetArg(3, SizeOf(Integer), @M);
        kernel.SetArg(4, SizeOf(Integer), @N);
        kernel.SetArg(5, SizeOf(Integer), @K);

        kernel.Execute(M * N);
        device.Finish;

        device.ReadBuffer(bufC, @flatC[0], M * N * SizeOf(Single));

        // Reconstruire la matrice r√©sultat
        SetLength(Result, M, N);
        for i := 0 to M - 1 do
          for j := 0 to N - 1 do
            Result[i, j] := flatC[i * N + j];
      end;
    finally
      kernel.Free;
    end;

    device.ReleaseBuffer(bufA);
    device.ReleaseBuffer(bufB);
    device.ReleaseBuffer(bufC);

  finally
    device.Free;
  end;
end;
```

### 3. Calcul de Mandelbrot

```pascal
const
  MANDELBROT_KERNEL =
    '__kernel void mandelbrot(__global uchar4* output,' + LineEnding +
    '                         const int width,' + LineEnding +
    '                         const int height,' + LineEnding +
    '                         const float zoom,' + LineEnding +
    '                         const float offsetX,' + LineEnding +
    '                         const float offsetY)' + LineEnding +
    '{' + LineEnding +
    '    int x = get_global_id(0);' + LineEnding +
    '    int y = get_global_id(1);' + LineEnding +
    '    ' + LineEnding +
    '    if (x >= width || y >= height) return;' + LineEnding +
    '    ' + LineEnding +
    '    float real = (x - width / 2.0f) * zoom + offsetX;' + LineEnding +
    '    float imag = (y - height / 2.0f) * zoom + offsetY;' + LineEnding +
    '    ' + LineEnding +
    '    float zr = 0.0f, zi = 0.0f;' + LineEnding +
    '    int iterations = 0;' + LineEnding +
    '    const int maxIter = 256;' + LineEnding +
    '    ' + LineEnding +
    '    while (zr * zr + zi * zi < 4.0f && iterations < maxIter) {' + LineEnding +
    '        float temp = zr * zr - zi * zi + real;' + LineEnding +
    '        zi = 2.0f * zr * zi + imag;' + LineEnding +
    '        zr = temp;' + LineEnding +
    '        iterations++;' + LineEnding +
    '    }' + LineEnding +
    '    ' + LineEnding +
    '    uchar color = (uchar)(iterations * 255 / maxIter);' + LineEnding +
    '    output[y * width + x] = (uchar4)(color, color, color, 255);' + LineEnding +
    '}';

procedure GenerateMandelbrotGPU(ABitmap: TBitmap; AZoom, AOffsetX, AOffsetY: Single);
var
  device: TGPUDevice;
  kernel: TGPUKernel;
  width, height: Integer;
  output: array of LongWord;
  buffer: cl_mem;
  globalSize: array[0..1] of size_t;
  i: Integer;
begin
  width := ABitmap.Width;
  height := ABitmap.Height;

  SetLength(output, width * height);

  device := TGPUDevice.Create;
  try
    device.Initialize;

    buffer := device.CreateBuffer(width * height * 4, CL_MEM_WRITE_ONLY);

    kernel := TGPUKernel.Create(device);
    try
      if kernel.CompileFromSource(MANDELBROT_KERNEL, 'mandelbrot') then
      begin
        kernel.SetArg(0, SizeOf(cl_mem), @buffer);
        kernel.SetArg(1, SizeOf(Integer), @width);
        kernel.SetArg(2, SizeOf(Integer), @height);
        kernel.SetArg(3, SizeOf(Single), @AZoom);
        kernel.SetArg(4, SizeOf(Single), @AOffsetX);
        kernel.SetArg(5, SizeOf(Single), @AOffsetY);

        globalSize[0] := width;
        globalSize[1] := height;

        // Ex√©cution 2D - n√©cessite d'adapter le wrapper
        device.Finish;

        device.ReadBuffer(buffer, @output[0], width * height * 4);

        // Copier vers le bitmap
        for i := 0 to width * height - 1 do
          PLongWord(ABitmap.ScanLine[i div width])[i mod width] := output[i];
      end;
    finally
      kernel.Free;
    end;

    device.ReleaseBuffer(buffer);

  finally
    device.Free;
  end;
end;
```

---

## Optimisation des Performances

### 1. M√©moire locale (Local Memory)

La m√©moire locale est partag√©e entre les threads d'un work-group et est beaucoup plus rapide que la m√©moire globale.

```c
// Kernel optimis√© avec m√©moire locale
__kernel void optimized_convolution(
    __global const float* input,
    __global float* output,
    __local float* localMem,  // M√©moire locale
    const int width,
    const int height)
{
    int gx = get_global_id(0);
    int gy = get_global_id(1);
    int lx = get_local_id(0);
    int ly = get_local_id(1);

    // Charger dans la m√©moire locale
    localMem[ly * get_local_size(0) + lx] = input[gy * width + gx];

    // Synchroniser tous les threads du work-group
    barrier(CLK_LOCAL_MEM_FENCE);

    // Utiliser localMem pour les calculs
    // ... calculs rapides ...
}
```

### 2. Coalescence m√©moire

Acc√©der √† la m√©moire de mani√®re contigu√´ am√©liore les performances :

```c
// Mauvais : acc√®s non coalesc√©s
__kernel void bad_access(__global float* data) {
    int i = get_global_id(0);
    data[i * 1000] = i;  // Stride important
}

// Bon : acc√®s coalesc√©s
__kernel void good_access(__global float* data) {
    int i = get_global_id(0);
    data[i] = i;  // Acc√®s contigus
}
```

### 3. Vectorisation

Utiliser les types vectoriels d'OpenCL :

```c
__kernel void vectorized(__global float4* input,
                         __global float4* output)
{
    int i = get_global_id(0);

    // Traiter 4 √©l√©ments √† la fois
    float4 value = input[i];
    output[i] = value * value;
}
```

### 4. Mesure des performances

```pascal
unit GPUBenchmark;

{$mode objfpc}{$H+}

interface

uses
  SysUtils, GPUCompute;

type
  TBenchmarkResult = record
    KernelTime: Double;      // Temps d'ex√©cution kernel (ms)
    TransferTime: Double;    // Temps de transfert donn√©es (ms)
    TotalTime: Double;       // Temps total (ms)
    Throughput: Double;      // D√©bit (GB/s)
  end;

function BenchmarkKernel(ADevice: TGPUDevice;
                         AKernel: TGPUKernel;
                         ADataSize: Integer): TBenchmarkResult;

implementation

function BenchmarkKernel(ADevice: TGPUDevice;
                         AKernel: TGPUKernel;
                         ADataSize: Integer): TBenchmarkResult;
var
  buffer: cl_mem;
  data: array of Single;
  startTime, endTime: QWord;
  i: Integer;
begin
  SetLength(data, ADataSize);
  for i := 0 to ADataSize - 1 do
    data[i] := Random;

  // Mesurer le transfert Host ‚Üí Device
  startTime := GetTickCount64;
  buffer := ADevice.CreateBuffer(ADataSize * SizeOf(Single), CL_MEM_READ_WRITE);
  ADevice.WriteBuffer(buffer, @data[0], ADataSize * SizeOf(Single));
  ADevice.Finish;
  endTime := GetTickCount64;
  Result.TransferTime := endTime - startTime;

  // Mesurer l'ex√©cution du kernel
  startTime := GetTickCount64;
  AKernel.Execute(ADataSize);
  ADevice.Finish;
  endTime := GetTickCount64;
  Result.KernelTime := endTime - startTime;

  // Mesurer le transfert Device ‚Üí Host
  startTime := GetTickCount64;
  ADevice.ReadBuffer(buffer, @data[0], ADataSize * SizeOf(Single));
  ADevice.Finish;
  endTime := GetTickCount64;
  Result.TransferTime := Result.TransferTime + (endTime - startTime);

  Result.TotalTime := Result.KernelTime + Result.TransferTime;

  // Calculer le d√©bit
  Result.Throughput := (ADataSize * SizeOf(Single) * 2) / // Lecture + √âcriture
                       (Result.TotalTime / 1000) / // Convertir en secondes
                       (1024 * 1024 * 1024); // GB/s

  ADevice.ReleaseBuffer(buffer);
  SetLength(data, 0);
end;

end.
```

---

## Interop√©rabilit√© OpenGL-OpenCL

Pour le rendu graphique acc√©l√©r√©, on peut partager des donn√©es entre OpenGL et OpenCL :

```pascal
unit GLCLInterop;

{$mode objfpc}{$H+}

interface

uses
  OpenCL, GL, GLext;

type
  TGLCLBuffer = class
  private
    FGLBuffer: GLuint;
    FCLBuffer: cl_mem;
    FSize: size_t;
    FContext: cl_context;
  public
    constructor Create(AContext: cl_context; ASize: size_t);
    destructor Destroy; override;

    procedure AcquireFromGL(AQueue: cl_command_queue);
    procedure ReleaseToGL(AQueue: cl_command_queue);

    property GLBuffer: GLuint read FGLBuffer;
    property CLBuffer: cl_mem read FCLBuffer;
  end;

implementation

constructor TGLCLBuffer.Create(AContext: cl_context; ASize: size_t);
var
  err: cl_int;
begin
  FContext := AContext;
  FSize := ASize;

  // Cr√©er un VBO OpenGL
  glGenBuffers(1, @FGLBuffer);
  glBindBuffer(GL_ARRAY_BUFFER, FGLBuffer);
  glBufferData(GL_ARRAY_BUFFER, ASize, nil, GL_DYNAMIC_DRAW);

  // Cr√©er un buffer OpenCL partag√©
  FCLBuffer := clCreateFromGLBuffer(FContext, CL_MEM_READ_WRITE, FGLBuffer, @err);

  if err <> CL_SUCCESS then
    raise Exception.Create('Erreur cr√©ation buffer GL/CL: ' + GetErrorString(err));
end;

destructor TGLCLBuffer.Destroy;
begin
  if FCLBuffer <> nil then
    clReleaseMemObject(FCLBuffer);

  if FGLBuffer <> 0 then
    glDeleteBuffers(1, @FGLBuffer);

  inherited;
end;

procedure TGLCLBuffer.AcquireFromGL(AQueue: cl_command_queue);
begin
  clEnqueueAcquireGLObjects(AQueue, 1, @FCLBuffer, 0, nil, nil);
end;

procedure TGLCLBuffer.ReleaseToGL(AQueue: cl_command_queue);
begin
  clEnqueueReleaseGLObjects(AQueue, 1, @FCLBuffer, 0, nil, nil);
end;

end.
```

---

## Gestion Multi-Plateforme

### D√©tection automatique du meilleur device

```pascal
function SelectBestDevice: TGPUDevice;
var
  platforms: array[0..9] of cl_platform_id;
  numPlatforms: cl_uint;
  i, j: Integer;
  devices: array[0..9] of cl_device_id;
  numDevices: cl_uint;
  deviceType: cl_uint;
  computeUnits: cl_uint;
  bestDevice: cl_device_id;
  maxComputeUnits: cl_uint;
  err: cl_int;
begin
  Result := TGPUDevice.Create;

  // Lister toutes les plateformes
  err := clGetPlatformIDs(10, @platforms[0], @numPlatforms);
  if err <> CL_SUCCESS then
  begin
    WriteLn('Aucune plateforme OpenCL trouv√©e');
    Exit;
  end;

  maxComputeUnits := 0;
  bestDevice := nil;

  // Parcourir toutes les plateformes et devices
  for i := 0 to numPlatforms - 1 do
  begin
    err := clGetDeviceIDs(platforms[i], CL_DEVICE_TYPE_ALL, 10, @devices[0], @numDevices);
    if err = CL_SUCCESS then
    begin
      for j := 0 to numDevices - 1 do
      begin
        clGetDeviceInfo(devices[j], CL_DEVICE_MAX_COMPUTE_UNITS,
                        SizeOf(cl_uint), @computeUnits, nil);

        if computeUnits > maxComputeUnits then
        begin
          maxComputeUnits := computeUnits;
          bestDevice := devices[j];
        end;
      end;
    end;
  end;

  if bestDevice <> nil then
    WriteLn('Meilleur device trouv√©: ', maxComputeUnits, ' compute units');
end;
```

### Configuration sp√©cifique par OS

```pascal
procedure ConfigureForPlatform(ADevice: TGPUDevice);
begin
  {$IFDEF WINDOWS}
  // Optimisations Windows
  WriteLn('Configuration Windows');
  // Utiliser les extensions NVIDIA si disponibles
  {$ENDIF}

  {$IFDEF LINUX}
  // Optimisations Linux
  WriteLn('Configuration Linux');
  // V√©rifier les permissions sur /dev/dri
  {$ENDIF}

  {$IFDEF DARWIN}
  // Optimisations macOS
  WriteLn('Configuration macOS');
  // Utiliser Metal Performance Shaders si possible
  {$ENDIF}
end;
```

---

## Debugging et Profiling

### 1. V√©rification des erreurs

```pascal
function CheckCLError(AError: cl_int; const AContext: string): Boolean;
begin
  Result := AError = CL_SUCCESS;

  if not Result then
  begin
    WriteLn('Erreur OpenCL dans ', AContext, ': ', GetErrorString(AError));

    // Informations suppl√©mentaires selon l'erreur
    case AError of
      CL_OUT_OF_HOST_MEMORY:
        WriteLn('  ‚Üí M√©moire RAM insuffisante');
      CL_OUT_OF_RESOURCES:
        WriteLn('  ‚Üí Ressources GPU insuffisantes');
      CL_MEM_OBJECT_ALLOCATION_FAILURE:
        WriteLn('  ‚Üí Allocation m√©moire GPU √©chou√©e');
      CL_INVALID_WORK_GROUP_SIZE:
        WriteLn('  ‚Üí Taille de work-group invalide');
    end;
  end;
end;
```

### 2. Profiling avec √©v√©nements

```pascal
function ProfileKernelExecution(AQueue: cl_command_queue;
                                 AKernel: cl_kernel;
                                 AGlobalSize: size_t): Double;
var
  event: cl_event;
  err: cl_int;
  startTime, endTime: cl_ulong;
begin
  // Ex√©cuter avec √©v√©nement
  err := clEnqueueNDRangeKernel(AQueue, AKernel, 1, nil, @AGlobalSize,
                                nil, 0, nil, @event);

  if err <> CL_SUCCESS then
  begin
    Result := -1;
    Exit;
  end;

  clFinish(AQueue);

  // R√©cup√©rer les timestamps
  clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_START,
                          SizeOf(cl_ulong), @startTime, nil);
  clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_END,
                          SizeOf(cl_ulong), @endTime, nil);

  // Temps en millisecondes
  Result := (endTime - startTime) / 1000000.0;

  clReleaseEvent(event);
end;
```

### 3. Informations d√©taill√©es du device

```pascal
procedure PrintDeviceInfo(ADevice: cl_device_id);
var
  buffer: array[0..1023] of Char;
  uintValue: cl_uint;
  ulongValue: cl_ulong;
  sizetValue: size_t;
begin
  WriteLn('=== Informations du Device ===');

  // Nom
  clGetDeviceInfo(ADevice, CL_DEVICE_NAME, 1024, @buffer[0], nil);
  WriteLn('Nom: ', string(PChar(@buffer[0])));

  // Vendeur
  clGetDeviceInfo(ADevice, CL_DEVICE_VENDOR, 1024, @buffer[0], nil);
  WriteLn('Vendeur: ', string(PChar(@buffer[0])));

  // Version
  clGetDeviceInfo(ADevice, CL_DEVICE_VERSION, 1024, @buffer[0], nil);
  WriteLn('Version OpenCL: ', string(PChar(@buffer[0])));

  // Compute Units
  clGetDeviceInfo(ADevice, CL_DEVICE_MAX_COMPUTE_UNITS, SizeOf(cl_uint), @uintValue, nil);
  WriteLn('Compute Units: ', uintValue);

  // Fr√©quence
  clGetDeviceInfo(ADevice, CL_DEVICE_MAX_CLOCK_FREQUENCY, SizeOf(cl_uint), @uintValue, nil);
  WriteLn('Fr√©quence max: ', uintValue, ' MHz');

  // M√©moire globale
  clGetDeviceInfo(ADevice, CL_DEVICE_GLOBAL_MEM_SIZE, SizeOf(cl_ulong), @ulongValue, nil);
  WriteLn('M√©moire globale: ', ulongValue div (1024*1024), ' MB');

  // M√©moire locale
  clGetDeviceInfo(ADevice, CL_DEVICE_LOCAL_MEM_SIZE, SizeOf(cl_ulong), @ulongValue, nil);
  WriteLn('M√©moire locale: ', ulongValue div 1024, ' KB');

  // Taille max work-group
  clGetDeviceInfo(ADevice, CL_DEVICE_MAX_WORK_GROUP_SIZE, SizeOf(size_t), @sizetValue, nil);
  WriteLn('Max work-group size: ', sizetValue);

  WriteLn('==============================');
end;
```

---

## Bonnes Pratiques

### 1. Gestion de la m√©moire

```pascal
// Toujours v√©rifier et lib√©rer les ressources
procedure SafeGPUCompute;
var
  device: TGPUDevice;
  buffer: cl_mem;
begin
  device := TGPUDevice.Create;
  try
    if not device.Initialize then
      raise Exception.Create('Initialisation GPU √©chou√©e');

    buffer := device.CreateBuffer(1024, CL_MEM_READ_WRITE);
    if buffer = nil then
      raise Exception.Create('Cr√©ation buffer √©chou√©e');

    try
      // Utiliser le buffer
      // ...
    finally
      device.ReleaseBuffer(buffer);
    end;

  finally
    device.Free;
  end;
end;
```

### 2. Choix de la taille de work-group

```pascal
function GetOptimalWorkGroupSize(ADevice: cl_device_id;
                                  AKernel: cl_kernel): size_t;
var
  maxSize, preferredMultiple: size_t;
begin
  // Taille maximale
  clGetDeviceInfo(ADevice, CL_DEVICE_MAX_WORK_GROUP_SIZE,
                  SizeOf(size_t), @maxSize, nil);

  // Multiple pr√©f√©r√© (pour les warps/wavefronts)
  clGetKernelWorkGroupInfo(AKernel, ADevice,
                           CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLE,
                           SizeOf(size_t), @preferredMultiple, nil);

  // Choisir un multiple qui ne d√©passe pas le max
  Result := preferredMultiple;
  while Result * 2 <= maxSize do
    Result := Result * 2;
end;
```

### 3. Gestion des erreurs de compilation

```pascal
function CompileWithErrorHandling(ADevice: TGPUDevice;
                                   const ASource, AKernelName: string): TGPUKernel;
var
  err: cl_int;
  buildLog: array[0..16383] of Char;
  logSize: size_t;
begin
  Result := TGPUKernel.Create(ADevice);

  if not Result.CompileFromSource(ASource, AKernelName) then
  begin
    // R√©cup√©rer le log de compilation
    err := clGetProgramBuildInfo(Result.FProgram, ADevice.Device,
                                  CL_PROGRAM_BUILD_LOG, 16384,
                                  @buildLog[0], @logSize);

    if err = CL_SUCCESS then
    begin
      WriteLn('Erreur de compilation:');
      WriteLn(string(PChar(@buildLog[0])));
    end;

    FreeAndNil(Result);
  end;
end;
```

---

## Ressources et Documentation

### Documentation officielle

üìö **OpenCL**
- Khronos OpenCL: https://www.khronos.org/opencl/
- OpenCL Reference: https://www.khronos.org/registry/OpenCL/
- Tutoriels: https://github.com/KhronosGroup/OpenCL-Guide

üìö **CUDA**
- NVIDIA CUDA Toolkit: https://developer.nvidia.com/cuda-toolkit
- CUDA C Programming Guide: https://docs.nvidia.com/cuda/cuda-c-programming-guide/
- CUDA Best Practices: https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/

### Outils de d√©veloppement

üõ†Ô∏è **Profilers**
- NVIDIA Nsight (CUDA)
- AMD CodeXL (OpenCL)
- Intel VTune (OpenCL)

üõ†Ô∏è **Debuggers**
- NVIDIA cuda-gdb
- AMD ROCm debugger
- Intel GDB with OpenCL support

### Biblioth√®ques utiles

**Pour OpenCL :**
- clBLAS - Alg√®bre lin√©aire
- clFFT - Transform√©es de Fourier
- clRNG - G√©n√©rateurs de nombres al√©atoires

**Pour CUDA :**
- cuBLAS - Alg√®bre lin√©aire
- cuDNN - Deep Learning
- Thrust - Algorithmes parall√®les

---

## Conclusion

### Ce que vous avez appris

Au cours de ce tutoriel, vous avez d√©couvert :

‚úÖ **Fondamentaux du GPU computing**
- Diff√©rence CPU vs GPU
- Parall√©lisme massif
- Architecture SIMT

‚úÖ **OpenCL et CUDA**
- Installation et configuration
- API et concepts cl√©s
- Kernels et ex√©cution

‚úÖ **Impl√©mentation en FreePascal**
- Bindings OpenCL
- Wrapper orient√© objet
- Gestion de la m√©moire

‚úÖ **Applications pratiques**
- Addition de vecteurs
- Traitement d'images
- Multiplication de matrices
- Fractales (Mandelbrot)

‚úÖ **Optimisation**
- M√©moire locale
- Coalescence
- Vectorisation
- Profiling

‚úÖ **D√©ploiement multi-plateforme**
- Windows, Linux, macOS
- S√©lection automatique du device
- Gestion des erreurs

### Avantages du GPU avec FreePascal

**Performance exceptionnelle**
- üöÄ 10-1000√ó plus rapide pour calculs parall√®les
- ‚ö° Traitement temps r√©el d'images/vid√©os
- üí™ Deep Learning performant

**D√©ploiement simplifi√©**
- üì¶ Ex√©cutables natifs avec OpenCL
- üîß Pas de d√©pendances Python
- üíæ Code compil√© optimis√©

**Portabilit√©**
- ü™ü Windows (NVIDIA, AMD, Intel)
- üêß Linux (drivers open source)
- üçé macOS (Metal + OpenCL)

### Quand utiliser le GPU ?

**‚úì Parfait pour :**
- Traitement d'images/vid√©os en masse
- Deep Learning (inf√©rence)
- Simulations scientifiques
- Calculs math√©matiques vectoriels
- Cryptographie (hashing, signatures)
- Rendu 3D temps r√©el

**‚úó Moins adapt√© pour :**
- Petites quantit√©s de donn√©es (<10k √©l√©ments)
- Algorithmes s√©quentiels
- Beaucoup de branchements
- Acc√®s m√©moire tr√®s irr√©guliers

### Comparaison finale

| Aspect | CPU | GPU | GPU + FreePascal |
|--------|-----|-----|------------------|
| **Performance s√©quentielle** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **Performance parall√®le** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Facilit√© d√©veloppement** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **D√©ploiement** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Portabilit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

### Prochaines √©tapes

**Pour aller plus loin :**

1. **Approfondir OpenCL**
   - M√©moire partag√©e avanc√©e
   - Pipes et SVM (Shared Virtual Memory)
   - SPIR-V

2. **Explorer CUDA**
   - Unified Memory
   - Streams et concurrence
   - Tensor Cores (deep learning)

3. **Biblioth√®ques sp√©cialis√©es**
   - Int√©grer clBLAS/cuBLAS
   - Utiliser clFFT pour traitement du signal
   - TensorFlow/PyTorch avec GPU

4. **Applications avanc√©es**
   - Ray tracing temps r√©el
   - Simulations physiques
   - R√©seaux de neurones from scratch
   - Computer vision temps r√©el

### Message final

Le GPU computing avec FreePascal/Lazarus vous offre le **meilleur des deux mondes** :

- La **puissance** du calcul parall√®le GPU
- La **simplicit√©** et **performance** de FreePascal
- Le **d√©ploiement facile** sans d√©pendances lourdes

Que ce soit pour :
- Acc√©l√©rer vos applications de traitement d'images
- Cr√©er des simulations scientifiques performantes
- D√©ployer des mod√®les d'IA en production
- D√©velopper des jeux avec physique r√©aliste

Le GPU est votre alli√©, et FreePascal vous permet de l'exploiter pleinement !

**Le calcul parall√®le n'est plus r√©serv√© aux super-ordinateurs !** Avec un simple GPU de gaming et FreePascal, vous pouvez accomplir des performances qui auraient n√©cessit√© un cluster entier il y a quelques ann√©es.

Bon computing parall√®le et bonnes optimisations ! üöÄüíª‚ö°

---

*Fin du tutoriel 15.9 - GPU computing avec CUDA/OpenCL*

**Prochaine √©tape recommand√©e :** Combiner GPU computing avec deep learning, vision par ordinateur et ONNX pour cr√©er des applications d'IA ultra-performantes !

‚è≠Ô∏è [D√©ploiement de mod√®les IA](/15-intelligence-artificielle-machine-learning/10-deploiement-modeles-ia.md)
