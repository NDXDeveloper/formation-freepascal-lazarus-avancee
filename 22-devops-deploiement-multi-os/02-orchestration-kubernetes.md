ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 22.2 Orchestration Kubernetes

## Introduction Ã  Kubernetes

Vous avez appris Ã  conteneuriser vos applications FreePascal/Lazarus avec Docker dans la section 22.1. Excellent ! Mais que se passe-t-il quand vous devez gÃ©rer **des dizaines, voire des centaines de conteneurs** ? Comment gÃ©rer la montÃ©e en charge, les pannes, les mises Ã  jour sans interruption ? C'est lÃ  qu'intervient **Kubernetes**.

### Qu'est-ce que Kubernetes ?

**Kubernetes** (souvent abrÃ©gÃ© **K8s** - K + 8 lettres + s) est un systÃ¨me d'orchestration de conteneurs open source dÃ©veloppÃ© par Google, maintenant maintenu par la Cloud Native Computing Foundation (CNCF).

**Analogie simple :**
- **Docker** = Un chef cuisinier qui prÃ©pare un plat
- **Kubernetes** = Un restaurant complet qui gÃ¨re plusieurs chefs, commandes, clients, stocks

**Kubernetes fait pour vous :**
- ğŸš€ **DÃ©ploiement automatisÃ©** : Lance vos applications sur un cluster
- âš–ï¸ **Load balancing** : RÃ©partit le trafic entre plusieurs instances
- ğŸ”„ **Auto-scaling** : Ajoute/retire des instances selon la charge
- ğŸ¥ **Auto-healing** : RedÃ©marre les conteneurs qui plantent
- ğŸ“¦ **Rolling updates** : Mise Ã  jour sans interruption de service
- ğŸ”™ **Rollback** : Retour arriÃ¨re si problÃ¨me
- ğŸ’¾ **Gestion du stockage** : Monte volumes et secrets
- ğŸŒ **Service discovery** : Les conteneurs se trouvent automatiquement

### Pourquoi Kubernetes pour FreePascal/Lazarus ?

**ScÃ©nario sans Kubernetes :**
```
Vous avez dÃ©veloppÃ© une API FreePascal qui fonctionne super bien.
Soudain, 1000 utilisateurs se connectent simultanÃ©ment.
â†’ Votre serveur plante
â†’ Vous devez manuellement lancer plus d'instances
â†’ Configurer le load balancer manuellement
â†’ GÃ©rer les adresses IP
â†’ Monitorer chaque serveur individuellement
â†’ Stress maximal ! ğŸ˜°
```

**ScÃ©nario avec Kubernetes :**
```yaml
replicas: 1  # Normalement 1 instance suffit

# Charge Ã©levÃ©e dÃ©tectÃ©e
â†’ Kubernetes lance automatiquement 10 instances
â†’ Load balancer configurÃ© automatiquement
â†’ Trafic rÃ©parti Ã©quitablement
â†’ Tout fonctionne parfaitement ! ğŸ˜Š

# Charge normale revenue
â†’ Kubernetes rÃ©duit Ã  2 instances
â†’ Ã‰conomie de ressources
```

### Concepts de base (vocabulaire K8s)

Avant de plonger, familiarisons-nous avec le vocabulaire Kubernetes :

**Cluster**
Un ensemble de machines (physiques ou virtuelles) qui exÃ©cutent Kubernetes.
```
Cluster = Control Plane + Nodes
```

**Node (NÅ“ud)**
Une machine (serveur) dans le cluster. Peut Ãªtre :
- **Master Node** : GÃ¨re le cluster (Control Plane)
- **Worker Node** : ExÃ©cute vos applications

**Pod**
La plus petite unitÃ© dÃ©ployable dans Kubernetes. Contient un ou plusieurs conteneurs.
```
Pod = 1 ou plusieurs conteneurs Docker qui partagent :
- RÃ©seau (mÃªme IP)
- Stockage
- Cycle de vie
```

**Deployment**
DÃ©clare l'Ã©tat dÃ©sirÃ© de votre application.
```yaml
Je veux 3 instances de mon API FreePascal,
avec la version 1.2.3,
utilisant 512MB de RAM chacune
```

**Service**
Point d'accÃ¨s stable pour communiquer avec vos Pods.
```
Service = Load Balancer interne pour vos Pods
```

**Namespace**
Espace de noms pour isoler les ressources.
```
namespace "production"
namespace "staging"
namespace "dev"
```

**ConfigMap & Secret**
- **ConfigMap** : Configuration en clair
- **Secret** : Configuration sensible (mots de passe, clÃ©s)

### Architecture Kubernetes

Comprenons comment Kubernetes fonctionne :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTROL PLANE                       â”‚
â”‚  (Cerveau du cluster - Prend les dÃ©cisions)            â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ API Server  â”‚  â”‚  Scheduler   â”‚  â”‚  Controller  â”‚   â”‚
â”‚  â”‚ (Interface) â”‚  â”‚  (Placement) â”‚  â”‚   Manager    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              etcd (Base de donnÃ©es)              â”‚  â”‚
â”‚  â”‚         Stocke l'Ã©tat du cluster                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker Node 1  â”‚ â”‚ Worker Node 2 â”‚ â”‚ Worker Node 3  â”‚
â”‚                  â”‚ â”‚               â”‚ â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Pod 1    â”‚  â”‚ â”‚  â”‚  Pod 3   â”‚ â”‚ â”‚  â”‚  Pod 5   â”‚  â”‚
â”‚  â”‚ (API FPC)  â”‚  â”‚ â”‚  â”‚ (DB)     â”‚ â”‚ â”‚  â”‚ (Cache)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚                â”‚
â”‚  â”‚   Pod 2    â”‚  â”‚ â”‚  â”‚  Pod 4   â”‚ â”‚ â”‚                â”‚
â”‚  â”‚ (API FPC)  â”‚  â”‚ â”‚  â”‚ (Web)    â”‚ â”‚ â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚                â”‚
â”‚                  â”‚ â”‚               â”‚ â”‚                â”‚
â”‚    Kubelet       â”‚ â”‚   Kubelet     â”‚ â”‚   Kubelet      â”‚
â”‚    (Agent)       â”‚ â”‚   (Agent)     â”‚ â”‚   (Agent)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Composants du Control Plane :**

**API Server**
- Point d'entrÃ©e pour toutes les commandes
- Vous interagissez avec lui via `kubectl`

**Scheduler**
- DÃ©cide sur quel Node placer chaque Pod
- Prend en compte : ressources disponibles, contraintes, affinitÃ©

**Controller Manager**
- Surveille l'Ã©tat du cluster
- Assure que l'Ã©tat rÃ©el = Ã©tat dÃ©sirÃ©
- Exemple : Si un Pod meurt, le Controller en lance un nouveau

**etcd**
- Base de donnÃ©es clÃ©-valeur
- Stocke toute la configuration du cluster
- Source de vÃ©ritÃ© unique

**Composants des Worker Nodes :**

**Kubelet**
- Agent qui tourne sur chaque Node
- ReÃ§oit les ordres du Control Plane
- Lance et surveille les Pods

**Kube-proxy**
- GÃ¨re le rÃ©seau
- ImplÃ©mente les Services
- Fait du load balancing

**Container Runtime**
- Docker, containerd, ou CRI-O
- ExÃ©cute rÃ©ellement les conteneurs

## Installation de Kubernetes

Il existe plusieurs faÃ§ons d'installer Kubernetes selon vos besoins.

### Option 1 : Minikube (DÃ©veloppement local - RecommandÃ© pour dÃ©buter)

Minikube crÃ©e un cluster Kubernetes local sur votre machine.

**Installation sur Ubuntu :**

```bash
# TÃ©lÃ©charger Minikube
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# VÃ©rifier
minikube version
```

**Installation sur Windows :**

```powershell
# Avec Chocolatey
choco install minikube

# Ou tÃ©lÃ©charger depuis
# https://minikube.sigs.k8s.io/docs/start/
```

**DÃ©marrer Minikube :**

```bash
# DÃ©marrer un cluster local
minikube start

# VÃ©rifier le statut
minikube status

# Interface web (optionnel)
minikube dashboard
```

### Option 2 : Docker Desktop Kubernetes

Docker Desktop inclut Kubernetes intÃ©grÃ©.

**Activation :**

1. Ouvrez Docker Desktop
2. Settings â†’ Kubernetes
3. Cochez "Enable Kubernetes"
4. Apply & Restart

**VÃ©rification :**
```bash
kubectl cluster-info
```

### Option 3 : Kind (Kubernetes IN Docker)

Kind crÃ©e des clusters Kubernetes dans des conteneurs Docker.

```bash
# Installation
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# CrÃ©er un cluster
kind create cluster --name mon-cluster

# Lister les clusters
kind get clusters

# Supprimer un cluster
kind delete cluster --name mon-cluster
```

### Option 4 : Production (Cloud ou bare-metal)

Pour la production, utilisez des solutions gÃ©rÃ©es ou installÃ©es :

**Cloud managÃ© (recommandÃ©) :**
- **GKE** (Google Kubernetes Engine)
- **EKS** (Amazon Elastic Kubernetes Service)
- **AKS** (Azure Kubernetes Service)
- **DigitalOcean Kubernetes**

**Auto-hÃ©bergÃ© :**
- **kubeadm** : Installation officielle
- **k3s** : Kubernetes lÃ©ger (parfait pour edge/IoT)
- **RKE** : Rancher Kubernetes Engine

### Installation de kubectl

`kubectl` est l'outil en ligne de commande pour interagir avec Kubernetes.

**Sur Ubuntu :**
```bash
# TÃ©lÃ©charger kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

# Installer
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# VÃ©rifier
kubectl version --client
```

**Sur Windows :**
```powershell
# Avec Chocolatey
choco install kubernetes-cli

# VÃ©rifier
kubectl version --client
```

**VÃ©rifier la connexion au cluster :**
```bash
kubectl cluster-info
kubectl get nodes
```

## Premier dÃ©ploiement : Application FreePascal simple

DÃ©ployons une application FreePascal simple sur Kubernetes.

### Ã‰tape 1 : PrÃ©parer l'image Docker

Supposons que vous avez cette application FreePascal :

**Fichier : `hello.pas`**
```pascal
program HelloK8s;

{$mode objfpc}{$H+}

uses
  SysUtils, fphttpserver;

var
  Server: TFPHTTPServer;

procedure HandleRequest(Sender: TObject; var Request: TFPHTTPConnectionRequest;
  var Response: TFPHTTPConnectionResponse);
begin
  Response.Content := '<h1>Hello from FreePascal on Kubernetes!</h1>' +
                      '<p>Hostname: ' + GetHostName + '</p>' +
                      '<p>Version: 1.0.0</p>';
  Response.Code := 200;
  Response.ContentType := 'text/html';
end;

begin
  Server := TFPHTTPServer.Create(nil);
  try
    Server.Port := 8080;
    Server.OnRequest := @HandleRequest;
    WriteLn('Serveur dÃ©marrÃ© sur le port 8080');
    Server.Active := True;
    ReadLn;
  finally
    Server.Free;
  end;
end.
```

**Dockerfile :**
```dockerfile
FROM ubuntu:22.04

RUN apt-get update && \
    apt-get install -y fpc && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY hello.pas .
RUN fpc hello.pas

EXPOSE 8080

CMD ["./hello"]
```

**Construire et pousser l'image :**
```bash
# Construire
docker build -t votre-username/hello-fpc:1.0.0 .

# Se connecter Ã  Docker Hub
docker login

# Pousser
docker push votre-username/hello-fpc:1.0.0
```

### Ã‰tape 2 : CrÃ©er un Deployment

Un Deployment dÃ©crit comment dÃ©ployer votre application.

**Fichier : `deployment.yaml`**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-fpc-deployment
  labels:
    app: hello-fpc
spec:
  replicas: 3  # 3 instances de votre application
  selector:
    matchLabels:
      app: hello-fpc
  template:
    metadata:
      labels:
        app: hello-fpc
    spec:
      containers:
      - name: hello-fpc
        image: votre-username/hello-fpc:1.0.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
```

**Explication ligne par ligne :**

- `apiVersion: apps/v1` : Version de l'API Kubernetes
- `kind: Deployment` : Type de ressource
- `metadata.name` : Nom unique du Deployment
- `spec.replicas: 3` : On veut 3 Pods identiques
- `selector.matchLabels` : Comment identifier les Pods
- `template` : Template du Pod
  - `containers` : Liste des conteneurs
    - `image` : Image Docker Ã  utiliser
    - `ports` : Ports exposÃ©s
    - `resources` : Ressources CPU/RAM
      - `requests` : Minimum garanti
      - `limits` : Maximum autorisÃ©

**Appliquer le Deployment :**
```bash
kubectl apply -f deployment.yaml
```

**VÃ©rifier :**
```bash
# Voir les Deployments
kubectl get deployments

# Voir les Pods crÃ©Ã©s
kubectl get pods

# DÃ©tails d'un Pod
kubectl describe pod <nom-du-pod>

# Logs d'un Pod
kubectl logs <nom-du-pod>
```

### Ã‰tape 3 : CrÃ©er un Service

Un Service expose votre application sur le rÃ©seau.

**Fichier : `service.yaml`**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: hello-fpc-service
spec:
  type: LoadBalancer  # Type de Service
  selector:
    app: hello-fpc  # SÃ©lectionne les Pods avec ce label
  ports:
    - protocol: TCP
      port: 80        # Port externe
      targetPort: 8080  # Port du conteneur
```

**Types de Service :**

**ClusterIP (dÃ©faut)**
- Accessible uniquement dans le cluster
- Pour communication interne

**NodePort**
- Expose sur un port de chaque Node
- Accessible via <NodeIP>:<NodePort>

**LoadBalancer**
- CrÃ©e un load balancer externe (cloud)
- Meilleur pour production

**ExternalName**
- Mappe vers un nom DNS externe

**Appliquer le Service :**
```bash
kubectl apply -f service.yaml

# Voir les Services
kubectl get services

# Attendre l'IP externe (si LoadBalancer)
kubectl get services -w
```

### Ã‰tape 4 : AccÃ©der Ã  l'application

**Avec Minikube :**
```bash
# Obtenir l'URL
minikube service hello-fpc-service --url

# Ou ouvrir dans le navigateur
minikube service hello-fpc-service
```

**Avec LoadBalancer (cloud) :**
```bash
# RÃ©cupÃ©rer l'IP externe
kubectl get service hello-fpc-service

# AccÃ©der via navigateur
http://<EXTERNAL-IP>
```

**Test avec curl :**
```bash
curl http://<IP-ou-URL>
```

Vous devriez voir :
```html
<h1>Hello from FreePascal on Kubernetes!</h1>
<p>Hostname: hello-fpc-deployment-abc123</p>
<p>Version: 1.0.0</p>
```

**Actualiser plusieurs fois** : vous verrez des hostnames diffÃ©rents â†’ le load balancer rÃ©partit entre les 3 Pods !

## Gestion des configurations avec ConfigMap et Secret

Les applications ont besoin de configuration. Kubernetes offre ConfigMap et Secret.

### ConfigMap : Configuration non-sensible

**Fichier : `configmap.yaml`**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  APP_NAME: "Mon Application FreePascal"
  APP_VERSION: "1.0.0"
  LOG_LEVEL: "INFO"
  DATABASE_HOST: "postgres-service"
  DATABASE_PORT: "5432"
  config.ini: |
    [Application]
    Name=Mon Application
    Version=1.0.0

    [Database]
    Host=postgres-service
    Port=5432
```

**Utiliser dans un Deployment :**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-fpc-deployment
spec:
  template:
    spec:
      containers:
      - name: hello-fpc
        image: votre-username/hello-fpc:1.0.0
        # Variables d'environnement depuis ConfigMap
        env:
        - name: APP_NAME
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: APP_NAME
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: LOG_LEVEL
        # Monter config.ini comme fichier
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
      volumes:
      - name: config-volume
        configMap:
          name: app-config
          items:
          - key: config.ini
            path: config.ini
```

**Dans votre code FreePascal :**
```pascal
// Lire variable d'environnement
AppName := GetEnvironmentVariable('APP_NAME');

// Lire fichier de config montÃ©
AssignFile(F, '/app/config/config.ini');
Reset(F);
// ...
```

### Secret : DonnÃ©es sensibles

Les Secrets stockent des donnÃ©es sensibles (mots de passe, clÃ©s API, certificats).

**CrÃ©er un Secret depuis la ligne de commande :**
```bash
kubectl create secret generic db-secret \
  --from-literal=username=dbuser \
  --from-literal=password=supersecret123
```

**Ou depuis un fichier YAML (Base64 encodÃ©) :**
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  username: ZGJ1c2Vy  # "dbuser" en Base64
  password: c3VwZXJzZWNyZXQxMjM=  # "supersecret123" en Base64
```

**Encoder en Base64 :**
```bash
echo -n "dbuser" | base64
echo -n "supersecret123" | base64
```

**Utiliser dans un Deployment :**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-fpc-deployment
spec:
  template:
    spec:
      containers:
      - name: hello-fpc
        image: votre-username/hello-fpc:1.0.0
        env:
        - name: DB_USERNAME
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
```

**Dans votre code FreePascal :**
```pascal
DBUsername := GetEnvironmentVariable('DB_USERNAME');
DBPassword := GetEnvironmentVariable('DB_PASSWORD');
```

## Stockage persistant avec Persistent Volumes

Les conteneurs sont Ã©phÃ©mÃ¨res. Pour persister des donnÃ©es, utilisez des Persistent Volumes.

### PersistentVolumeClaim (PVC)

**Fichier : `pvc.yaml`**
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-data-pvc
spec:
  accessModes:
    - ReadWriteOnce  # Un seul Pod en lecture/Ã©criture
  resources:
    requests:
      storage: 10Gi  # 10 GB de stockage
  storageClassName: standard  # Classe de stockage (dÃ©pend du provider)
```

**AccessModes :**
- `ReadWriteOnce` (RWO) : Un seul Node en lecture/Ã©criture
- `ReadOnlyMany` (ROX) : Plusieurs Nodes en lecture seule
- `ReadWriteMany` (RWX) : Plusieurs Nodes en lecture/Ã©criture

**Utiliser dans un Deployment :**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-fpc-deployment
spec:
  template:
    spec:
      containers:
      - name: hello-fpc
        image: votre-username/hello-fpc:1.0.0
        volumeMounts:
        - name: data-volume
          mountPath: /app/data  # Chemin dans le conteneur
      volumes:
      - name: data-volume
        persistentVolumeClaim:
          claimName: app-data-pvc
```

**Dans votre code FreePascal :**
```pascal
// Ã‰crire dans le volume persistant
DataPath := '/app/data/';
AssignFile(F, DataPath + 'database.db');
Rewrite(F);
// Les donnÃ©es survivent aux redÃ©marrages du Pod
```

## Scaling : MontÃ©e en charge automatique

Kubernetes peut automatiquement ajuster le nombre de Pods selon la charge.

### Scaling manuel

```bash
# Passer de 3 Ã  10 rÃ©plicas
kubectl scale deployment hello-fpc-deployment --replicas=10

# VÃ©rifier
kubectl get pods
```

### Horizontal Pod Autoscaler (HPA)

Le HPA ajuste automatiquement le nombre de Pods selon des mÃ©triques (CPU, RAM, custom).

**PrÃ©requis : Metrics Server**

Sur Minikube :
```bash
minikube addons enable metrics-server
```

Sur cluster standard :
```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

**CrÃ©er un HPA :**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hello-fpc-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: hello-fpc-deployment
  minReplicas: 2    # Minimum 2 Pods
  maxReplicas: 10   # Maximum 10 Pods
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50  # Maintenir CPU Ã  50%
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70  # Maintenir RAM Ã  70%
```

**Appliquer :**
```bash
kubectl apply -f hpa.yaml

# Voir le statut
kubectl get hpa

# Surveiller en temps rÃ©el
kubectl get hpa -w
```

**Test de charge :**
```bash
# GÃ©nÃ©rer du trafic
kubectl run -it --rm load-generator --image=busybox /bin/sh

# Dans le conteneur
while true; do wget -q -O- http://hello-fpc-service; done
```

Observez le HPA augmenter automatiquement les rÃ©plicas !

## Mises Ã  jour et rollbacks

Kubernetes facilite les mises Ã  jour sans interruption.

### Rolling Update (Mise Ã  jour progressive)

**Nouvelle version de votre app :**
```bash
# Construire la v1.1.0
docker build -t votre-username/hello-fpc:1.1.0 .
docker push votre-username/hello-fpc:1.1.0
```

**Mettre Ã  jour le Deployment :**
```bash
# MÃ©thode 1 : Via kubectl
kubectl set image deployment/hello-fpc-deployment \
  hello-fpc=votre-username/hello-fpc:1.1.0

# MÃ©thode 2 : Modifier le YAML
# Changez image: votre-username/hello-fpc:1.1.0
kubectl apply -f deployment.yaml
```

**Suivre la mise Ã  jour :**
```bash
kubectl rollout status deployment/hello-fpc-deployment
```

**Comment Ã§a fonctionne :**
```
1. CrÃ©er un nouveau Pod avec v1.1.0
2. Attendre qu'il soit prÃªt
3. Supprimer un ancien Pod v1.0.0
4. RÃ©pÃ©ter jusqu'Ã  remplacement complet
```

**StratÃ©gie de rolling update (dans deployment.yaml) :**
```yaml
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Max 1 Pod supplÃ©mentaire pendant update
      maxUnavailable: 0  # Toujours au moins N Pods disponibles
```

### Rollback (Retour arriÃ¨re)

Si la nouvelle version a des problÃ¨mes :

```bash
# Annuler la derniÃ¨re mise Ã  jour
kubectl rollout undo deployment/hello-fpc-deployment

# Retourner Ã  une rÃ©vision spÃ©cifique
kubectl rollout history deployment/hello-fpc-deployment
kubectl rollout undo deployment/hello-fpc-deployment --to-revision=2
```

## Application complÃ¨te : Stack FreePascal avec PostgreSQL

DÃ©ployons une application complÃ¨te avec API FreePascal, base de donnÃ©es PostgreSQL et cache Redis.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ingress   â”‚ â† Point d'entrÃ©e externe
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Service    â”‚ â† Load Balancer
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
 â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚           â”‚         â”‚         â”‚
â”Œâ–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”
â”‚ API   â”‚  â”‚ API   â”‚ â”‚ API   â”‚ â”‚ Redis â”‚
â”‚ Pod 1 â”‚  â”‚ Pod 2 â”‚ â”‚ Pod 3 â”‚ â”‚  Pod  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   PostgreSQL    â”‚
      â”‚   StatefulSet   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PostgreSQL StatefulSet

**Fichier : `postgres-statefulset.yaml`**
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: "myapp"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
```

**Service PostgreSQL :**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  clusterIP: None  # Headless Service pour StatefulSet
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
```

### Redis Deployment

**Fichier : `redis-deployment.yaml`**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        command: ["redis-server", "--appendonly", "yes"]
        volumeMounts:
        - name: redis-storage
          mountPath: /data
      volumes:
      - name: redis-storage
        persistentVolumeClaim:
          claimName: redis-pvc
```

### API FreePascal Deployment

**Fichier : `api-deployment.yaml`**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-fpc
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-fpc
  template:
    metadata:
      labels:
        app: api-fpc
        version: v1
    spec:
      containers:
      - name: api
        image: votre-username/api-fpc:1.0.0
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          value: "postgres"
        - name: DB_PORT
          value: "5432"
        - name: DB_NAME
          value: "myapp"
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        - name: REDIS_HOST
          value: "redis"
        - name: REDIS_PORT
          value: "6379"
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
```

**Service API :**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: api-fpc-service
spec:
  type: ClusterIP
  selector:
    app: api-fpc
  ports:
  - port: 80
    targetPort: 8080
```

### Ingress pour exposition externe

L'Ingress gÃ¨re l'accÃ¨s HTTP/HTTPS depuis l'extÃ©rieur.

**Fichier : `ingress.yaml`**
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: api-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: api.monapp.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-fpc-service
            port:
              number: 80
```

**Installer Ingress Controller (nginx) :**

```bash
# Sur Minikube
minikube addons enable ingress

# Sur cluster standard
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml
```

### DÃ©ploiement complet de la stack

**Script : `deploy-all.sh`**
```bash
#!/bin/bash
set -e

echo "=== DÃ©ploiement de la stack FreePascal sur Kubernetes ==="

# CrÃ©er le namespace
kubectl create namespace freepascal-app || true
kubectl config set-context --current --namespace=freepascal-app

# Secrets
echo "[1/7] CrÃ©ation des secrets..."
kubectl create secret generic db-secret \
  --from-literal=username=dbuser \
  --from-literal=password=supersecret123 \
  --dry-run=client -o yaml | kubectl apply -f -

# PostgreSQL
echo "[2/7] DÃ©ploiement PostgreSQL..."
kubectl apply -f postgres-statefulset.yaml
kubectl apply -f postgres-service.yaml

# Attendre que PostgreSQL soit prÃªt
echo "   Attente de PostgreSQL..."
kubectl wait --for=condition=ready pod -l app=postgres --timeout=300s

# Redis
echo "[3/7] DÃ©ploiement Redis..."
kubectl apply -f redis-pvc.yaml
kubectl apply -f redis-deployment.yaml
kubectl apply -f redis-service.yaml

# API FreePascal
echo "[4/7] DÃ©ploiement API FreePascal..."
kubectl apply -f api-deployment.yaml
kubectl apply -f api-service.yaml

# ConfigMap
echo "[5/7] Application de la configuration..."
kubectl apply -f configmap.yaml

# HPA
echo "[6/7] Configuration de l'autoscaling..."
kubectl apply -f hpa.yaml

# Ingress
echo "[7/7] Configuration de l'Ingress..."
kubectl apply -f ingress.yaml

echo ""
echo "=== DÃ©ploiement terminÃ© ==="
echo ""
echo "VÃ©rifiez l'Ã©tat avec :"
echo "  kubectl get all"
echo ""
echo "AccÃ©dez Ã  l'API via :"
if command -v minikube &> /dev/null; then
    minikube service api-fpc-service --url
fi
```

## Health Checks et Probes

Kubernetes utilise des probes pour surveiller la santÃ© de vos Pods.

### Types de Probes

**1. Liveness Probe**
- "Est-ce que mon application fonctionne ?"
- Si Ã©choue â†’ Kubernetes redÃ©marre le Pod

**2. Readiness Probe**
- "Est-ce que mon application est prÃªte Ã  recevoir du trafic ?"
- Si Ã©choue â†’ Le Pod est retirÃ© du load balancing

**3. Startup Probe**
- "Est-ce que mon application a fini de dÃ©marrer ?"
- Utile pour applications Ã  dÃ©marrage lent

### ImplÃ©mentation dans FreePascal

**Code FreePascal avec endpoints de health check :**

```pascal
program APIHealthCheck;

{$mode objfpc}{$H+}

uses
  SysUtils, fphttpserver, sqldb, pqconnection;

var
  Server: TFPHTTPServer;
  DBConnection: TPQConnection;
  IsReady: Boolean = False;

function CheckDatabaseConnection: Boolean;
begin
  try
    if not DBConnection.Connected then
      DBConnection.Open;
    Result := DBConnection.Connected;
  except
    Result := False;
  end;
end;

procedure HandleHealth(var Response: TFPHTTPConnectionResponse);
begin
  // Liveness : L'application tourne-t-elle ?
  Response.Code := 200;
  Response.Content := '{"status":"ok","timestamp":"' +
                      FormatDateTime('yyyy-mm-dd hh:nn:ss', Now) + '"}';
  Response.ContentType := 'application/json';
end;

procedure HandleReadiness(var Response: TFPHTTPConnectionResponse);
begin
  // Readiness : Peut-on servir des requÃªtes ?
  if IsReady and CheckDatabaseConnection then
  begin
    Response.Code := 200;
    Response.Content := '{"status":"ready","database":"connected"}';
  end
  else
  begin
    Response.Code := 503;  // Service Unavailable
    Response.Content := '{"status":"not ready","database":"disconnected"}';
  end;
  Response.ContentType := 'application/json';
end;

procedure HandleRequest(Sender: TObject;
  var Request: TFPHTTPConnectionRequest;
  var Response: TFPHTTPConnectionResponse);
begin
  if Request.URI = '/health' then
    HandleHealth(Response)
  else if Request.URI = '/ready' then
    HandleReadiness(Response)
  else if Request.URI = '/' then
  begin
    Response.Code := 200;
    Response.Content := '{"message":"API FreePascal","version":"1.0.0"}';
    Response.ContentType := 'application/json';
  end
  else
  begin
    Response.Code := 404;
    Response.Content := '{"error":"Not Found"}';
    Response.ContentType := 'application/json';
  end;
end;

procedure InitializeDatabase;
begin
  DBConnection := TPQConnection.Create(nil);
  DBConnection.HostName := GetEnvironmentVariable('DB_HOST');
  DBConnection.DatabaseName := GetEnvironmentVariable('DB_NAME');
  DBConnection.UserName := GetEnvironmentVariable('DB_USER');
  DBConnection.Password := GetEnvironmentVariable('DB_PASSWORD');

  try
    DBConnection.Open;
    IsReady := True;
    WriteLn('Base de donnÃ©es connectÃ©e - Application prÃªte');
  except
    on E: Exception do
    begin
      WriteLn('Erreur connexion BD: ', E.Message);
      IsReady := False;
    end;
  end;
end;

begin
  WriteLn('DÃ©marrage de l''API FreePascal...');

  // Initialiser la connexion BD
  InitializeDatabase;

  Server := TFPHTTPServer.Create(nil);
  try
    Server.Port := 8080;
    Server.OnRequest := @HandleRequest;
    WriteLn('Serveur dÃ©marrÃ© sur le port 8080');
    Server.Active := True;

    // Maintenir le serveur actif
    while True do
      Sleep(1000);
  finally
    Server.Free;
    DBConnection.Free;
  end;
end.
```

**Configuration des probes dans le Deployment :**

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30  # Attendre 30s aprÃ¨s dÃ©marrage
  periodSeconds: 10        # VÃ©rifier toutes les 10s
  timeoutSeconds: 5        # Timeout aprÃ¨s 5s
  failureThreshold: 3      # RedÃ©marrer aprÃ¨s 3 Ã©checs

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
  successThreshold: 1      # 1 succÃ¨s = prÃªt
  failureThreshold: 3      # 3 Ã©checs = pas prÃªt
```

## Namespaces : Isolation et organisation

Les Namespaces isolent les ressources dans un cluster.

### CrÃ©er et utiliser des Namespaces

```bash
# CrÃ©er des namespaces
kubectl create namespace production
kubectl create namespace staging
kubectl create namespace development

# Lister les namespaces
kubectl get namespaces

# DÃ©ployer dans un namespace spÃ©cifique
kubectl apply -f deployment.yaml -n production

# DÃ©finir le namespace par dÃ©faut
kubectl config set-context --current --namespace=production

# Voir les ressources d'un namespace
kubectl get all -n production
```

### Organisation recommandÃ©e

```
production/
â”œâ”€â”€ api-fpc (3 replicas)
â”œâ”€â”€ postgres
â””â”€â”€ redis

staging/
â”œâ”€â”€ api-fpc (2 replicas)
â”œâ”€â”€ postgres
â””â”€â”€ redis

development/
â”œâ”€â”€ api-fpc (1 replica)
â”œâ”€â”€ postgres
â””â”€â”€ redis
```

**Fichier avec namespace explicite :**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-fpc
  namespace: production  # Namespace explicite
spec:
  replicas: 3
  # ...
```

### Resource Quotas par Namespace

Limitez les ressources par namespace :

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: development
spec:
  hard:
    requests.cpu: "4"        # Max 4 CPU
    requests.memory: 8Gi     # Max 8 GB RAM
    persistentvolumeclaims: "10"  # Max 10 PVCs
    pods: "20"               # Max 20 Pods
```

## Monitoring et ObservabilitÃ©

Surveiller vos applications dans Kubernetes est crucial.

### Prometheus et Grafana

**Installation avec Helm :**

```bash
# Installer Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Ajouter le repo Prometheus
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Installer Prometheus + Grafana
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace
```

**AccÃ©der Ã  Grafana :**

```bash
# Port-forward pour accÃ¨s local
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# Ouvrir http://localhost:3000
# Login: admin / prom-operator
```

### Exporter des mÃ©triques depuis FreePascal

**Ajouter un endpoint /metrics :**

```pascal
procedure HandleMetrics(var Response: TFPHTTPConnectionResponse);
var
  Metrics: String;
begin
  Metrics := '# HELP api_requests_total Total API requests' + LineEnding +
             '# TYPE api_requests_total counter' + LineEnding +
             'api_requests_total ' + IntToStr(RequestCount) + LineEnding +
             LineEnding +
             '# HELP api_response_time_seconds API response time' + LineEnding +
             '# TYPE api_response_time_seconds histogram' + LineEnding +
             'api_response_time_seconds_sum ' + FloatToStr(ResponseTimeSum) + LineEnding +
             'api_response_time_seconds_count ' + IntToStr(ResponseTimeCount) + LineEnding;

  Response.Code := 200;
  Response.Content := Metrics;
  Response.ContentType := 'text/plain';
end;
```

**Service Monitor pour Prometheus :**

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: api-fpc-monitor
spec:
  selector:
    matchLabels:
      app: api-fpc
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
```

### Logging avec Fluentd

**Architecture de logging :**
```
Pods (logs) â†’ Fluentd â†’ Elasticsearch â†’ Kibana
```

**DaemonSet Fluentd :**

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      k8s-app: fluentd
  template:
    metadata:
      labels:
        k8s-app: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
```

**Dans votre application FreePascal, loggez en JSON :**

```pascal
procedure LogJSON(Level, Message: String);
var
  LogEntry: String;
begin
  LogEntry := Format('{"timestamp":"%s","level":"%s","message":"%s"}',
                     [FormatDateTime('yyyy-mm-dd"T"hh:nn:ss', Now),
                      Level,
                      Message]);
  WriteLn(LogEntry);
end;

// Utilisation
LogJSON('INFO', 'Application dÃ©marrÃ©e');
LogJSON('ERROR', 'Connexion base de donnÃ©es Ã©chouÃ©e');
```

## SÃ©curitÃ© dans Kubernetes

### RBAC (Role-Based Access Control)

ContrÃ´lez qui peut faire quoi dans le cluster.

**ServiceAccount pour votre application :**

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: api-fpc-sa
  namespace: production
```

**Role (permissions dans un namespace) :**

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: api-fpc-role
  namespace: production
rules:
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list"]
```

**RoleBinding (lier le Role au ServiceAccount) :**

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: api-fpc-binding
  namespace: production
subjects:
- kind: ServiceAccount
  name: api-fpc-sa
roleRef:
  kind: Role
  name: api-fpc-role
  apiGroup: rbac.authorization.k8s.io
```

**Utiliser dans le Deployment :**

```yaml
spec:
  template:
    spec:
      serviceAccountName: api-fpc-sa
      containers:
      - name: api
        # ...
```

### Network Policies

ContrÃ´lez le trafic rÃ©seau entre Pods.

**Exemple : Seuls les Pods API peuvent contacter PostgreSQL**

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: postgres-policy
spec:
  podSelector:
    matchLabels:
      app: postgres
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: api-fpc
    ports:
    - protocol: TCP
      port: 5432
```

### Security Context

Configurez les options de sÃ©curitÃ© des conteneurs.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-fpc
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true   # Ne pas tourner en root
        runAsUser: 1000      # UID de l'utilisateur
        fsGroup: 1000        # GID pour les volumes
      containers:
      - name: api
        image: votre-username/api-fpc:1.0.0
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true  # SystÃ¨me de fichiers en lecture seule
          capabilities:
            drop:
            - ALL  # Retirer toutes les capabilities Linux
        volumeMounts:
        - name: tmp
          mountPath: /tmp  # Seul /tmp est writable
      volumes:
      - name: tmp
        emptyDir: {}
```

## Helm : Gestionnaire de paquets Kubernetes

Helm simplifie le dÃ©ploiement d'applications complexes.

### Installation de Helm

```bash
# Linux
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Windows (Chocolatey)
choco install kubernetes-helm

# VÃ©rifier
helm version
```

### CrÃ©er un Chart Helm pour votre application

**Structure d'un Chart :**

```
freepascal-app/
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ values.yaml
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â””â”€â”€ secret.yaml
â””â”€â”€ charts/  # DÃ©pendances
```

**Fichier : `Chart.yaml`**

```yaml
apiVersion: v2
name: freepascal-app
description: Application FreePascal sur Kubernetes
type: application
version: 1.0.0
appVersion: "1.0.0"
```

**Fichier : `values.yaml`**

```yaml
replicaCount: 3

image:
  repository: votre-username/api-fpc
  tag: "1.0.0"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: nginx
  hosts:
    - host: api.monapp.com
      paths:
        - path: /
          pathType: Prefix

resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "500m"

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 50

database:
  host: postgres
  name: myapp
  user: dbuser
  password: supersecret123
```

**Fichier : `templates/deployment.yaml`**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "freepascal-app.fullname" . }}
  labels:
    {{- include "freepascal-app.labels" . | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "freepascal-app.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "freepascal-app.selectorLabels" . | nindent 8 }}
    spec:
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          value: {{ .Values.database.host }}
        - name: DB_NAME
          value: {{ .Values.database.name }}
        - name: DB_USER
          value: {{ .Values.database.user }}
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ include "freepascal-app.fullname" . }}-secret
              key: password
        resources:
          {{- toYaml .Values.resources | nindent 10 }}
```

### Utiliser le Chart

```bash
# Installer
helm install mon-app ./freepascal-app

# Avec des valeurs personnalisÃ©es
helm install mon-app ./freepascal-app \
  --set replicaCount=5 \
  --set image.tag=1.1.0

# Avec un fichier de values custom
helm install mon-app ./freepascal-app -f custom-values.yaml

# Mettre Ã  jour
helm upgrade mon-app ./freepascal-app

# Rollback
helm rollback mon-app

# DÃ©sinstaller
helm uninstall mon-app

# Lister les releases
helm list
```

### Publier votre Chart

```bash
# Packager le chart
helm package freepascal-app/

# CrÃ©er un index
helm repo index .

# HÃ©berger sur GitHub Pages ou serveur web
# Les utilisateurs peuvent alors :
helm repo add mon-repo https://example.com/helm-charts
helm install mon-app mon-repo/freepascal-app
```

## Bonnes pratiques Kubernetes

### 1. Labels et Annotations

Utilisez des labels cohÃ©rents :

```yaml
metadata:
  labels:
    app: api-fpc
    version: v1.0.0
    component: backend
    tier: api
    environment: production
  annotations:
    description: "API FreePascal principale"
    maintainer: "votre.email@example.com"
    documentation: "https://docs.example.com/api"
```

### 2. Resource Limits

DÃ©finissez toujours requests et limits :

```yaml
resources:
  requests:  # Minimum garanti
    memory: "256Mi"
    cpu: "100m"
  limits:  # Maximum autorisÃ©
    memory: "512Mi"
    cpu: "500m"
```

### 3. Graceful Shutdown

GÃ©rez proprement l'arrÃªt des Pods :

```yaml
spec:
  terminationGracePeriodSeconds: 30  # Temps pour arrÃªt propre
```

**Dans votre code FreePascal :**

```pascal
uses
  BaseUnix;

var
  ShuttingDown: Boolean = False;

procedure SignalHandler(Signal: cint); cdecl;
begin
  WriteLn('Signal SIGTERM reÃ§u, arrÃªt gracieux...');
  ShuttingDown := True;
end;

begin
  // Installer le handler
  FpSignal(SIGTERM, @SignalHandler);

  // Boucle principale
  while not ShuttingDown do
  begin
    // Traiter les requÃªtes
    Sleep(100);
  end;

  // Cleanup
  WriteLn('Fermeture des connexions...');
  // Fermer DB, Redis, etc.
  WriteLn('ArrÃªt terminÃ©.');
end.
```

### 4. Configuration par environnement

Utilisez des overlays Kustomize :

```
k8s/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ service.yaml
â”œâ”€â”€ overlays/
â”‚   â”œâ”€â”€ production/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â””â”€â”€ replicas.yaml
â”‚   â””â”€â”€ staging/
â”‚       â”œâ”€â”€ kustomization.yaml
â”‚       â””â”€â”€ replicas.yaml
```

**base/kustomization.yaml :**
```yaml
resources:
- deployment.yaml
- service.yaml
```

**overlays/production/kustomization.yaml :**
```yaml
bases:
- ../../base

patchesStrategicMerge:
- replicas.yaml

namespace: production
```

**DÃ©ployer :**
```bash
kubectl apply -k overlays/production
```

### 5. GitOps avec ArgoCD

Automatisez le dÃ©ploiement depuis Git.

**Installation ArgoCD :**

```bash
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# AccÃ©der Ã  l'interface
kubectl port-forward svc/argocd-server -n argocd 8080:443
```

**Application ArgoCD :**

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: freepascal-app
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/username/freepascal-k8s
    targetRevision: main
    path: k8s/overlays/production
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
```

Maintenant, chaque commit vers Git dÃ©clenche un dÃ©ploiement automatique !

## Troubleshooting : RÃ©soudre les problÃ¨mes

### Commandes de debugging essentielles

```bash
# Voir l'Ã©tat des Pods
kubectl get pods

# DÃ©tails d'un Pod
kubectl describe pod <pod-name>

# Logs d'un Pod
kubectl logs <pod-name>

# Logs en temps rÃ©el
kubectl logs -f <pod-name>

# Logs du conteneur prÃ©cÃ©dent (si redÃ©marrÃ©)
kubectl logs <pod-name> --previous

# Shell interactif dans un Pod
kubectl exec -it <pod-name> -- /bin/bash

# Copier des fichiers
kubectl cp <pod-name>:/chemin/fichier ./local-fichier

# Port-forward pour accÃ¨s local
kubectl port-forward pod/<pod-name> 8080:8080

# Ã‰vÃ©nements du cluster
kubectl get events --sort-by='.lastTimestamp'

# Utilisation des ressources
kubectl top nodes
kubectl top pods
```

### ProblÃ¨mes courants

**1. Pod en CrashLoopBackOff**

```bash
# Voir les logs
kubectl logs <pod-name> --previous

# Causes frÃ©quentes :
# - Application plante au dÃ©marrage
# - Port dÃ©jÃ  utilisÃ©
# - DÃ©pendance manquante
```

**2. ImagePullBackOff**

```bash
# VÃ©rifier l'image
kubectl describe pod <pod-name>

# Causes :
# - Image n'existe pas
# - Registry privÃ© sans credentials
# - Typo dans le nom de l'image
```

**3. Pod Pending**

```bash
# Voir pourquoi
kubectl describe pod <pod-name>

# Causes :
# - Pas assez de ressources sur les Nodes
# - PVC en attente
# - Contraintes d'affinitÃ© non satisfaites
```

**4. Service inaccessible**

```bash
# VÃ©rifier le Service
kubectl get svc
kubectl describe svc <service-name>

# VÃ©rifier les endpoints
kubectl get endpoints <service-name>

# Tester depuis un Pod
kubectl run test --image=busybox --rm -it -- wget -O- http://<service-name>
```

## Conclusion

Vous maÃ®trisez maintenant l'orchestration Kubernetes pour vos applications FreePascal/Lazarus !

**Ce que vous avez appris :**

âœ… **Concepts fondamentaux** de Kubernetes  
âœ… **DÃ©ploiement d'applications** FreePascal  
âœ… **Gestion de la configuration** (ConfigMap, Secret)  
âœ… **Stockage persistant** avec PV/PVC  
âœ… **Scaling automatique** avec HPA  
âœ… **Mises Ã  jour sans interruption** (Rolling Updates)  
âœ… **Monitoring et logging** avec Prometheus/Grafana  
âœ… **SÃ©curitÃ©** (RBAC, Network Policies)  
âœ… **Helm** pour packaging  
âœ… **Bonnes pratiques** professionnelles

**Prochaines Ã©tapes :**

- **Section 22.3** : Infrastructure as Code (Terraform, Ansible)
- **Section 22.4** : Pipelines CI/CD complets
- **Section 22.5** : Build multi-plateforme automatisÃ©

**Ressources pour approfondir :**

- Documentation officielle : https://kubernetes.io/docs/
- Tutoriels interactifs : https://kubernetes.io/docs/tutorials/
- Kubernetes Patterns (livre)
- Production Kubernetes (livre)

**Bonne orchestration avec Kubernetes ! â˜¸ï¸ğŸš€**

â­ï¸ [Infrastructure as Code (Terraform, Ansible)](/22-devops-deploiement-multi-os/03-infrastructure-as-code-terraform-ansible.md)
